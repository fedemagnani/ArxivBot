[{"id":"http://arxiv.org/abs/2206.03386v1","published":"Tue, 07 Jun 2022 15:30:01 GMT","title":"Dependency structures in cryptocurrency market from high to low   frequency","summary":"  We investigate logarithmic price returns cross-correlations at different time horizons for a set of 25 liquid cryptocurrencies traded on the FTX digital currency exchange. We study how the structure of the Minimum Spanning Tree (MST) and the Triangulated Maximally Filtered Graph (TMFG) evolve across time horizons from high (15 seconds) to low (1 day) frequency time resolutions. For each horizon, we test the stability, statistical significance and economic meaningfulness of the networks. Results give a deep insight into the evolutionary process of the time dependent hierarchical organization of the system under analysis. A decrease in correlation between pairs of cryptocurrencies is observed for finer time sampling resolutions. A growing structure emerges for coarser ones, highlighting multiple changes in the hierarchical reference role played by mainstream cryptocurrencies. This effect is studied both in its inter- and intra-sector realizations. ","comment":"24 pages, 9 figures, 4 tables, 4 appendices","authors":"Antonio Briola, Tomaso Aste","pdf":"http://arxiv.org/pdf/2206.03386v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02871v1","published":"Mon, 06 Jun 2022 19:54:21 GMT","title":"Cooperation among an anonymous group protected Bitcoin during failures   of decentralization","summary":"  Bitcoin is a digital currency designed to rely on a decentralized, trustless network of anonymous agents. Using a pseudonymous-address-linking procedure that achieves >99% sensitivity and >99% specificity, we reveal that between launch (January 3rd, 2009), and when the price reached $1 (February 9th, 2011), most bitcoin was mined by only sixty-four agents. This was due to the rapid emergence of Pareto distributions in bitcoin income, producing such extensive resource centralization that almost all contemporary bitcoin addresses can be connected to these top agents by a chain of six transactions. Centralization created a social dilemma. Attackers could routinely exploit bitcoin via a \\51% attack\\, making it possible for them to repeatedly spend the same bitcoins. Yet doing so would harm the community. Strikingly, we find that potential attackers always chose to cooperate instead. We model this dilemma using an N-player Centipede game in which anonymous players can choose to exploit, and thereby undermine, an appreciating good. Combining theory and economic experiments, we show that, even when individual payoffs are unchanged, cooperation is more frequent when the game is played by an anonymous group. Although bitcoin was designed to rely on a decentralized, trustless network of anonymous agents, its early success rested instead on cooperation among a small group of altruistic founders. ","comment":"12 pages main text 6 main text figures 76 total pages 23 supplemental   figures","authors":"Alyssa Blackburn, Christoph Huber, Yossi Eliaz, Muhammad S. Shamim, David Weisz, Goutham Seshadri, Kevin Kim, Shengqi Hang, Erez Lieberman Aiden","pdf":"http://arxiv.org/pdf/2206.02871v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02248v1","published":"Sun, 05 Jun 2022 19:50:11 GMT","title":"LNGate$^2$: Secure Bidirectional IoT Micro-payments using Bitcoin's   Lightning Network and Threshold Cryptography","summary":"  Bitcoin has emerged as a revolutionary payment system with its decentralized ledger concept; however it has significant problems such as high transaction fees and low throughput. Lightning Network (LN), which was introduced much later, solves most of these problems with an innovative concept called off-chain payments. With this advancement, Bitcoin has become an attractive venue to perform micro-payments which can also be adopted in many IoT applications (e.g., toll payments). Nevertheless, it is not feasible to host LN and Bitcoin on IoT devices due to the storage, memory, and processing restrictions. Therefore, in this paper, we propose a secure and efficient protocol that enables an IoT device to use LN's functions through an untrusted gateway node. Through this gateway which hosts the LN and Bitcoin nodes, the IoT device can open & close LN channels and send & receive LN payments. This delegation approach is powered by a threshold cryptography based scheme that requires the IoT device and the LN gateway to jointly perform all LN operations. Specifically, we propose thresholdizing LN's Bitcoin public and private keys as well as its public and private keys for the new channel states (i.e., commitment points). We prove with a game theoretical security analysis that the IoT device is secure against collusion and stealing attacks. We implemented the proposed protocol by changing LN's source code and thoroughly evaluated its performance using a Raspberry Pi. Our evaluation results show that the protocol is fast, does not bring extra cost overhead and can be run on low data-rate wireless networks. To the best of our knowledge, this is the first work that implemented threshold cryptography in LN. ","comment":"Journal extension of https://dl.acm.org/doi/10.1145/3448300.3467833.   arXiv admin note: substantial text overlap with arXiv:2105.08902","authors":"Ahmet Kurt, Kemal Akkaya, Sabri Yilmaz, Suat Mercan, Omer Shlomovits, Enes Erdin","pdf":"http://arxiv.org/pdf/2206.02248v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02239v1","published":"Sun, 05 Jun 2022 18:59:26 GMT","title":"Winner does not take all: contrasting centrality in adversarial networks","summary":"  In adversarial networks, edges correspond to negative interactions such as competition or dominance. We introduce a new type of node called a low-key leader in adversarial networks, distinguished by contrasting the centrality measures of CON score and PageRank. We present a novel hypothesis that low-key leaders are ubiquitous in adversarial networks and provide evidence by considering data from real-world networks, including dominance networks in 172 animal populations, trading networks between G20 nations, and Bitcoin trust networks. We introduce a random graph model that generates directed graphs with low-key leaders. ","authors":"Anthony Bonato, Joey Kapusin, Jiajie Yuan","pdf":"http://arxiv.org/pdf/2206.02239v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02227v1","published":"Sun, 05 Jun 2022 17:46:23 GMT","title":"Stability of shares in the Proof of Stake Protocol -- Concentration and   Phase Transitions","summary":"  This paper is concerned with the stability of shares in a cryptocurrency where the new coins are issued according to the Proof of Stake protocol. We identify large, medium and small investors under various rewarding schemes, and show that the limiting behaviors of these investors are different -- for large investors their shares are stable, while for medium to small investors their shares may be volatile or even shrink to zero. For instance, with a geometric reward there is chaotic centralization, where all the shares will eventually concentrate on one investor in a random manner. This leads to the phase transition phenomenon, and the thresholds for stability are characterized. In response to the increasing activities in blockchain networks, we also propose and analyze a dynamical population model for the PoS protocol, which allows the number of investors to grow over the time. Numerical experiments are provided to corroborate our theory. ","comment":"30 pages, 11 figures","authors":"Wenpin Tang","pdf":"http://arxiv.org/pdf/2206.02227v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.00716v1","published":"Wed, 01 Jun 2022 18:50:56 GMT","title":"Not so immutable: Upgradeability of Smart Contracts on Ethereum","summary":"  A smart contract that is deployed to a blockchain system like Ethereum is, under reasonable circumstances, expected to be immutable and tamper-proof. This is both a feature (promoting integrity and transparency) and a bug (preventing security patches and feature updates). Modern smart contracts use software tricks to enable upgradeability, raising the research questions of how upgradeability is achieved and who is authorized to make changes. In this paper, we summarize and evaluate six upgradeability patterns. We develop a measurement framework for finding how many upgradeable contracts are on Ethereum that use certain prominent upgrade patters. We find 1.4 million proxy contracts which 8,225 of them are unique upgradeable proxy contracts. We also measure how they implement access control over their upgradeability: about 50% are controlled by a single Externally Owned Address (EOA), and about 14% are controlled by multi-signature wallets in which a limited number of persons can change the whole logic of the contract. ","authors":"Mehdi Salehi, Jeremy Clark, Mohammad Mannan","pdf":"http://arxiv.org/pdf/2206.00716v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.00375v1","published":"Wed, 01 Jun 2022 10:21:30 GMT","title":"Detecting Cybercriminal Bitcoin Relationships through Backwards   Exploration","summary":"  Cybercriminals often leverage Bitcoin for their illicit activities. In this work, we propose back-and-forth exploration, a novel automated Bitcoin transaction tracing technique to identify cybercrime financial relationships. Given seed addresses belonging to a cybercrime campaign, it outputs a transaction graph, and identifies paths corresponding to relationships between the campaign under study and external services and other cybercrime campaigns. Back-and-forth exploration provides two key contributions. First, it explores both forward and backwards, instead of only forward as done by prior work, enabling the discovery of relationships that cannot be found by only exploring forward (e.g., deposits from clients of a mixer). Second, it prevents graph explosion by combining a tagging database with a machine learning classifier for identifying addresses belonging to exchanges. We evaluate back-and-forth exploration on 30 malware families. We build oracles for 4 families using Bitcoin for C&C and use them to demonstrate that back-and-forth exploration identifies 13 C&C signaling addresses missed by prior work, 8 of which are fundamentally missed by forward-only explorations. Our approach uncovers a wealth of services used by the malware including 44 exchanges, 11 gambling sites, 5 payment service providers, 4 underground markets, 4 mining pools, and 2 mixers. In 4 families, the relations include new attribution points missed by forward-only explorations. It also identifies relationships between the malware families and other cybercrime campaigns, highlighting how some malware operators participate in a variety of cybercriminal activities. ","authors":"Gibran Gomez, Pedro Moreno-Sanchez, Juan Caballero","pdf":"http://arxiv.org/pdf/2206.00375v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.00648v1","published":"Mon, 30 May 2022 19:25:12 GMT","title":"A multimodal model with Twitter FinBERT embeddings for extreme price   movement prediction of Bitcoin","summary":"  Bitcoin, with its ever-growing popularity, has demonstrated extreme price volatility since its origin. This volatility, together with its decentralised nature, make Bitcoin highly subjective to speculative trading as compared to more traditional assets. In this paper, we propose a multimodal model for predicting extreme price fluctuations. This model takes as input a variety of correlated assets, technical indicators, as well as Twitter content. In an in-depth study, we explore whether social media discussions from the general public on Bitcoin have predictive power for extreme price movements. A dataset of 5,000 tweets per day containing the keyword `Bitcoin' was collected from 2015 to 2021. This dataset, called PreBit, is made available online. In our hybrid model, we use sentence-level FinBERT embeddings, pretrained on financial lexicons, so as to capture the full contents of the tweets and feed it to the model in an understandable way. By combining these embeddings with a Convolutional Neural Network, we built a predictive model for significant market movements. The final multimodal ensemble model includes this NLP model together with a model based on candlestick data, technical indicators and correlated asset prices. In an ablation study, we explore the contribution of the individual modalities. Finally, we propose and backtest a trading strategy based on the predictions of our models with varying prediction threshold and show that it can used to build a profitable trading strategy with a reduced risk over a `hold' or moving average strategy. ","comment":"18 pages, submitted preprint to Elsevier Expert Systems with   Applications","authors":"Yanzhao Zou, Dorien Herremans","pdf":"http://arxiv.org/pdf/2206.00648v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03867v1","published":"Mon, 30 May 2022 16:33:26 GMT","title":"Blockchain-enabled supply chain: An experimental study","summary":"  Despite Information and Communication Technologies (ICT) have reduced the information asymmetry and increased the degree of interorganizational collaboration, the companies participating a supply chain are less inclined to share data when information is sensible and partners cannot be fully trusted. In such a context, Blockchain is a decentralized certificate authority that may provide economic and operational benefits but companies operating in a supply chain claim to have little knowledge about Blockchain due to its novelty and to the lack of use cases and application studies. In this work, a software connector has been designed and developed to connect an Ethereum-like blockchain with the enterprises' information systems to allow companies to share information with their partners with different levels of visibility and to check data authenticity, integrity and invariability over time through the blockchain, thus building trust. In order to explore the potential of deploying the blockchain in a supply chain, a simulation model has been developed to recreate the supply chain operations and integrated with the blockchain through the same software connector to carry out a scenario statistical analysis. Application results shows how blockchain technology is a convenient instrument to overcome collaboration and trust issues in a supply chain, to increase the supply chain overall performance, to minimize the negative consequences of information asymmetry over the echelons of a supply chain but also to discourage companies from any misconduct (e.g. counterfeiting data or low data accuracy). ","comment":"13 pages, 15 figures, 10 tables","authors":"Francesco Longo, Letizia Nicoletti, Antonio Padovano, Gianfranco d'Atri, Marco Forte","pdf":"http://arxiv.org/pdf/2206.03867v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14611v1","published":"Sun, 29 May 2022 09:23:02 GMT","title":"Forensic Artefact Discovery and Attribution from Android Cryptocurrency   Wallet Applications","summary":"  Cryptocurrency has been (ab)used to purchase illicit goods and services such as drugs, weapons and child pornography (also referred to as child sexual abuse materials), and thus mobile devices (where cryptocurrency wallet applications are installed) are a potential source of evidence in a criminal investigation. Not surprisingly, there has been increased focus on the security of cryptocurrency wallets, although forensic extraction and attribution of forensic artefacts from such wallets is understudied. In this paper, we examine Bitcoin and Dogecoin. The latter is increasingly popular partly due to endorsements from celebrities and being positioned as an introductory path to cryptocurrency for newcomers. Specifically, we demonstrate how one can acquire forensic artefacts from Android Bitcoin and Dogecoin cryptocurrency wallets, such as wallet IDs, transaction IDs, timestamp information, email addresses, cookies, and OAuth tokens. ","authors":"Eugene Chang, Paul Darcy, Kim-Kwang Raymond Choo, Nhien-An Le-Khac","pdf":"http://arxiv.org/pdf/2205.14611v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14517v1","published":"Sat, 28 May 2022 20:15:49 GMT","title":"The Relationship between Digital RMB and Digital Economy in China","summary":"  By comparing the historical patterns of currency development, this paper pointed out the inevitability of the development of digital currency and the relationship between digital currency and the digital economy. With the example of China, this paper predicts the future development trend of digital currency. In the context of the rapid development of private cryptocurrency, China launched the digital currency based on serving the digital economy and committed to the globalization of the digital renminbi (RMB) and the globalization of the digital economy. The global economy in 2022 ushered in stagnation, and China treats digital fiat currency and the digital economy development as a breakthrough to pursue economic transformation and new growth. It has become one of the forefront countries with numerous experiences that can be learned by countries around the world. ","comment":"C.S. and W.L. contributed equally to this work","authors":"Chang Su, Wenbo Lyu, Yueting Liu","pdf":"http://arxiv.org/pdf/2205.14517v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14076v1","published":"Fri, 27 May 2022 16:15:03 GMT","title":"How to Tame Multiple Spending in Decentralized Cryptocurrencies","summary":"  The last decade has seen a variety of Asset-Transfer systems designed for decentralized environments. To address the problem of double-spending, these systems inherently make strong model assumptions and spend a lot of resources. In this paper, we take a non-orthodox approach to the double-spending problem that might suit better realistic environments in which these systems are to be deployed. We consider the decentralized trust setting, where each user may independently choose who to trust by forming its local quorums. In this setting, we define $k$-Spending Asset Transfer, a relaxed version of asset transfer which bounds the number of times the same asset can be spent. We establish a precise relationship between the decentralized trust assumptions and $k$, the optimal spending number of the system. ","authors":"João Paulo Bezerra, Petr Kuznetsov","pdf":"http://arxiv.org/pdf/2205.14076v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.13882v1","published":"Fri, 27 May 2022 10:32:41 GMT","title":"How to Peel a Million: Validating and Expanding Bitcoin Clusters","summary":"  One of the defining features of Bitcoin and the thousands of cryptocurrencies that have been derived from it is a globally visible transaction ledger. While Bitcoin uses pseudonyms as a way to hide the identity of its participants, a long line of research has demonstrated that Bitcoin is not anonymous. This has been perhaps best exemplified by the development of clustering heuristics, which have in turn given rise to the ability to track the flow of bitcoins as they are sent from one entity to another.   In this paper, we design a new heuristic that is designed to track a certain type of flow, called a peel chain, that represents many transactions performed by the same entity; in doing this, we implicitly cluster these transactions and their associated pseudonyms together. We then use this heuristic to both validate and expand the results of existing clustering heuristics. We also develop a machine learning-based validation method and, using a ground-truth dataset, evaluate all our approaches and compare them with the state of the art. Ultimately, our goal is to not only enable more powerful tracking techniques but also call attention to the limits of anonymity in these systems. ","authors":"George Kappos, Haaroon Yousaf, Rainer Stütz, Sofia Rollet, Bernhard Haslhofer, Sarah Meiklejohn","pdf":"http://arxiv.org/pdf/2205.13882v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.13426v1","published":"Thu, 26 May 2022 15:30:40 GMT","title":"AntiBenford Subgraphs: Unsupervised Anomaly Detection in Financial   Networks","summary":"  Benford's law describes the distribution of the first digit of numbers appearing in a wide variety of numerical data, including tax records, and election outcomes, and has been used to raise \\red flags\\ about potential anomalies in the data such as tax evasion. In this work, we ask the following novel question: given a large transaction or financial graph, how do we find a set of nodes that perform many transactions among each other that also deviate significantly from Benford's law?   We propose the AntiBenford subgraph framework that is founded on well-established statistical principles. Furthermore, we design an efficient algorithm that finds AntiBenford subgraphs in near-linear time on real data. We evaluate our framework on both real and synthetic data against a variety of competitors. We show empirically that our proposed framework enables the detection of anomalous subgraphs in cryptocurrency transaction networks that go undetected by state-of-the-art graph-based anomaly detection methods. Our empirical findings show that our \\\\ab framework is able to mine anomalous subgraphs, and provide novel insights into financial transaction data.   The code and the datasets are available at \\\\url{https://github.com/tsourakakis-lab/antibenford-subgraphs}. ","comment":"Accepted at KDD'22","authors":"Tianyi Chen, Charalampos E. Tsourakakis","pdf":"http://arxiv.org/pdf/2205.13426v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.13333v1","published":"Thu, 26 May 2022 13:10:04 GMT","title":"SoK: Decentralized Randomness Beacon Protocols","summary":"  The scientific interest in the area of Decentralized Randomness Beacon (DRB) protocols has been thriving recently. Partially that interest is due to the success of the disruptive technologies introduced by modern cryptography, such as cryptocurrencies, blockchain technologies, and decentralized finances, where there is an enormous need for a public, reliable, trusted, verifiable, and distributed source of randomness. On the other hand, recent advancements in the development of new cryptographic primitives brought a huge interest in constructing a plethora of DRB protocols differing in design and underlying primitives.   To the best of our knowledge, no systematic and comprehensive work systematizes and analyzes the existing DRB protocols. Therefore, we present a Systematization of Knowledge (SoK) intending to structure the multi-faced body of research on DRB protocols. In this SoK, we delineate the DRB protocols along the following axes: their underlying primitive, properties, and security. This SoK tries to fill that gap by providing basic standard definitions and requirements for DRB protocols, such as Unpredictability, Bias-resistance, Availability (or Liveness), and Public Verifiability. We classify DRB protocols according to the nature of interactivity among protocol participants. We also highlight the most significant features of DRB protocols such as scalability, complexity, and performance along with a brief discussion on its improvement. We present future research directions along with a few interesting research problems. ","comment":"Accepted at the 27th Australasian Conference on Information Security   and Privacy (ACISP 2022)","authors":"Mayank Raikwar, Danilo Gligoroski","pdf":"http://arxiv.org/pdf/2205.13333v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.13322v1","published":"Thu, 26 May 2022 12:53:40 GMT","title":"DoS Attacks on Blockchain Ecosystem","summary":"  Denial of Service (DoS) attacks are a growing threat in network services. The frequency and intensity of DoS attacks are rapidly increasing day by day. The immense financial potential of the Cryptocurrency market is a prevalent target of the DoS attack. The DoS attack events are kept on happening in cryptocurrencies and the blockchain ecosystem. To the best of our knowledge, there has not been any study on the DoS attack on the blockchain ecosystem. In this paper, we identify ten entities in the blockchain ecosystem and we scrutinize the DoS attacks on them. We also present the DoS mitigation techniques applicable to the blockchain services. Additionally, we propose a DoS mitigation technique by the use of verifiable delay function (VDF). ","comment":"Accepted at 4TH INTERNATIONAL WORKSHOP ON FUTURE PERSPECTIVE OF   DECENTRALIZED APPLICATIONS (FPDAPP), Euro-Par 2021: Parallel Processing   Workshops","authors":"Mayank Raikwar, Danilo Gligoroski","pdf":"http://arxiv.org/pdf/2205.13322v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12995v1","published":"Wed, 25 May 2022 18:05:44 GMT","title":"Black holes and cryptocurrencies","summary":"  It has been proposed in the literature that the volume of Einstein-Rosen bridge is equal to complexity of state preparation (\\Complexity=Volume\\ conjecture). Taking this statement outside the horizon, one might be tempted to propose \\Complexity=Time\\ correspondence. In this Essay we argue that in a blockchain protocol, which is the foundation of all modern cryptocurrencies, time is emergent and it is defined according to a version of \\Complexity=Time\\. ","comment":"15 pages. Essay written for the Gravity Research Foundation 2022   Awards for Essays on Gravitation (extended version)","authors":"Alexey Milekhin","pdf":"http://arxiv.org/pdf/2205.12995v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12905v2","published":"Wed, 25 May 2022 16:51:09 GMT","title":"Analytics of Business Time Series Using Machine Learning and Bayesian   Inference","summary":"  In the survey we consider the case studies on sales time series forecasting, the deep learning approach for forecasting non-stationary time series using time trend correction, dynamic price and supply optimization using Q-learning, Bitcoin price modeling, COVID-19 spread impact on stock market, using social networks signals in analytics. The use of machine learning and Bayesian inference in predictive analytics has been analyzed. ","comment":"Survey article. arXiv admin note: text overlap with arXiv:2201.02034,   arXiv:2201.02058, arXiv:2201.02729, arXiv:2201.02049, arXiv:2004.01489","authors":"Bohdan M. Pavlyshenko","pdf":"http://arxiv.org/pdf/2205.12905v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12897v1","published":"Wed, 25 May 2022 16:30:55 GMT","title":"Cryptocurreny Giveaway Scam with YouTube Live Stream","summary":"  This paper investigates the cryptocurrency giveaway scam with the YouTube live stream carried out on 5/15/2022 and 5/16/2022. In this scam scheme, the scammer plays a recorded video of a famous person in a YouTube live stream annotated with a cryptocurrency giveaway announcement. In the annotated announcement, the victims are directed to the scammer's webpage. The scammer's webpage is designed intelligently to deceive victims such that they believe the legitimacy of the giveaway. The scammer claims that whatever donation the victim sends to a cryptocurrency wallet address, the giveaway scheme will double the donated amount and immediately send it back to the victim. By analyzing the scammers' wallet addresses, it can be seen that scammers could steal a significant amount of money in a short time. After analyzing the attackers' techniques, tactics, and procedures, this paper discusses the countermeasures that can be applied to mitigate such a fraudulent activity in the future. ","authors":"Iman Vakilinia","pdf":"http://arxiv.org/pdf/2205.12897v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.09922v1","published":"Fri, 20 May 2022 01:32:07 GMT","title":"Nonlinear Forecasts and Impulse Responses for Causal-Noncausal (S)VAR   Models","summary":"  We introduce the closed-form formulas of nonlinear forecasts and nonlinear impulse response functions (IRF) for the mixed causal-noncausal (Structural) Vector Autoregressive (S)VAR models. We also discuss the identification of nonlinear causal innovations of the model to which the shocks are applied. Our approach is illustrated by a simulation study and an application to a bivariate process of Bitcoin/USD and Ethereum/USD exchange rates. ","comment":"53 pages, 17 figures","authors":"Christian Gourieroux, Joann Jasiak","pdf":"http://arxiv.org/pdf/2205.09922v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.09524v1","published":"Thu, 19 May 2022 12:44:11 GMT","title":"Security Analysis of DeFi: Vulnerabilities, Attacks and Advances","summary":"  Decentralized finance (DeFi) in Ethereum is a financial ecosystem built on the blockchain that has locked over 200 billion USD until April 2022. All transaction information is transparent and open when transacting through the DeFi protocol, which has led to a series of attacks. Several studies have attempted to optimize it from both economic and technical perspectives. However, few works analyze the vulnerabilities and optimizations of the entire DeFi system. In this paper, we first systematically analyze vulnerabilities related to DeFi in Ethereum at several levels, then we investigate real-world attacks. Finally, we summarize the achievements of DeFi optimization and provide some future directions. ","authors":"Wenkai Li, Jiuyang Bu, Xiaoqi Li, Xianyi Chen","pdf":"http://arxiv.org/pdf/2205.09524v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.08904v1","published":"Wed, 18 May 2022 12:56:37 GMT","title":"Risks and Returns of Uniswap V3 Liquidity Providers","summary":"  Trade execution on Decentralized Exchanges (DEXes) is automatic and does not require individual buy and sell orders to be matched. Instead, liquidity aggregated in pools from individual liquidity providers enables trading between cryptocurrencies. The largest DEX measured by trading volume, Uniswap V3, promises a DEX design optimized for capital efficiency. However, Uniswap V3 requires far more decisions from liquidity providers than previous DEX designs.   In this work, we develop a theoretical model to illustrate the choices faced by Uniswap V3 liquidity providers and their implications. Our model suggests that providing liquidity on Uniswap V3 is highly complex and requires many considerations from a user. Our supporting data analysis of the risks and returns of real Uniswap V3 liquidity providers underlines that liquidity providing in Uniswap V3 is incredibly complicated, and performances can vary wildly. While there are simple and profitable strategies for liquidity providers in liquidity pools characterized by negligible price volatilities, these strategies only yield modest returns. Instead, significant returns can only be obtained by accepting increased financial risks and at the cost of active management. Thus, providing liquidity has become a game reserved for sophisticated players with the introduction of Uniswap V3, where retail traders do not stand a chance. ","authors":"Lioba Heimbach, Eric Schertenleib, Roger Wattenhofer","pdf":"http://arxiv.org/pdf/2205.08904v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.08529v1","published":"Tue, 17 May 2022 17:53:45 GMT","title":"F3B: A Low-Latency Commit-and-Reveal Architecture to Mitigate Blockchain   Front-Running","summary":"  Front-running attacks, which benefit from advanced knowledge of pending transactions, have proliferated in the cryptocurrency space since the emergence of decentralized finance. Front-running causes devastating losses to honest participants$\\\\unicode{x2013}$estimated at \\\\$280M each month$\\\\unicode{x2013}$and endangers the fairness of the ecosystem. We present Flash Freezing Flash Boys (F3B), a blockchain architecture to address front-running attacks by relying on a commit-and-reveal scheme where the contents of transactions are encrypted and later revealed by a decentralized secret-management committee once the underlying consensus layer has committed the transaction. F3B mitigates front-running attacks because an adversary can no longer read the content of a transaction before commitment, thus preventing the adversary from benefiting from advance knowledge of pending transactions. We design F3B to be agnostic to the underlying consensus algorithm and compatible with legacy smart contracts by addressing front-running at the blockchain architecture level. Unlike existing commit-and-reveal approaches, F3B only requires writing data onto the underlying blockchain once, establishing a significant overhead reduction. An exploration of F3B shows that with a secret-management committee consisting of 8 and 128 members, F3B presents between 0.1 and 1.8 seconds of transaction-processing latency, respectively. ","authors":"Haoqian Zhang, Louis-Henri Merino, Vero Estrada-Galinanes, Bryan Ford","pdf":"http://arxiv.org/pdf/2205.08529v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.08512v1","published":"Tue, 17 May 2022 17:31:16 GMT","title":"Experimental evaluation of digitally-verifiable photonic computing for   blockchain and cryptocurrency","summary":"  As blockchain technology and cryptocurrency become increasingly mainstream, ever-increasing energy costs required to maintain the computational power running these decentralized platforms create a market for more energy-efficient hardware. Photonic cryptographic hash functions, which use photonic integrated circuits to accelerate computation, promise energy efficiency for verifying transactions and mining in a cryptonetwork. Like many analog computing approaches, however, current proposals for photonic cryptographic hash functions that promise similar security guarantees as Bitcoin are susceptible to systematic error, so multiple devices may not reach a consensus on computation despite high numerical precision (associated with low photodetector noise). In this paper, we theoretically and experimentally demonstrate that a more general family of robust discrete analog cryptographic hash functions, which we introduce as LightHash, leverages integer matrix-vector operations on photonic mesh networks of interferometers. The difficulty of LightHash can be adjusted to be sufficiently tolerant to systematic error (calibration error, loss error, coupling error, and phase error) and preserve inherent security guarantees present in the Bitcoin protocol. Finally, going beyond our proof-of-concept, we define a ``photonic advantage'' criterion and justify how recent developments in CMOS optoelectronics (including analog-digital conversion) provably achieve such advantage for robust and digitally-verifiable photonic computing and ultimately generate a new market for decentralized photonic technology. ","comment":"17 pages, 7 figures","authors":"Sunil Pai, Taewon Park, Marshall Ball, Bogdan Penkovsky, Maziyar Milanizadeh, Michael Dubrovsky, Nathnael Abebe, Francesco Morichetti, Andrea Melloni, Shanhui Fan, Olav Solgaard, David A. B. Miller","pdf":"http://arxiv.org/pdf/2205.08512v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.08087v1","published":"Tue, 17 May 2022 04:21:06 GMT","title":"An Empirical Study of Blockchain Repositories in GitHub","summary":"  Blockchain is a distributed ledger technique that guarantees the traceability of transactions. Blockchain is adopted in multiple domains like finance (e.g., cryptocurrency), healthcare, security, and supply chain. In the open-source software (OSS) portal GitHub, we observe a growing adoption of Blockchain-based solutions. Given the rapid emergence of Blockchain-based solutions in our daily life and the evolving cryptocurrency market, it is important to know the status quo, how developers generally interact in those repos, and how much freedom they have in applying code changes. We report an empirical study of 3,664 Blockchain software repositories from GitHub. We divide the Blockchain repositories into two categories: Tool (e.g., SDKs) and Applications (e.g., service/solutions developed using SDKs). The Application category is further divided into two sub-categories: Crypto and Non-Crypto applications. In all Blockchain repository categories, the contribution interactions on commits are the most common interaction type. We found that more organizations contributing to the Blockchain repos than individual users. The median numbers of internal and external users in tools are higher than the application repos. We observed a higher degree of collaboration (e.g., for maintenance efforts) among users in Blockchain tools than those in the application repos. Among the artifacts, issues have a greater number of interactions than commits and pull requests. Related to autonomy we found that less than half of total project contributions are autonomous. Our findings offer implications to Blockchain stakeholders, like developers to stay aware of OSS practices around Blockchain software. ","comment":"The International Conference on Evaluation and Assessment in Software   Engineering 2022 (EASE 2022)","authors":"Ajoy Das, Gias Uddin, Guenther Ruhe","pdf":"http://arxiv.org/pdf/2205.08087v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03227v1","published":"Mon, 16 May 2022 18:03:45 GMT","title":"Does Crypto Kill? Relationship between Electricity Consumption Carbon   Footprints and Bitcoin Transactions","summary":"  Cryptocurrencies are gaining more popularity due to their security, making counterfeits impossible. However, these digital currencies have been criticized for creating a large carbon footprint due to their algorithmic complexity and decentralized system design for proof of work and mining. We hypothesize that the carbon footprint of cryptocurrency transactions has a higher dependency on carbon-rich fuel sources than green or renewable fuel sources. We provide a machine learning framework to model such transactions and correlate them with the electricity generation patterns to estimate and analyze their carbon cost. ","comment":"8 pages, 17 figures","authors":"Altanai Bisht, Arielle Wilson, Zachary Jeffreys, Shadrokh Samavi","pdf":"http://arxiv.org/pdf/2206.03227v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07529v1","published":"Mon, 16 May 2022 09:08:48 GMT","title":"Specification is Law: Safe Creation and Upgrade of Ethereum Smart   Contracts","summary":"  Smart contracts are the building blocks of the \\code is law\\ paradigm: the smart contract's code indisputably describes how its assets are to be managed - once it is created, its code is typically immutable. Faulty smart contracts present the most significant evidence against the practicality of this paradigm; they are well-documented and resulted in assets worth vast sums of money being compromised. To address this issue, the Ethereum community proposed (i) tools and processes to audit/analyse smart contracts, and (ii) design patterns implementing a mechanism to make contract code mutable. Individually, (i) and (ii) only partially address the challenges raised by the \\code is law\\ paradigm. In this paper, we combine elements from (i) and (ii) to create a systematic framework that moves away from \\code is law\\ and gives rise to a new \\specification is law\\ paradigm. It allows contracts to be created and upgraded but only if they meet a corresponding formal specification. The framework is centered around \\\\emph{a trusted deployer}: an off-chain service that formally verifies and enforces this notion of conformance. We have prototyped this framework, and investigated its applicability to contracts implementing two widely used Ethereum standards: the ERC20 Token Standard and ERC1155 Multi Token Standard, with promising results. ","authors":"Pedro Antonino, Juliandson Ferreira, Augusto Sampaio, A. W. Roscoe","pdf":"http://arxiv.org/pdf/2205.07529v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07478v1","published":"Mon, 16 May 2022 06:59:57 GMT","title":"Estimating Patch Propagation Times across (Blockchain) Forks","summary":"  The wide success of Bitcoin has led to a huge surge of alternative cryptocurrencies (altcoins). Most altcoins essentially fork Bitcoin's code with minor modifications, such as the number of coins to be minted, the block size, and the block generation time. As such, they are often deemed identical to Bitcoin in terms of security, robustness, and maturity.   In this paper, we show that this common conception is misleading. By mining data retrieved from the GitHub repositories of various altcoin projects, we estimate the time it took to propagate relevant patches from Bitcoin to the altcoins. We find that, while the Bitcoin development community is quite active in fixing security flaws of Bitcoin's code base, forked cryptocurrencies are not as rigorous in patching the same vulnerabilities (inherited from Bitcoin). In some cases, we observe that even critical vulnerabilities, discovered and fixed within the Bitcoin community, have been addressed by the altcoins tens of months after disclosure. Besides raising awareness of this problem, our work aims to motivate the need for a proper responsible disclosure of vulnerabilities to all forked chains prior to reporting them publicly. ","authors":"Sebastien Andreina, Lorenzo Alluminio, Giorgia Azzurra Marson, Ghassan Karame","pdf":"http://arxiv.org/pdf/2205.07478v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.06338v1","published":"Thu, 12 May 2022 20:00:40 GMT","title":"A Multivariate Hawkes Process Model for Stablecoin-Cryptocurrency   Depegging Event Dynamics","summary":"  Stablecoins, digital assets pegged to a specific currency or commodity value, are heavily involved in transactions of major cryptocurrencies. The effects of deviations from their desired fixed values (depeggings) on the cryptocurrencies for which they are frequently used in transactions are therefore of interest to study. We propose a model for this phenomenon using a multivariate mutually-exciting Hawkes process, and present a numerical example applying this model to Tether (USDT) and Bitcoin (BTC). ","authors":"Connor Oxenhorn","pdf":"http://arxiv.org/pdf/2205.06338v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.08382v1","published":"Wed, 11 May 2022 20:44:08 GMT","title":"Compatible deep neural network framework with financial time series   data, including data preprocessor, neural network model and trading strategy","summary":"  Experience has shown that trading in stock and cryptocurrency markets has the potential to be highly profitable. In this light, considerable effort has been recently devoted to investigate how to apply machine learning and deep learning to interpret and predict market behavior. This research introduces a new deep neural network architecture and a novel idea of how to prepare financial data before feeding them to the model. In the data preparation part, the first step is to generate many features using technical indicators and then apply the XGBoost model for feature engineering. Splitting data into three categories and using separate autoencoders, we extract high-level mixed features at the second step. This data preprocessing is introduced to predict price movements. Regarding modeling, different convolutional layers, an long short-term memory unit, and several fully-connected layers have been designed to perform binary classification. This research also introduces a trading strategy to exploit the trained model outputs. Three different datasets are used to evaluate this method, where results indicate that this framework can provide us with profitable and robust predictions. ","comment":"26 pages, 17 figures, 7 tables","authors":"Mohammadmahdi Ghahramani, Hamid Esmaeili Najafabadi","pdf":"http://arxiv.org/pdf/2205.08382v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.05611v1","published":"Wed, 11 May 2022 16:28:12 GMT","title":"Blockchain-based Secure Client Selection in Federated Learning","summary":"  Despite the great potential of Federated Learning (FL) in large-scale distributed learning, the current system is still subject to several privacy issues due to the fact that local models trained by clients are exposed to the central server. Consequently, secure aggregation protocols for FL have been developed to conceal the local models from the server. However, we show that, by manipulating the client selection process, the server can circumvent the secure aggregation to learn the local models of a victim client, indicating that secure aggregation alone is inadequate for privacy protection. To tackle this issue, we leverage blockchain technology to propose a verifiable client selection protocol. Owing to the immutability and transparency of blockchain, our proposed protocol enforces a random selection of clients, making the server unable to control the selection process at its discretion. We present security proofs showing that our protocol is secure against this attack. Additionally, we conduct several experiments on an Ethereum-like blockchain to demonstrate the feasibility and practicality of our solution. ","comment":"IEEE ICBC 2022","authors":"Truc Nguyen, Phuc Thai, Tre' R. Jeter, Thang N. Dinh, My T. Thai","pdf":"http://arxiv.org/pdf/2205.05611v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.05028v1","published":"Tue, 10 May 2022 16:41:26 GMT","title":"A Tale of Two Markets: Investigating the Ransomware Payments Economy","summary":"  Ransomware attacks are among the most severe cyber threats. They have made headlines in recent years by threatening the operation of governments, critical infrastructure, and corporations. Collecting and analyzing ransomware data is an important step towards understanding the spread of ransomware and designing effective defense and mitigation mechanisms. We report on our experience operating Ransomwhere, an open crowdsourced ransomware payment tracker to collect information from victims of ransomware attacks. With Ransomwhere, we have gathered 13.5k ransom payments to more than 87 ransomware criminal actors with total payments of more than $101 million. Leveraging the transparent nature of Bitcoin, the cryptocurrency used for most ransomware payments, we characterize the evolving ransomware criminal structure and ransom laundering strategies. Our analysis shows that there are two parallel ransomware criminal markets: commodity ransomware and Ransomware as a Service (RaaS). We notice that there are striking differences between the two markets in the way that cryptocurrency resources are utilized, revenue per transaction, and ransom laundering efficiency. Although it is relatively easy to identify choke points in commodity ransomware payment activity, it is more difficult to do the same for RaaS. ","authors":"Kris Oosthoek, Jack Cable, Georgios Smaragdakis","pdf":"http://arxiv.org/pdf/2205.05028v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.04678v1","published":"Tue, 10 May 2022 05:18:45 GMT","title":"Real-time Forecasting of Time Series in Financial Markets Using   Sequentially Trained Many-to-one LSTMs","summary":"  Financial markets are highly complex and volatile; thus, learning about such markets for the sake of making predictions is vital to make early alerts about crashes and subsequent recoveries. People have been using learning tools from diverse fields such as financial mathematics and machine learning in the attempt of making trustworthy predictions on such markets. However, the accuracy of such techniques had not been adequate until artificial neural network (ANN) frameworks were developed. Moreover, making accurate real-time predictions of financial time series is highly subjective to the ANN architecture in use and the procedure of training it. Long short-term memory (LSTM) is a member of the recurrent neural network family which has been widely utilized for time series predictions. Especially, we train two LSTMs with a known length, say $T$ time steps, of previous data and predict only one time step ahead. At each iteration, while one LSTM is employed to find the best number of epochs, the second LSTM is trained only for the best number of epochs to make predictions. We treat the current prediction as in the training set for the next prediction and train the same LSTM. While classic ways of training result in more error when the predictions are made further away in the test period, our approach is capable of maintaining a superior accuracy as training increases when it proceeds through the testing period. The forecasting accuracy of our approach is validated using three time series from each of the three diverse financial markets: stock, cryptocurrency, and commodity. The results are compared with those of an extended Kalman filter, an autoregressive model, and an autoregressive integrated moving average model. ","comment":"20 pages, 7 figures, submitted to Expert Systems with Applications   Journal","authors":"Kelum Gajamannage, Yonggi Park","pdf":"http://arxiv.org/pdf/2205.04678v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.04646v1","published":"Tue, 10 May 2022 03:24:32 GMT","title":"Crypto Pump and Dump Detection via Deep Learning Techniques","summary":"  Despite the fact that cryptocurrencies themselves have experienced an astonishing rate of adoption over the last decade, cryptocurrency fraud detection is a heavily under-researched problem area. Of all fraudulent activity regarding cryptocurrencies, pump and dump schemes are some of the most common. Though some studies have been done on these kinds of scams in the stock market, the lack of labelled stock data and the volatility unique to the cryptocurrency space constrains the applicability of studies on the stock market toward this problem domain. Furthermore, the only work done in this space thus far has been either statistical in nature, or has been concerned with classical machine learning models such as random forest trees. We propose the novel application of two existing neural network architectures to this problem domain and show that deep learning solutions can significantly outperform all other existing pump and dump detection methods for cryptocurrencies. ","comment":"8 pages, 4 figures","authors":"Viswanath Chadalapaka, Kyle Chang, Gireesh Mahajan, Anuj Vasil","pdf":"http://arxiv.org/pdf/2205.04646v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.04290v2","published":"Mon, 09 May 2022 13:58:56 GMT","title":"Timing Matters: Bitcoin Returns, Public Attention to COVID-19, and   Individualism","summary":"  The pandemic evolution and people's concern over it have an impact on the Bitcoin market, while the extent of individualism differentiates how individuals respond to preventive measures and how investors behave on the financial market during the pandemic. This paper examines if public attention to COVID-19 in individualistic vs. collectivistic countries Granger causes Bitcoin returns between February 11, 2020 and May 09, 2022. In particular, from a time-varying perspective, it accounts for variations in the timing of COVID-19 issues across countries and circumvents the potential estimation bias that a Granger causality test could suffer, due largely to Google's sampling variation for different time frames. By comparing eight typically individualistic and collectivistic countries, the results show that collectivistic countries present a stronger pattern of causal relationships with Bitcoin returns than individualistic countries. ","comment":"17 pages, 16 figures, 1 table","authors":"Huaxin Wang-Lu","pdf":"http://arxiv.org/pdf/2205.04290v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.04256v1","published":"Mon, 09 May 2022 13:16:22 GMT","title":"SoK: Blockchain Decentralization","summary":"  Blockchain empowers a decentralized economy by enabling distributed trust in a peer-to-peer network. However, surprisingly, a widely accepted definition or measurement of decentralization is still lacking. We explore a systematization of knowledge (SoK) on blockchain decentralization by reviewing existing studies on various aspects of blockchain decentralization. First, we establish a taxonomy for analyzing blockchain decentralization in the five facets of consensus, network, governance, wealth, and transaction. We find a lack of research on the transaction aspects that closely characterize user behavior. Second, we apply Shannon entropy in information theory to propose a decentralization index for blockchain transactions. We show that our index intuitively measures levels of decentralization in peer-to-peer transactions by simulating blockchain token transfers. Third, we apply our index to empirically analyze the dynamics of DeFi token transfers. Intertemporally, we observe that levels of decentralization converge regardless of the initial levels of decentralization. Comparison of DeFi applications shows that exchange and lending are more decentralized than payment and derivatives. We also discover that a greater return of ether, the native coin of the Ethereum blockchain, predicts a greater decentralization level in stablecoin transfer that includes ether as collateral. Finally, we develop future research directions to explore the interactions between different facets of blockchain decentralization, the design of blockchain mechanisms that achieve sustainable decentralization, and the interplay of decentralization levels and economic factors. ","authors":"Luyao Zhang, Xinshi Ma, Yulin Liu","pdf":"http://arxiv.org/pdf/2205.04256v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.04108v1","published":"Mon, 09 May 2022 08:19:35 GMT","title":"On the Storage Overhead of Proof-of-Work Blockchains","summary":"  Permissionless blockchains such as Bitcoin have long been criticized for their high computational and storage overhead. Unfortunately, while a number of proposals address the energy consumption of existing Proof-of-Work deployments, little attention has been given so far to remedy the storage overhead incurred by those blockchains. In fact, it seems widely acceptable that full nodes supporting the blockchains have to volunteer hundreds of GBs of their storage, to store and verify all transactions exchanged in the system. In this paper, we explore the solution space to effectively reduce the storage footprint of Proof-of-Work based blockchains. To do so, we analyze, by means of thorough empirical measurements, how existing full blockchain nodes utilize data from the shared ledger to validate incoming transactions/blocks. Based on this analysis, we show that it is possible for full nodes to locally reduce their storage footprint to approximately 15 GB, without any modification to the underlying protocol. We also discuss other client-side strategies to further reduce the storage footprint while incurring negligible computational overhead on the nodes. ","authors":"Alessandro Sforzin, Matteo Maso, Claudio Soriente, Ghassan Karame","pdf":"http://arxiv.org/pdf/2205.04108v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.03259v1","published":"Fri, 06 May 2022 14:31:18 GMT","title":"Decentralized Digital Currency System using Merkle Hash Trees","summary":"  In India, post the demonetization exercise in 2016, digital payments have become extremely popular. Among them, the volume of transactions using Paytm wallets and UPI (Unified Payment Interface) have grown manifold. The lockdowns due to COVID-19 Pandemic have furthered this trend. Side by side, crypto-currencies such as bitcoin are also gaining traction. Many countries are considering issuing a Digital Currency via their Central Banks. In this paper, we propose a novel Decentralized Digital Currency System (DDCS) that makes use of Merkle Hash-Trees as Authenticated Data Structures. DDCS uses a Ledger-less, distributed, peer-to-peer architecture. We name the proposed currency $\\\\delta$-Money. $\\\\delta$-Money is intended as a replacement for physical currency and has in-built security features that rival crypto-currencies. Transactions using $\\\\delta$-Money happen in a disintermediated manner but with post-facto reconciliation. In place of Central Bank-issued Digital Currency (CBDC), we envisage a scenario where multiple Payment Banks issue digital currencies that have stable valuations without being subject to either volatility or perennial devaluation. ","comment":"37 pages, 9 Figures, 8 Tables, submitted to Journal of Banking and   Financial Technology","authors":"Shreekanth M Prabhu, Natarajan Subramanyam, Ms. Shreya P Krishnan, Ms. Brindavana Sachidananda","pdf":"http://arxiv.org/pdf/2205.03259v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.02348v1","published":"Wed, 04 May 2022 22:45:33 GMT","title":"Secure Decentralized Online Gaming with Lending Functionalities","summary":"  We present a decentralized online gaming platform implemented as a Decentralized Application (DApp) on the Ethereum blockchain. The gaming platform enables secure gaming, where the account balances and the stakes of the players are secured by a smart contract. Moreover, the fair enforcement of the game rules and the deposit of the winnings of the players and the gaming platform into their accounts are guaranteed by the smart contract. The gaming platform proposes lending functionalities that allow players to securely borrow tokens from the gaming platform in order to participate in the games. ","comment":"6 pages, 6 figures, BCCA conference 2022","authors":"Katharina Alefs, Florian Hartl, Luke Newman, Banu Ozdeveci, Wisnu Uriawan","pdf":"http://arxiv.org/pdf/2205.02348v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.01797v1","published":"Tue, 03 May 2022 21:48:04 GMT","title":"Coded Transaction Broadcasting for High-throughput Blockchains","summary":"  High-throughput blockchains require efficient transaction broadcast mechanisms that can deliver transactions to most network nodes with low bandwidth overhead and latency. Existing schemes coordinate transmissions across peers to avoid sending redundant data, but they either incur a high latency or are not robust against adversarial network nodes. We present Strokkur, a new transaction broadcasting mechanism that provides both low bandwidth overhead and low latency. The core idea behind Strokkur is to avoid explicit coordination through randomized transaction coding. Rather than forward individual transactions. Strokkur nodes send out codewords -- XOR sums of multiple transactions selected at random. Since almost every codeword is useful for the receiver to decode new transactions, Strokkur nodes do not require coordination, for example, to determine which transactions the receiver is missing. Strokkur's coding strategy builds on LT codes, a popular class of rateless erasure codes, and extends them to support multiple uncoordinated senders with partially-overlapping continual streams of transaction data. Strokkur introduces mechanisms to cope with adversarial senders that may send corrupt codewords, and a simple rate control algorithm that enables each node to independently determine an appropriate sending rate of codewords for each peer. Our implementation of Strokkur in Golang supports 647k transactions per second using only one CPU core. Our evaluation across a 19-node Internet deployment and large-scale simulation show that Strokkur consumes 2--7.6x less bandwidth than the existing scheme in Bitcoin, and 9x lower latency that Shrec when only 4% of nodes are adversarial. ","authors":"Lei Yang, Yossi Gilad, Mohammad Alizadeh","pdf":"http://arxiv.org/pdf/2205.01797v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.01646v1","published":"Tue, 03 May 2022 17:13:17 GMT","title":"Implementation of an efficient, portable and platform-agnostic   cryptocurrency mining algorithm for Internet of Things devices","summary":"  Recently, there has been a remarkable amount of research being done in both, the fields of Blockchain and Internet of Things (IoT). Blockchain technology synergises well with IoT, solving key problems such as privacy, concerns with interoperability and security. However, the consensus mechanisms that allows trustless parties to maintain an agreement, the same algorithms that underpins cryptocurrency mining, are usually extremely computationally expensive, making implementation on low-power IoT devices difficult. More importantly, mining requires downloading and synchronizing hundred of gigabytes worth of blocks which is far beyond the capabilities of most IoT devices. In this paper, we present an efficient, portable and platform-agnostic cryptocurrency mining algorithm using the Stratum protocol to avoid downloading the entire blockchain. We implement the algorithm in four different platforms- PC, ESP32, an emulator and an old PlayStation Portable (PSP) to demonstrate that it is indeed possible for any device to mine cryptocurrencies with no assumptions except the ability to connect to the internet. To make sure of ease of portability on any platform and for reproducibility of the reported results we make the implementation publicly available with detailed instructions at: https://anonymous.4open.science/r/cryptominer. ","comment":"10 pages, 9 figures, 4 tables. Submitted to Array, Elsevier","authors":"Kinshuk Dua","pdf":"http://arxiv.org/pdf/2205.01646v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.00869v1","published":"Mon, 02 May 2022 12:53:09 GMT","title":"Topology Analysis of the XRP Network","summary":"  XRP is one of the oldest, well-established cryptocurrencies. Despite the popularity of XRP, little is known about its underlying peer-to-peer network. The structural properties of a network impact its efficiency, security and robustness. We aim to close the knowledge gap by providing a detailed analysis of the XRP overlay network.   In this paper we examine the graph-theoretic properties of the XRP Network topology and its temporal characteristics. We crawl the XRP Network over two months and collect 1,300 unique network snapshots. We uncover a small group of nodes that act as a networking backbone. In addition, we observe a high network churn, with a third of the nodes changing every five days. Our findings have strong implications for the resilience and safety of the XRP Ledger. ","comment":"6 pages, 6 figures, Submitted to IEEE Global Communications   Conference (GLOBECOM) 2022","authors":"Vytautas Tumas, Sean Rivera, Damien Magoni, Radu State","pdf":"http://arxiv.org/pdf/2205.00869v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.00745v1","published":"Mon, 02 May 2022 08:51:19 GMT","title":"Bitcoin P2P Network Measurements: A testbed study of the effect of peer   selection on transaction propagation and confirmation times","summary":"  Bitcoin is the first and the most extensive decentralized electronic cryptocurrency system that uses blockchain technology. It uses a peer-to-peer (P2P) network to operate without a central authority and propagate system information such as transactions or blockchain updates. The communication between participating nodes is highly relying on the underlying network infrastructure to facilitate a platform. Understanding the impact of peer formation strategies, peer list, and delay are vital on understanding node to node communication. To this aim, we performed an extensive study on the transaction characteristic of Bitcoin through a Testbed. The analysis shows that peer selection strategies affect the transactions propagation and confirmation time. Moreover, the default distance-based peer selection strategy in Bitcoin performs less when there is high arrival intensity and creates high number forks. ","authors":"Befekadu G. Gebraselase, Bjarne E. Helvik, Yuming Jiang","pdf":"http://arxiv.org/pdf/2205.00745v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.00586v2","published":"Mon, 02 May 2022 00:11:39 GMT","title":"Fitting Generalized Tempered Stable distribution: Fractional Fourier   Transform (FRFT) Approach","summary":"  The paper investigates the rich class of Generalized Tempered Stable distribution, an alternative to Normal distribution and the $\\\\alpha$-Stable distribution for modelling asset return and many physical and economic systems. Firstly, we explore some important properties of the Generalized Tempered Stable (GTS) distribution. The theoretical tools developed are used to perform empirical analysis. The GTS distribution is fitted using S&P 500, SPY ETF and Bitcoin BTC. The Fractional Fourier Transform (FRFT) technique evaluates the probability density function and its derivatives in the maximum likelihood procedure. Based on the results from the statistical inference and the Kolmogorov-Smirnov (K-S) goodness-of-fit, the GTS distribution fits the underlying distribution of the SPY ETF return. The right side of the Bitcoin BTC return, and the left side of the S&P 500 return underlying distributions fit the Tempered Stable distribution; while the left side of the Bitcoin BTC return and the right side of the S&P 500 return underlying distributions are modelled by the compound Poisson process ","comment":"17 pages, 10 figures","authors":"A. H. Nzokem, V. T. Montshiwa","pdf":"http://arxiv.org/pdf/2205.00586v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.00384v1","published":"Sun, 01 May 2022 02:53:29 GMT","title":"Blockchain Applicability for the Internet of Things: Performance and   Scalability Challenges and Solutions","summary":"  Blockchain has recently been able to draw wider attention throughout the research community. Since its emergence, the world has seen the mind-blowing expansion of this new technology, which was initially developed as a pawn of digital currency more than a decade back. A self-administering ledger that ensures extensive data immutability over the peer-to-peer network has made it attractive for cybersecurity applications such as a sensor-enabled system called the Internet of things (IoT). Brand new challenges and questions now demand solutions as huge IoT devices are now online in a distributed fashion to ease our everyday lives. After being motivated by those challenges, the work here has figured out the issues and perspectives an IoT infrastructure can suffer because of the wrong choice of blockchain technology. Though it may look like a typical review, however, unlike that, this paper targets sorting out the specific security challenges of the blockchain-IoT eco-system through critical findings and applicable use-cases. Therefore, the contribution includes directing Blockchain architects, designers, and researchers in the broad domain to select the unblemished combinations of Blockchain-powered IoT applications. In addition, the paper promises to bring a deep insight into the state-of-the-art Blockchain platforms, namely Ethereum, Hyperledger, and IOTA, to exhibit the respective challenges, constraints, and prospects in terms of performance and scalability. ","comment":"22 pages, 11 Figures, 7 Tables","authors":"Ziaur Rahman, Xun Yi, Sk. Tanzir Mehedi, Rafiqul Islam, Andrei Kelarev","pdf":"http://arxiv.org/pdf/2205.00384v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.00383v1","published":"Sun, 01 May 2022 02:38:48 GMT","title":"Regulating stochastic clocks","summary":"  Stochastic clocks represent a class of time change methods for incorporating trading activity into continuous-time financial models, with the ability to deal with typical asymmetrical and tail risks in financial returns. In this paper we propose a significant improvement of stochastic clocks for the same objective but without decreasing the number of trades or changing the trading intensity. Our methodology targets any L\\\\'{e}vy subordinator, or more generally any process of nonnegative independent increments, and is based on various choices of regulating kernels motivated from repeated averaging. By way of a hyperparameter linked to the degree of regulation, arbitrarily large skewness and excess kurtosis of returns can be easily achieved. Generic-time Laplace transforms, characterizing triplets, and cumulants of the regulated clocks and subsequent mixed models are analyzed, serving purposes ranging from statistical estimation and option price calibration to simulation techniques. Under specified jump-diffusion processes and tempered stable processes, a robust moment-based estimation procedure with profile likelihood is employed for statistical estimation and a comprehensive empirical study involving S\\\\&P500 and Bitcoin daily returns is conducted to demonstrate a series of desirable effects of the proposed methods. ","comment":"52 pages","authors":"Zhe Fei, Weixuan Xia","pdf":"http://arxiv.org/pdf/2205.00383v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.00335v1","published":"Sat, 30 Apr 2022 19:46:14 GMT","title":"Evaluating the Impact of Bitcoin on International Asset Allocation using   Mean-Variance, Conditional Value-at-Risk (CVaR), and Markov Regime Switching   Approaches","summary":"  This paper aims to analyze the effect of Bitcoin on portfolio optimization using mean-variance, conditional value-at-risk (CVaR), and Markov regime switching approaches. I assessed each approach and developed the next based on the prior approach's weaknesses until I ended with a high level of confidence in the final approach. Though the results of mean-variance and CVaR frameworks indicate that Bitcoin improves the diversification of a well-diversified international portfolio, they assume that assets' returns are developed linearly and normally distributed. However, the Bitcoin return does not have both of these characteristics. Due to this, I developed a Markov regime switching approach to analyze the effect of Bitcoin on an international portfolio performance. The results show that there are two regimes based on the assets' returns: 1- bear state, where returns have low means and high volatility, 2- bull state, where returns have high means and low volatility. ","authors":"Mohammadreza Mahmoudi","pdf":"http://arxiv.org/pdf/2205.00335v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.00185v1","published":"Sat, 30 Apr 2022 07:17:16 GMT","title":"Protecting the Integrity of IoT Sensor Data and Firmware With A   Feather-Light Blockchain Infrastructure","summary":"  Smart cities deploy large numbers of sensors and collect a tremendous amount of data from them. For example, Advanced Metering Infrastructures (AMIs), which consist of physical meters that collect usage data about public utilities such as power and water, are an important building block in a smart city. In a typical sensor network, the measurement devices are connected through a computer network, which exposes them to cyber attacks. Furthermore, the data is centrally managed at the operator's servers, making it vulnerable to insider threats.   Our goal is to protect the integrity of data collected by large-scale sensor networks and the firmware in measurement devices from cyber attacks and insider threats. To this end, we first develop a comprehensive threat model for attacks against data and firmware integrity, which can target any of the stakeholders in the operation of the sensor network. Next, we use our threat model to analyze existing defense mechanisms, including signature checks, remote firmware attestation, anomaly detection, and blockchain-based secure logs. However, the large size of the Trusted Computing Base and a lack of scalability limit the applicability of these existing mechanisms. We propose the Feather-Light Blockchain Infrastructure (FLBI) framework to address these limitations. Our framework leverages a two-layer architecture and cryptographic threshold signature chains to support large networks of low-capacity devices such as meters and data aggregators. We have fully implemented the FLBI's end-to-end functionality on the Hyperledger Fabric and private Ethereum blockchain platforms. Our experiments show that the FLBI is able to support millions of end devices. ","authors":"Daniel Reijsbergen, Aung Maw, Sarad Venugopalan, Dianshi Yang, Tien Tuan Anh Dinh, Jianying Zhou","pdf":"http://arxiv.org/pdf/2205.00185v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.01091v1","published":"Fri, 29 Apr 2022 19:23:58 GMT","title":"Blockchain in a nutshell","summary":"  Blockchain enables a digital society where people can contribute, collaborate, and transact without having to second-guess trust and transparency. It is the technology behind the success of Bitcoin, Ethereum, and many disruptive applications and platforms that have positive impact in numerous sectors, including finance, education, health care, environment, transportation, and philanthropy, to name a few. This chapter provides a friendly description of essential concepts, mathematics, and algorithms that lay the foundation for blockchain technology. ","comment":"Pre-print. Book chapter (50 pages) in \\Handbook on Blockchain\\. Duc   A. Tran, My T. Thai, and Bhaskar Krishnamachari (eds). Springer Nature   Publisher, 2022","authors":"Duc A. Tran, Bhaskar Krishnamachari","pdf":"http://arxiv.org/pdf/2205.01091v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.13827v1","published":"Fri, 29 Apr 2022 00:11:39 GMT","title":"PRETRUST: A Framework for Fast Payments in Blockchain System","summary":"  Decentralized cryptocurrencies based on blockchains hold an advantage over the conventional methods in digital payments. However, many current decentralized cryptocurrencies based on blockchains cannot manage to satisfy the requests for fast payments. In fact, most time cost on blockchains is the time waiting for records to be verified. The efficiency of addressing transactions will be greatly improved if this part of the time can be saved. One motivation is to scale out the capacity by reducing interactions with the public chain while keeping its original structure, which is a mainstream strategy of improving efficiency. In the paper, we propose PRETRUST, a new framework to address the problem above. PRETRUST is based on consortium blockchains thoughts, supporting fast payments. In order to make parties address transactions and scale-out the capacity, the main strategy is based on the guarantee mechanism and shard technology with a random arrangement of transactions and consensus groups. In PRETRUST, the guarantee process replaces the verification of a transaction on-chain. And the model of a trusted execution environment is utilized in the interactions between PRETRUST and public systems. Throughout the paper, we discuss several transaction scenarios and analyze the security, which shows that PRETRUST can guarantee security. ","comment":"9 pages","authors":"Baocheng Wang, Huapeng Li","pdf":"http://arxiv.org/pdf/2204.13827v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.13459v2","published":"Thu, 28 Apr 2022 12:49:59 GMT","title":"Weighted Packet Selection for Rechargeable Links: Complexity and   Approximation","summary":"  We consider a natural problem dealing with weighted packet selection across a rechargeable link, which e.g., finds applications in cryptocurrency networks. The capacity of a link $(u,v)$ is determined by how much players $u$ and $v$ allocate for this link. Specifically, the input is a finite ordered sequence of packets that arrive in both directions along a link. Given $(u, v)$ and a packet of weight $x$ going from $u$ to $v$, player $u$ can either accept or reject the packet. If player $u$ accepts the packet, their capacity on link $(u,v)$ decreases by $x$. Correspondingly, player $v$ capacity on $(u,v)$ increases by $x$. If a player rejects the packet, this will entail a cost linear in the weight of the packet. A link is \\rechargeable\\ in the sense that the total capacity of the link has to remain constant, but the allocation of capacity at the ends of the link can depend arbitrarily on players' decisions. The goal is to minimise the sum of the capacity injected into the link and the cost of rejecting packets. We show the problem is NP-hard, but can be approximated efficiently with a ratio of $(1+ \\\\varepsilon)\\\\cdot (1+\\\\sqrt{3})$ for some arbitrary $\\\\varepsilon >0$. ","authors":"Stefan Schmid, Jakub Svoboda, Michelle Yeo","pdf":"http://arxiv.org/pdf/2204.13459v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.13442v1","published":"Thu, 28 Apr 2022 12:17:00 GMT","title":"TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum   Phishing Scams Detection","summary":"  In recent years, phishing scams have become the most serious type of crime involved in Ethereum, the second-largest blockchain platform. The existing phishing scams detection technology on Ethereum mostly uses traditional machine learning or network representation learning to mine the key information from the transaction network to identify phishing addresses. However, these methods adopt the last transaction record or even completely ignore these records, and only manual-designed features are taken for the node representation. In this paper, we propose a Temporal Transaction Aggregation Graph Network (TTAGN) to enhance phishing scams detection performance on Ethereum. Specifically, in the temporal edges representation module, we model the temporal relationship of historical transaction records between nodes to construct the edge representation of the Ethereum transaction network. Moreover, the edge representations around the node are aggregated to fuse topological interactive relationships into its representation, also named as trading features, in the edge2node module. We further combine trading features with common statistical and structural features obtained by graph neural networks to identify phishing addresses. Evaluated on real-world Ethereum phishing scams datasets, our TTAGN (92.8% AUC, and 81.6% F1score) outperforms the state-of-the-art methods, and the effectiveness of temporal edges representation and edge2node module is also demonstrated. ","comment":"WWW 2022","authors":"Sijia Li, Gaopeng Gou, Chang Liu, Chengshang Hou, Zhenzhen Li, Gang Xiong","pdf":"http://arxiv.org/pdf/2204.13442v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.00974v1","published":"Thu, 28 Apr 2022 02:39:42 GMT","title":"Cross Cryptocurrency Relationship Mining for Bitcoin Price Prediction","summary":"  Blockchain finance has become a part of the world financial system, most typically manifested in the attention to the price of Bitcoin. However, a great deal of work is still limited to using technical indicators to capture Bitcoin price fluctuation, with little consideration of historical relationships and interactions between related cryptocurrencies. In this work, we propose a generic Cross-Cryptocurrency Relationship Mining module, named C2RM, which can effectively capture the synchronous and asynchronous impact factors between Bitcoin and related Altcoins. Specifically, we utilize the Dynamic Time Warping algorithm to extract the lead-lag relationship, yielding Lead-lag Variance Kernel, which will be used for aggregating the information of Altcoins to form relational impact factors. Comprehensive experimental results demonstrate that our C2RM can help existing price prediction methods achieve significant performance improvement, suggesting the effectiveness of Cross-Cryptocurrency interactions on benefitting Bitcoin price prediction. ","comment":"14 pages, 4 figures","authors":"Panpan Li, Shengbo Gong, Shaocong Xu, Jiajun Zhou, Yu Shanqing, Qi Xuan","pdf":"http://arxiv.org/pdf/2205.00974v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.13253v1","published":"Thu, 28 Apr 2022 02:12:34 GMT","title":"Temporal Analysis of Transaction Ego Networks with Different Labels on   Ethereum","summary":"  Due to the widespread use of smart contracts, Ethereum has become the second-largest blockchain platform after Bitcoin. Many different types of Ethereum accounts (ICO, Mining, Gambling, etc.) also have quite active trading activities on Ethereum. Studying the transaction records of these specific Ethereum accounts is very important for understanding their particular transaction characteristics, and further labeling the pseudonymous accounts. However, traditional methods are generally based on static and global transaction networks to conduct research, ignoring useful information about dynamic changes. Our work chooses six kinds of important account labels, and builds ego networks for each kind of Ethereum account. We focus on the interaction between the target node and neighbor nodes with temporal analysis. Experiments show that there is a significant difference between various types of accounts in terms of several network features, helping us better understand their transaction patterns. To the best of our knowledge, this is the first work to analyze the dynamic characteristics of Ethereum labeled accounts from the perspective of transaction ego networks. ","authors":"Baoying Huang, Jieli Liu, Jiajing Wu, Quanzhong Li, Hao Lin","pdf":"http://arxiv.org/pdf/2204.13253v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.13102v1","published":"Wed, 27 Apr 2022 17:57:55 GMT","title":"The Price and Cost of Bitcoin","summary":"  Explaining changes in bitcoin's price and predicting its future have been the foci of many research studies. In contrast, far less attention has been paid to the relationship between bitcoin's mining costs and its price. One popular notion is the cost of bitcoin creation provides a support level below which this cryptocurrency's price should never fall because if it did, mining would become unprofitable and threaten the maintenance of bitcoin's public ledger. Other research has used mining costs to explain or forecast bitcoin's price movements. Competing econometric analyses have debunked this idea, showing that changes in mining costs follow changes in bitcoin's price rather than preceding them, but the reason for this behavior remains unexplained in these analyses. This research aims to employ economic theory to explain why econometric studies have failed to predict bitcoin prices and why mining costs follow movements in bitcoin prices rather than precede them. We do so by explaining the chain of causality connecting a bitcoin's price to its mining costs. ","comment":"18 pages, 3 tables, 5 figures Accepted by the Quarterly Review of   Economics and Finance","authors":"John E. Marthinsen, Steven R. Gordon","pdf":"http://arxiv.org/pdf/2204.13102v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.14232v1","published":"Wed, 27 Apr 2022 14:43:42 GMT","title":"Panoptic: a perpetual, oracle-free options protocol","summary":"  Panoptic is a perpetual, oracle-free, instant-settlement options trading protocol on the Ethereum blockchain. Panoptic enables the permissionless trading of options on top of any asset pool in the Uniswap v3 ecosystem and seeks to develop a trustless, permissionless, and composable options product, i.e., do for decentralized options markets what x*y=k automated market maker protocols did for spot trading. ","authors":"Guillaume Lambert, Jesper Kristensen","pdf":"http://arxiv.org/pdf/2204.14232v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.12806v1","published":"Wed, 27 Apr 2022 09:48:35 GMT","title":"Quantum Prudent Contracts with Applications to Bitcoin","summary":"  Smart contracts are cryptographic protocols that are enforced without a judiciary. Smart contracts are used occasionally in Bitcoin and are prevalent in Ethereum. Public quantum money improves upon cash we use today, yet the current constructions do not enable smart contracts. In this work, we define and introduce quantum payment schemes, and show how to implement prudent contracts -- a non-trivial subset of the functionality that a network such as Ethereum provides. Examples discussed include: multi-signature wallets in which funds can be spent by any 2-out-of-3 owners; restricted accounts that can send funds only to designated destinations; and \\colored coins\\ that can represent stocks that can be freely traded, and their owner would receive dividends. Our approach is not as universal as the one used in Ethereum since we do not reach a consensus regarding the state of a ledger. We call our proposal prudent contracts to reflect this. The main building block is either quantum tokens for digital signatures (Ben-David and Sattath QCrypt'17, Coladangelo et al. Crypto'21), semi-quantum tokens for digital signatures (Shmueli'22) or one-shot signatures (Amos et al. STOC'20). The solution has all the benefits of public quantum money: no mining is necessary, and the security model is standard (e.g., it is not susceptible to 51\\\\% attacks, as in Bitcoin). Our one-shot signature construction can be used to upgrade the Bitcoin network to a quantum payment scheme. Notable advantages of this approach are: transactions are locally verifiable and without latency, the throughput is unbounded, and most importantly, it would remove the need for Bitcoin mining. Our approach requires a universal large-scale quantum computer and long-term quantum memory; hence we do not expect it to be implementable in the next few years. ","authors":"Or Sattath","pdf":"http://arxiv.org/pdf/2204.12806v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.12547v1","published":"Tue, 26 Apr 2022 19:07:15 GMT","title":"Design, Implementation, and Evaluation of Blockchain-Based Trusted   Achievement Record System for Students in Higher Education","summary":"  With a growing number of institutions involved in the global education market, it has become increasingly challenging to verify the authenticity of academic achievements such as CVs and diplomas. Blockchain is an enabling technology that can play a key role in solving this problem. This study introduces a blockchain-based achievement record system that produces a verifiable record of achievements. The proposed system aims to facilitate the process of authentication and validation of certificates reliably, easily, and quickly, leveraging the unique capabilities offered through Blockchain technology (public Ethereum Blockchain) and smart contracts. We present the design and implementation of the system and its components and tools. We then evaluate the system through a number of studies to measure the system's usability, effectiveness, performance, and cost. A System Usability Scale (SUS) test gave a scale of 77.1. Through a literature survey, we demonstrate that this system is a significant improvement on legacy systems, being both more user-friendly and more efficient. We also conduct a detailed cost analysis and discuss the positives and limitations of alternative blockchain solutions. ","authors":"Bakri Awaji, Ellis Solaiman","pdf":"http://arxiv.org/pdf/2204.12547v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.11193v1","published":"Sun, 24 Apr 2022 05:15:14 GMT","title":"Exploring Security Practices of Smart Contract Developers","summary":"  Smart contracts are self-executing programs that run on blockchains (e.g., Ethereum). 680 million US dollars worth of digital assets controlled by smart contracts have been hacked or stolen due to various security vulnerabilities in 2021. Although security is a fundamental concern for smart contracts, it is unclear how smart contract developers approach security. To help fill this research gap, we conducted an exploratory qualitative study consisting of a semi-structured interview and a code review task with 29 smart contract developers with diverse backgrounds, including 10 early stage (less than one year of experience) and 19 experienced (2-5 years of experience) smart contract developers.   Our findings show a wide range of smart contract security perceptions and practices including various tools and resources they used. Our early-stage developer participants had a much lower success rate (15%) of identifying security vulnerabilities in the code review task than their experienced counterparts (55%). Our hierarchical task analysis of their code reviews implies that just by accessing standard documentation, reference implementations and security tools is not sufficient. Many developers checked those materials or used a security tool but still failed to identify the security issues. In addition, several participants pointed out shortcomings of current smart contract security tooling such as its usability. We discuss how future education and tools could better support developers in ensuring smart contract security. ","authors":"Tanusree Sharma, Zhixuan Zhou, Andrew Miller, Yang Wang","pdf":"http://arxiv.org/pdf/2204.11193v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.11107v2","published":"Sat, 23 Apr 2022 17:00:21 GMT","title":"Debt-Financed Collateral and Stability Risks in the DeFi Ecosystem","summary":"  The rise of Decentralized Finance (\\DeFi\\) on the Ethereum blockchain has enabled the creation of lending platforms, which serve as marketplaces to lend and borrow digital currencies. We first categorize the activity of lending platforms within a standard regulatory framework. We then employ a novel grouping and classification algorithm to calculate the percentage of fund flows into DeFi lending platforms that can be attributed to debt created elsewhere in the system (\\debt-financed collateral\\). Based on our results, we conclude that the wide-spread use of stablecoins as debt-financed collateral increases financial stability risks in the DeFi ecosystem. ","authors":"Michael Darlin, Georgios Palaiokrassas, Leandros Tassiulas","pdf":"http://arxiv.org/pdf/2204.11107v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.10643v2","published":"Fri, 22 Apr 2022 11:26:16 GMT","title":"Quantum Proof of Work with Parametrized Quantum Circuits","summary":"  Despite all the progress in quantum technologies over the last decade, there is still a dearth of practical applications for quantum computers with a small number of noisy qubits. The effort to show quantum supremacy has been largely focused on demonstrating computations that cannot be accomplished on a classical computer at all, a difficult and controversial target. Quantum advantage (a speedup over classical computers) is a more practical milestone for today's modest quantum processors. In this work, we proposed a scheme for quantum-computer compatible proof of work (cryptographic mechanism used in Bitcoin mining) and verified it on a 4-qubit superconducting quantum node. ","comment":"6 pages, 3 figures, 1 table","authors":"Mikhail Y. Shalaginov, Michael Dubrovsky","pdf":"http://arxiv.org/pdf/2204.10643v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.10857v1","published":"Fri, 22 Apr 2022 10:55:44 GMT","title":"Blockchain and Cryptocurrency in Human Computer Interaction: A   Systematic Literature Review and Research Agenda","summary":"  We present a systematic literature review of cryptocurrency and blockchain research in Human-Computer Interaction (HCI) published between 2014 and 2021. We aim to provide an overview of the field, consolidate existing knowledge, and chart paths for future research. Our analysis of 99 articles identifies six major themes: (1) the role of trust, (2) understanding motivation, risk, and perception of cryptocurrencies, (3) cryptocurrency wallets, (4) engaging users with blockchain, (5) using blockchain for application-specific use cases, and (6) support tools for blockchain. We discuss the focus of the existing research body and juxtapose it to the changing landscape of emerging blockchain technologies to highlight future research avenues for HCI and interaction design. With this review, we identify key aspects where interaction design is critical for the adoption of blockchain systems. Doing so, we provide a starting point for new scholars and designers and help them position future contributions. ","authors":"Michael Fröhlich, Franz Waltenberger, Ludwig Trotter, Florian Alt, Albrecht Schmidt","pdf":"http://arxiv.org/pdf/2204.10857v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.10611v1","published":"Fri, 22 Apr 2022 10:05:21 GMT","title":"Bridging Sapling: Private Cross-Chain Transfers","summary":"  Interoperability is one of the main challenges of blockchain technologies, which are generally designed as self-contained systems. Interoperability schemes for privacy-focused blockchains are particularly hard to design: they must integrate with the unique privacy features of the underlying blockchain so as to prove statements about specific transactions in protocols designed to obfuscate them. This has led to users being forced to weaken their privacy, e.g. by using centralised exchanges, to move assets from one chain to another. We present ZCLAIM, a framework for trustless cross-chain asset migration based on the Zcash privacy-protecting protocol. ZCLAIM integrates with an implementation of the Sapling version of Zcash on a smart-contract capable issuing chain in order to attain private cross-chain transfers. We show that a tokenised representation can be created via a set of collateralised intermediaries without relying on or revealing the total amount to any third party. ","comment":"8 pages, to be published in: IEEE International Conference on   Blockchain and Cryptocurrency, ICBC 2022","authors":"Aleixo Sanchez, Alistair Stewart, Fatemeh Shirazi","pdf":"http://arxiv.org/pdf/2204.10611v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.12929v1","published":"Thu, 21 Apr 2022 16:34:53 GMT","title":"Sequence-Based Target Coin Prediction for Cryptocurrency Pump-and-Dump","summary":"  As the pump-and-dump schemes (P&Ds) proliferate in the cryptocurrency market, it becomes imperative to detect such fraudulent activities in advance, to inform potentially susceptible investors before they become victims. In this paper, we focus on the target coin prediction task, i.e., to predict the pump probability of all coins listed in the target exchange before a pump. We conduct a comprehensive study of the latest P&Ds, investigate 709 events organized in Telegram channels from Jan. 2019 to Jan. 2022, and unearth some abnormal yet interesting patterns of P&Ds. Empirical analysis demonstrates that pumped coins exhibit intra-channel homogeneity and inter-channel heterogeneity, which inspires us to develop a novel sequence-based neural network named SNN. Specifically, SNN encodes each channel's pump history as a sequence representation via a positional attention mechanism, which filters useful information and alleviates the noise introduced when the sequence length is long. We also identify and address the coin-side cold-start problem in a practical setting. Extensive experiments show a lift of 1.6% AUC and 41.0% Hit Ratio@3 brought by our method, making it well-suited for real-world application. As a side contribution, we release the source code of our entire data science pipeline on GitHub, along with the dataset tailored for studying the latest P&Ds. ","comment":"9 pages","authors":"Sihao Hu, Zhen Zhang, Shengliang Lu, Bingsheng He, Zhao Li","pdf":"http://arxiv.org/pdf/2204.12929v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.09864v1","published":"Thu, 21 Apr 2022 03:40:47 GMT","title":"Using SGX for Meta-Transactions Support in Ethereum DApps","summary":"  Decentralized applications (DApps) gained traction in the context of the blockchain technology. Ethereum is currently the public blockchain that backs the largest amount of the existing DApps. Onboarding new users to Ethereum DApps is a notoriously hard issue to solve. This is mainly caused by lack of cryptocurrency ownership, needed for transaction fees. Several meta-transaction patterns emerged for decoupling users from paying these fees. However, such solutions are mostly offered via off-chain, often paid relayer services and do not fully address the security issues present in the meta-transaction path. In this paper, we introduce a new meta-transaction architecture that makes use of the Intel Software Guard Extensions (SGX). Unlike other solutions, our approach would offer the possibility to deploy a fee-free Ethereum DApp on a web server that can directly relay meta-transactions to the Ethereum network while having essential security guarantees integrated by design. ","comment":"Preprint of paper accepted at DAIS 2022 - 22nd IFIP International   Conference on Distributed Applications and Interoperable Systems","authors":"Emanuel Onica, Ciprian Amariei","pdf":"http://arxiv.org/pdf/2204.09864v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.09796v1","published":"Wed, 20 Apr 2022 21:53:42 GMT","title":"Distributed Runtime Verification of Metric Temporal Properties for   Cross-Chain Protocols","summary":"  Transactions involving multiple blockchains are implemented by cross-chain protocols. These protocols are based on smart contracts, programs that run on blockchains, executed by a network of computers. Because smart contracts can automatically transfer ownership of cryptocurrencies, electronic securities, and other valuable assets among untrusting parties, verifying the runtime correctness of smart contracts is a problem of compelling practical interest. Such verification is challenging since smart contract execution is time-sensitive, and the clocks on different blockchains may not be perfectly synchronized. This paper describes a method for runtime monitoring of blockchain executions. First, we propose a generalized runtime verification technique for verifying partially synchronous distributed computations for the metric temporal logic (MTL) by exploiting bounded-skew clock synchronization. Second, we introduce a progression-based formula rewriting scheme for monitoring \\\\MTL specifications which employ SMT solving techniques and report experimental results. ","comment":"2022 IEEE 42nd International Conference on Distributed Computing   Systems (ICDCS)","authors":"Ritam Ganguly, Yingjie Xue, Aaron Jonckheere, Parker Ljung, Benjamin Schornstein, Borzoo Bonakdarpour, Maurice Herlihy","pdf":"http://arxiv.org/pdf/2204.09796v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.09282v1","published":"Wed, 20 Apr 2022 07:55:06 GMT","title":"The Danger of Small Anonymity Sets in Privacy-Preserving Payment Systems","summary":"  Unlike suggested during their early years of existence, Bitcoin and similar cryptocurrencies in fact offer significantly less privacy as compared to traditional banking. A myriad of privacy-enhancing extensions to those cryptocurrencies as well as several clean-slate privacy-protecting cryptocurrencies have been proposed in turn. To convey a better understanding of the protection of popular design decisions, we investigate expected anonymity set sizes in an initial simulation study. The large variation of expected transaction values yields soberingly small effective anonymity sets for protocols that leak transaction values. We hence examine the effect of preliminary, intuitive strategies for merging groups of payments into larger anonymity sets, for instance by choosing from pre-specified value classes. The results hold promise, as they indeed induce larger anonymity sets at comparatively low cost, depending on the corresponding strategy ","authors":"Christiane Kuhn, Aniket Kate, Thorsten Strufe","pdf":"http://arxiv.org/pdf/2204.09282v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.08916v1","published":"Tue, 19 Apr 2022 14:27:23 GMT","title":"Heterogeneous Feature Augmentation for Ponzi Detection in Ethereum","summary":"  While blockchain technology triggers new industrial and technological revolutions, it also brings new challenges. Recently, a large number of new scams with a \\blockchain\\ sock-puppet continue to emerge, such as Ponzi schemes, money laundering, etc., seriously threatening financial security. Existing fraud detection methods in blockchain mainly concentrate on manual feature and graph analytics, which first construct a homogeneous transaction graph using partial blockchain data and then use graph analytics to detect anomaly, resulting in a loss of pattern information. In this paper, we mainly focus on Ponzi scheme detection and propose HFAug, a generic Heterogeneous Feature Augmentation module that can capture the heterogeneous information associated with account behavior patterns and can be combined with existing Ponzi detection methods. HFAug learns the metapath-based behavior characteristics in an auxiliary heterogeneous interaction graph, and aggregates the heterogeneous features to corresponding account nodes in the homogeneous one where the Ponzi detection methods are performed. Comprehensive experimental results demonstrate that our HFAug can help existing Ponzi detection methods achieve significant performance improvement on Ethereum datasets, suggesting the effectiveness of heterogeneous information on detecting Ponzi schemes. ","comment":"5 pages, 3 figures","authors":"Chengxiang Jin, Jie Jin, Jiajun Zhou, Jiajing Wu, Qi Xuan","pdf":"http://arxiv.org/pdf/2204.08916v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.08769v1","published":"Tue, 19 Apr 2022 09:34:40 GMT","title":"Bodyless Block Propagation: TPS Fully Scalable Blockchain with   Pre-Validation","summary":"  The fundamental tradeoff between transaction per second (TPS) and security in blockchain systems persists despite numerous prior attempts to boost TPS. To increase TPS without compromising security, we propose a bodyless block propagation (BBP) scheme for which the block body is not validated and transmitted during the block propagation process. Rather, the nodes in the blockchain network anticipate the transactions and their ordering in the next upcoming block so that these transactions can be pre-executed and pre-validated before the birth of the block. It is critical, however, all nodes have a consensus on the transaction content of the next block.   This paper puts forth a transaction selection, ordering, and synchronization algorithm to drive the nodes to reach such a consensus. Yet, the coinbase address of the miner of the next block cannot be anticipated, and therefore transactions that depend on the coinbase address cannot be pre-executed and pre-validated. This paper further puts forth an algorithm to deal with such unresolvable transactions for an overall consistent and TPS-efficient scheme. With our scheme, most transactions do not need to be validated and transmitted during block propagation, ridding the dependence of propagation time on the number of transactions in the block, and making the system fully TPS scalable. Experimental results show that our protocol can reduce propagation time by 4x with respect to the current Ethereum blockchain, and its TPS performance is limited by the node hardware performance rather than block propagation. ","authors":"Chonghe Zhao, Shengli Zhang, Taotao Wang, Soung Chang Liew","pdf":"http://arxiv.org/pdf/2204.08769v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.08664v1","published":"Tue, 19 Apr 2022 04:57:22 GMT","title":"Toward Understanding the Use of Centralized Exchanges for Decentralized   Cryptocurrency","summary":"  Cryptocurrency has been extensively studied as a decentralized financial technology built on blockchain. However, there is a lack of understanding of user experience with cryptocurrency exchanges, the main means for novice users to interact with cryptocurrency. We conduct a qualitative study to provide a panoramic view of user experience and security perception of exchanges. All 15 Chinese participants mainly use centralized exchanges (CEX) instead of decentralized exchanges (DEX) to trade decentralized cryptocurrency, which is paradoxical. A closer examination reveals that CEXes provide better usability and charge lower transaction fee than DEXes. Country-specific security perceptions are observed. Though DEXes provide better anonymity and privacy protection, and are free of governmental regulation, these are not necessary features for many participants. Based on the findings, we propose design implications to make cryptocurrency trading more decentralized. ","comment":"13th International Conference on Applied Human Factors and Ergonomics   (AHFE 2022)","authors":"Zhixuan Zhou, Bohui Shen","pdf":"http://arxiv.org/pdf/2204.08664v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.10185v1","published":"Tue, 19 Apr 2022 03:27:29 GMT","title":"Social Media Sentiment Analysis for Cryptocurrency Market Prediction","summary":"  In this paper, we explore the usability of different natural language processing models for the sentiment analysis of social media applied to financial market prediction, using the cryptocurrency domain as a reference. We study how the different sentiment metrics are correlated with the price movements of Bitcoin. For this purpose, we explore different methods to calculate the sentiment metrics from a text finding most of them not very accurate for this prediction task. We find that one of the models outperforms more than 20 other public ones and makes it possible to fine-tune it efficiently given its interpretable nature. Thus we confirm that interpretable artificial intelligence and natural language processing methods might be more valuable practically than non-explainable and non-interpretable ones. In the end, we analyse potential causal connections between the different sentiment metrics and the price movements. ","comment":"10 pages, 3 figures, submitted to Interpretable Natural Language   Processing Workshop of AGI-2022 Conference","authors":"Ali Raheman, Anton Kolonin, Igors Fridkins, Ikram Ansari, Mukul Vishwas","pdf":"http://arxiv.org/pdf/2204.10185v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.08194v1","published":"Mon, 18 Apr 2022 07:16:52 GMT","title":"Phishing Fraud Detection on Ethereum using Graph Neural Network","summary":"  Blockchain has widespread applications in the financial field but has also attracted increasing cybercrimes. Recently, phishing fraud has emerged as a major threat to blockchain security, calling for the development of effective regulatory strategies. Nowadays network science has been widely used in modeling Ethereum transaction data, further introducing the network representation learning technology to analyze the transaction patterns. In this paper, we consider phishing detection as a graph classification task and propose an end-to-end Phishing Detection Graph Neural Network framework (PDGNN). Specifically, we first construct a lightweight Ethereum transaction network and extract transaction subgraphs of collected phishing accounts. Then we propose an end-to-end detection model based on Chebyshev-GCN to precisely distinguish between normal and phishing accounts. Extensive experiments on five Ethereum datasets demonstrate that our PDGNN significantly outperforms general phishing detection methods and scales well in large transaction networks. ","comment":"14 pages, 5 figures","authors":"Panpan Li, Yunyi Xie, Xinyao Xu, Jiajun Zhou, Qi Xuan","pdf":"http://arxiv.org/pdf/2204.08194v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.08032v1","published":"Sun, 17 Apr 2022 15:36:35 GMT","title":"A Survey of Layer-Two Blockchain Protocols","summary":"  After the success of the Bitcoin blockchain, came several cryptocurrencies and blockchain solutions in the last decade. Nonetheless, Blockchain-based systems still suffer from low transaction rates and high transaction processing latencies, which hinder blockchains' scalability. An entire class of solutions, called Layer-1 scalability solutions, have attempted to incrementally improve such limitations by adding/modifying fundamental blockchain attributes. Recently, a completely different class of works, called Layer-2 protocols, have emerged to tackle the blockchain scalability issues using unconventional approaches. Layer-2 protocols improve transaction processing rates, periods, and fees by minimizing the use of underlying slow and costly blockchains. In fact, the main chain acts just as an instrument for trust establishment and dispute resolution among Layer-2 participants, where only a few transactions are dispatched to the main chain. Thus, Layer-2 blockchain protocols have the potential to transform the domain. However, rapid and discrete developments have resulted in diverse branches of Layer-2 protocols. In this work, we systematically create a broad taxonomy of such protocols and implementations. We discuss each Layer-2 protocol class in detail and also elucidate their respective approaches, salient features, requirements, etc. Moreover, we outline the issues related to these protocols along with a comparative discussion. Our thorough study will help further systematize the knowledge dispersed in the domain and help the readers to better understand the field of Layer-2 protocols. ","comment":"21 pages, 15 figures, 2 tables","authors":"Ankit Gangwal, Haripriya Ravali Gangavalli, Apoorva Thirupathi","pdf":"http://arxiv.org/pdf/2204.08032v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.06919v1","published":"Thu, 14 Apr 2022 12:24:22 GMT","title":"Proof of Federated Training: Accountable Cross-Network Model Training   and Inference","summary":"  Blockchain has widely been adopted to design accountable federated learning frameworks; however, the existing frameworks do not scale for distributed model training over multiple independent blockchain networks. For storing the pre-trained models over blockchain, current approaches primarily embed a model using its structural properties that are neither scalable for cross-chain exchange nor suitable for cross-chain verification. This paper proposes an architectural framework for cross-chain verifiable model training using federated learning, called Proof of Federated Training (PoFT), the first of its kind that enables a federated training procedure span across the clients over multiple blockchain networks. Instead of structural embedding, PoFT uses model parameters to embed the model over a blockchain and then applies a verifiable model exchange between two blockchain networks for cross-network model training. We implement and test PoFT over a large-scale setup using Amazon EC2 instances and observe that cross-chain training can significantly boosts up the model efficacy. In contrast, PoFT incurs marginal overhead for inter-chain model exchanges. ","comment":"Accepted at IEEE International Conference on Blockchain and   Cryptocurrency (ICBC 2022)","authors":"Sarthak Chakraborty, Sandip Chakraborty","pdf":"http://arxiv.org/pdf/2204.06919v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.05746v3","published":"Sun, 10 Apr 2022 06:46:51 GMT","title":"BABD: A Bitcoin Address Behavior Dataset for Pattern Analysis","summary":"  Cryptocurrencies are no longer just the preferred option for cybercriminal activities on darknets, due to the increasing adoption in mainstream applications. This is partly due to the transparency associated with the underpinning ledgers, where any individual can access the record of a transaction record on the public ledger. In this paper, we build a dataset comprising Bitcoin transactions between 12 July 2019 and 26 May 2021. This dataset (hereafter referred to as BABD-13) contains 13 types of Bitcoin addresses, 5 categories of indicators with 148 features, and 544,462 labeled data, which is the largest labeled Bitcoin address behavior dataset publicly available to our knowledge. We then use our proposed dataset on common machine learning models, namely: k-nearest neighbors algorithm, decision tree, random forest, multilayer perceptron, and XGBoost. The results show that the accuracy rates of these machine learning models for the multi-classification task on our proposed dataset are between 93.24% and 97.13%. We also analyze the proposed features and their relationships from the experiments, and propose a k-hop subgraph generation algorithm to extract a k-hop subgraph from the entire Bitcoin transaction graph constructed by the directed heterogeneous multigraph starting from a specific Bitcoin address node (e.g., a known transaction associated with a criminal investigation). Besides, we initially analyze the behavior patterns of different types of Bitcoin addresses according to the extracted features. ","comment":"14 pages, 4 figures","authors":"Yuexin Xiang, Yuchen Lei, Ding Bao, Wei Ren, Tiantian Li, Qingqing Yang, Wenmao Liu, Tianqing Zhu, Kim-Kwang Raymond Choo","pdf":"http://arxiv.org/pdf/2204.05746v3","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.04272v1","published":"Fri, 08 Apr 2022 19:54:43 GMT","title":"Matrix Syncer -- A Multi-chain Data Aggregator For Supporting   Blockchain-based Metaverses","summary":"  Due to the rising complexity of the metaverse's business logic and the low-latency nature of the metaverse, developers typically encounter the challenge of effectively reading, writing, and retrieving historical on-chain data in order to facilitate their functional implementations at scale. While it is true that accessing blockchain states is simple, more advanced real-world operations such as search, aggregation, and conditional filtering are not available when interacting directly with blockchain networks, particularly when dealing with requirements for on-chain event reflection. We offer Matrix Syncer, the ultimate middleware that bridges the data access gap between blockchains and end-user applications. Matrix Syncer is designed to facilitate the consolidation of on-chain information into a distributed data warehouse while also enabling customized on-chain state transformation for a scalable storage, access, and retrieval. It offers a unified layer for both on- and off-chain state, as well as a fast and flexible atomic query. Matrix Syncer is easily incorporated into any infrastructure to aggregate data from various blockchains concurrently, such as Ethereum and Flow. The system has been deployed to support several metaverse projects with a total value of more than $15 million USD. ","authors":"Xinyao Sun, Yi Lu, Jinghan Sun, Bohao Tang, Kyle D. Rehak, Shuyi Zhang","pdf":"http://arxiv.org/pdf/2204.04272v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.03552v1","published":"Thu, 07 Apr 2022 16:23:57 GMT","title":"On the Correctness of Speculative Consensus","summary":"  The introduction of Bitcoin fueled the development of blockchain-based resilient data management systems that are resilient against failures, enable federated data management, and can support data provenance. The key factor determining the performance of such resilient data management systems is the consensus protocol used by the system to replicate client transactions among all participants. Unfortunately, existing high-throughput consensus protocols are costly and impose significant latencies on transaction processing, which rules out their usage in responsive high-performance data management systems.   In this work, we improve on this situation by introducing the Proof-of-Execution consensus protocol (PoE), a consensus protocol designed for high-performance low-latency resilient data management. PoE introduces speculative execution, which minimizes latencies by starting execution before consensus is reached, and PoE introduces proof-of-executions to guarantee successful execution to clients. Furthermore, PoE introduces a single-round check-commit protocol to reduce the overall communication costs of consensus. Hence, we believe that PoE is a promising step towards flexible general-purpose low-latency resilient data management systems. ","comment":"An extended abstract of this work appeared at the 24th International   Conference on Extending Database Technology (EDBT 2021), see also   arXiv:1911.00838","authors":"Jelle Hellings, Suyash Gupta, Sajjad Rahnama, Mohammad Sadoghi","pdf":"http://arxiv.org/pdf/2204.03552v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.06766v1","published":"Thu, 07 Apr 2022 11:00:35 GMT","title":"Variants in managing supply chains on distributed ledgers","summary":"  Smart contracts show a high potential for ensuring that Supply Chain Management strategies make a qualitative leap toward higher levels of optimality, not only in terms of efficiency and profitability but also in the aggregation of skills aimed at creating the best products and services to bring to the market. In this article, we illustrate an architecture that employs smart contracts to implement various algorithmic versions of the Income Sharing principle between companies participating in a supply chain. We implement our approach on Hyperledger Fabric, the most widespread platform for private and consortium distributed ledgers, and discuss its suitability to our purposes by comparing this design choice with the alternative given by public blockchains, with particular attention to Ethereum. ","comment":"33 pages, 9 figures, 1 listing, extended version from BRAIN 2021","authors":"Paolo Bottoni, Claudio Di Ciccio, Remo Pareschi, Nicola Gessa, Gilda Massa","pdf":"http://arxiv.org/pdf/2205.06766v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.02757v1","published":"Wed, 06 Apr 2022 12:02:15 GMT","title":"Does non-linear factorization of financial returns help build better and   stabler portfolios?","summary":"  A portfolio allocation method based on linear and non-linear latent constrained conditional factors is presented. The factor loadings are constrained to always be positive in order to obtain long-only portfolios, which is not guaranteed by classical factor analysis or PCA. In addition, the factors are to be uncorrelated among clusters in order to build long-only portfolios. Our approach is based on modern machine learning tools: convex Non-negative Matrix Factorization (NMF) and autoencoder neural networks, designed in a specific manner to enforce the learning of useful hidden data structure such as correlation between the assets' returns. Our technique finds lowly correlated linear and non-linear conditional latent factors which are used to build outperforming global portfolios consisting of cryptocurrencies and traditional assets, similar to hierarchical clustering method. We study the dynamics of the derived non-linear factors in order to forecast tail losses of the portfolios and thus build more stable ones. ","authors":"Bruno Spilak, Wolfgang Karl Härdle","pdf":"http://arxiv.org/pdf/2204.02757v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.05781v1","published":"Wed, 06 Apr 2022 07:45:05 GMT","title":"Cryptocurrency Return Prediction Using Investor Sentiment Extracted by   BERT-Based Classifiers from News Articles, Reddit Posts and Tweets","summary":"  This paper studies the extent at which investor sentiment contributes to cryptocurrency return prediction. Investor sentiment is extracted from news articles, Reddit posts and Tweets using BERT-based classifiers fine-tuned on this specific text data. As this data is unlabeled, a weak supervision approach by pseudo-labeling using a zero-shot classifier is used. Contribution of sentiment is then examined using a variety of machine learning models. Each model is trained on data with and without sentiment separately. The conclusion is that sentiment leads to higher prediction accuracy and additional investment profit when the models are analyzed collectively, although this does not hold true for every single model. ","comment":"36 pages core text, 49 pages including Appendix","authors":"Duygu Ider","pdf":"http://arxiv.org/pdf/2204.05781v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.02461v2","published":"Tue, 05 Apr 2022 19:35:52 GMT","title":"Less is More: Fairness in Wide-Area Proof-of-Work Blockchain Networks","summary":"  Blockchain is rapidly emerging as an important class of network application, with a unique set of trust, security and transparency properties. In a blockchain system, participants record and update the `server-side' state of an application as blocks of a replicated, immutable ledger using a consensus protocol over the Internet. Mining blocks has become lucrative in recent years; e.g., a miner receives over USD 200,000 per mined block in Bitcoin today. A key factor affecting mining rewards, is the latency of broadcasting blocks over the network. In this paper, we consider the problem of topology design for optimizing mining rewards in a wide-area blockchain network that uses a Proof-of-Work protocol for consensus. Contrary to general wisdom that a faster network is always better for miners, we show a counter intuitive result where a slower network is actually beneficial to some miners. This is because competing miners must choose neighbors that not only decrease their own latency to others, but also ensure that the latency between other miners do not decrease because of itself. We formalize this problem, and provide both theoretical analysis and experimental results to support our claim. ","authors":"Yifan Mao, Shaileshh Bojja Venkatakrishnan","pdf":"http://arxiv.org/pdf/2204.02461v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.02019v1","published":"Tue, 05 Apr 2022 06:49:58 GMT","title":"Mixing detection on Bitcoin transactions using statistical patterns","summary":"  Cryptocurrencies gained lots of attention mainly because of the anonymous way of online payment, which they suggested. Meanwhile, Bitcoin and other major cryptocurrencies have experienced severe deanonymization attacks. To address these attacks, Bitcoin contributors introduced services called mixers or tumblers. Mixing or laundry services aim to return anonymity back to the network. In this research, we tackle the problem of losing the footprint of money in Bitcoin and other cryptocurrencies networks caused by the usage of mixing services. We devise methods to track transactions and addresses of these services and the addresses of dirty and cleaned money. Because of the lack of labeled data, we had to transact with these services and prepare labeled data. Using this data, we found reliable patterns and developed an integrated algorithm to detect mixing transactions, mixing addresses, sender addresses, and receiver addresses in the Bitcoin network. ","authors":"Ardeshir Shojaeenasab, Amir Pasha Motamed, Behnam Bahrak","pdf":"http://arxiv.org/pdf/2204.02019v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.01535v1","published":"Mon, 04 Apr 2022 14:44:04 GMT","title":"Retail Central Bank Digital Currencies (CBDC), Disintermediation and   Financial Privacy: The Case of the Bahamian Sand Dollar","summary":"  The fast-growing, market-driven demand for cryptocurrencies worries central banks, as their monetary policy could be completely undermined. Central bank digital currencies (CBDCs) could offer a solution, yet our understanding of their design and consequences is in its infancy. This non-technical paper examines how The Bahamas has designed the Sand Dollar, the first real-world instance of a retail CBDC. It contrasts the Sand Dollar with definition-based specifications. I then develop a scenario analysis to illustrate commercial bank risks. In this process, the central bank becomes a deposit monopolist, leading to high funding risks, disintermediation risks, and solvency risks for the com-mercial banking sector. I argue that restrictions and caps will be the new specifications of a regulatory framework for CBDCs if disintermediation in the banking sector is to be prevented. I identify the anonymity of CBDCs as a comparative disadvantage that will affect their adoption. These findings provide insight into governance problems facing central banks, and coherently lead to the design of the Sand Dollar. I conclude by suggesting that combating cryptocurrencies is a task that cannot be solved by a CBDC. ","comment":"30 pages, 5 figures, 2 tables","authors":"Kilian Wenker","pdf":"http://arxiv.org/pdf/2204.01535v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.01176v1","published":"Sun, 03 Apr 2022 22:58:01 GMT","title":"Analyzing Voting Power in Decentralized Governance: Who controls DAOs?","summary":"  We empirically study the state of three prominent DAO governance systems on the Ethereum blockchain: Compound, Uniswap and ENS. In particular, we examine how the voting power is distributed in these systems. Using a comprehensive dataset of all governance token holders, delegates, proposals and votes, we analyze who holds the voting rights and how they are used to influence governance decisions. ","authors":"Robin Fritsch, Marino Müller, Roger Wattenhofer","pdf":"http://arxiv.org/pdf/2204.01176v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.00979v1","published":"Sun, 03 Apr 2022 03:39:07 GMT","title":"Breaking Blockchain's Communication Barrier with Coded Computation","summary":"  Although blockchain, the supporting technology of various cryptocurrencies, has offered a potentially effective framework for numerous decentralized trust management systems, its performance is still sub-optimal in real-world networks. With limited bandwidth, the communication complexity for nodes to process a block scales with the growing network size and hence becomes the limiting factor of blockchain's performance.   In this paper, we suggest a re-design of existing blockchain systems, which addresses the issue of the communication burden. First, by employing techniques from Coded Computation, our scheme guarantees correct verification of transactions while reducing the bit complexity dramatically such that it grows logarithmically with the number of nodes. Second, with the adoption of techniques from Information Dispersal and State Machine Replication, the system is resilient to Byzantine faults and achieves linear message complexity. Third, we propose a novel 2-dimensional sharding strategy, which inherently supports cross-shard transactions, alleviating the need for complicated communication protocols between shards, while keeping the computation and storage benefits of sharding. ","authors":"Canran Wang, Netanel Raviv","pdf":"http://arxiv.org/pdf/2204.00979v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.00955v1","published":"Sat, 02 Apr 2022 23:30:13 GMT","title":"FIRST: FrontrunnIng Resilient Smart ConTracts","summary":"  Owing to the meteoric rise in the usage of cryptocurrencies, there has been a widespread adaptation of traditional financial applications such as lending, borrowing, margin trading, and more, to the cryptocurrency realm. In some cases, the inherently transparent and unregulated nature of cryptocurrencies leads to attacks on users of these applications. One such attack is frontrunning, where a malicious entity leverages the knowledge of currently unprocessed financial transactions submitted by users and attempts to get its own transaction(s) executed ahead of the unprocessed ones. The consequences of this can be financial loss, inaccurate transactions, and even exposure to more attacks. We propose FIRST, a framework that prevents frontrunning attacks, and is built using cryptographic protocols including verifiable delay functions and aggregate signatures. In our design, we have a federated setup for generating the public parameters of the VDF, thus removing the need for a single trusted setup. We formally analyze FIRST, prove its security using the Universal Composability framework and experimentally demonstrate the effectiveness of FIRST. ","comment":"16 pages, 5 figures","authors":"Emrah Sariboz, Gaurav Panwar, Roopa Vishwanathan, Satyajayant Misra","pdf":"http://arxiv.org/pdf/2204.00955v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.00251v1","published":"Fri, 01 Apr 2022 07:24:56 GMT","title":"The return of (I)DeFiX","summary":"  Decentralized Finance (DeFi) is a nascent set of financial services, using tokens, smart contracts, and blockchain technology as financial instruments. We investigate four possible drivers of DeFi returns: exposure to cryptocurrency market, the network effect, the investor's attention, and the valuation ratio. As DeFi tokens are distinct from classical cryptocurrencies, we design a new dedicated market index, denoted DeFiX. First, we show that DeFi tokens returns are driven by the investor's attention on technical terms such as \\decentralized finance\\ or \\DeFi\\, and are exposed to their own network variables and cryptocurrency market. We construct a valuation ratio for the DeFi market by dividing the Total Value Locked (TVL) by the Market Capitalization (MC). Our findings do not support the TVL/MC predictive power assumption. Overall, our empirical study shows that the impact of the cryptocurrency market on DeFi returns is stronger than any other considered driver and provides superior explanatory power. ","authors":"Florentina Şoiman, CASC, CNRS - UMR3571, Guillaume Dumas, CNRS - UMR3571, Sonia Jimenez-Garces, CERAG","pdf":"http://arxiv.org/pdf/2204.00251v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.00034v1","published":"Thu, 31 Mar 2022 18:14:31 GMT","title":"Parallel Proof-of-Work with Concrete Bounds","summary":"  Authorization is challenging in distributed systems that cannot rely on the identification of nodes. Proof-of-work offers an alternative gate-keeping mechanism, but its probabilistic nature is incompatible with conventional security definitions. Recent related work establishes concrete bounds for the failure probability of Bitcoin's sequential proof-of-work mechanism. We propose a family of state replication protocols using parallel proof-of-work. Our bottom-up design from an agreement sub-protocol allows us to give concrete bounds for the failure probability in adversarial synchronous networks. After the typical interval of 10 minutes, parallel proof-of-work offers two orders of magnitude more security than sequential proof-of-work. This means that state updates can be sufficiently secure to support commits after one block (i.e., after 10 minutes), removing the risk of double-spending in many applications. We offer guidance on the optimal choice of parameters for a wide range of network and attacker assumptions. Simulations show that the proposed construction is robust against violations of design assumptions. ","authors":"Patrik Keller, Rainer Böhme","pdf":"http://arxiv.org/pdf/2204.00034v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.16666v1","published":"Wed, 30 Mar 2022 20:39:46 GMT","title":"Hawkes Process Modeling of Block Arrivals in Bitcoin Blockchain","summary":"  The paper constructs a multi-variate Hawkes process model of Bitcoin block arrivals and price jumps. Hawkes processes are selfexciting point processes that can capture the self- and cross-excitation effects of block mining and Bitcoin price volatility. We use publicly available blockchain datasets to estimate the model parameters via maximum likelihood estimation. The results show that Bitcoin price volatility boost block mining rate and Bitcoin investment return demonstrates mean reversion. Quantile-Quantile plots show that the proposed Hawkes process model is a better fit to the blockchain datasets than a Poisson process model. ","authors":"Rui Luo, Vikram Krishnamurthy, Erik Blasch","pdf":"http://arxiv.org/pdf/2203.16666v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.16612v1","published":"Wed, 30 Mar 2022 18:50:38 GMT","title":"Decentralization illusion in DeFi: Evidence from MakerDAO","summary":"  Decentralized Autonomous Organization (DAO) is very popular in Decentralized Finance (DeFi) applications as it provides a decentralized governance solution through blockchain. We analyze the governance characteristics in the relevant Maker protocol and its stablecoin Dai (DAI) and governance token Maker (MKR). To achieve that, we establish several measurements of centralized governance. Our empirical analysis investigates the effect of centralized governance over a series of factors related to MKR, DAI and Ethereum, such as financial, transaction, exchange, network and twitter sentiment indicators. Our results show that governance centralization influences both the Maker protocol and Ethereum blockchain. The main implication of this study is that centralized governance in MakerDAO very much exists, while DeFi investors face a trade-off between efficiency and decentralization. This further contributes to the contemporary debate on whether DeFi can be truly decentralized. ","authors":"Xiaotong Sun, Charalampos Stasinakis, Georigios Sermpinis","pdf":"http://arxiv.org/pdf/2203.16612v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.16058v1","published":"Wed, 30 Mar 2022 04:58:50 GMT","title":"Measuring Miner Decentralization in Proof-of-Work Blockchains","summary":"  Proof of work cryptocurrencies began with the promise of a more egalitarian future with a decentralized monetary system with no powerful entities in charge. While this vision is far from realized, these cryptocurrencies are still touted to be much more decentralized than traditional centralized systems. While it is well understood that cryptocurrencies are centralized, it is still unclear what the underlying causes are. This work aims to address this gap and examines some of the forces behind mining centralization.   The internals of cryptocurrency mining is very opaque and difficult to study since it traditionally requires forming relationships with miners, who are typically reticent to share internal information about their competitive advantages. This work takes a different approach by combining large-scale statistical techniques with publicly available blockchain data in order to answer previously intractable questions. The crux of our analysis technique is based on the simple observation that some miners can utilize their hashpower more efficiently due to their position in the network. By teasing out that effect, we de-bias the mining power distribution to get a more accurate estimate. Using that de-biased mining power distribution, we can answer questions about the network position of miners in each cryptocurrency network. Finally, during the course of this study, we observed some unusual mining behaviors which we highlight. ","authors":"Sishan Long, Soumya Basu, Emin Gün Sirer","pdf":"http://arxiv.org/pdf/2203.16058v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.15930v1","published":"Tue, 29 Mar 2022 22:19:24 GMT","title":"Extracting Godl [sic] from the Salt Mines: Ethereum Miners Extracting   Value","summary":"  Cryptocurrency miners have great latitude in deciding which transactions they accept, including their own, and the order in which they accept them. Ethereum miners in particular use this flexibility to collect MEV-Miner Extractable Value-by structuring transactions to extract additional revenue. Ethereum also contains numerous bots that attempt to obtain MEV based on public-but-not-yet-confirmed transactions. Private relays shelter operations from these selfsame bots by directly submitting transactions to mining pools.   In this work, we develop an algorithm to detect MEV exploitation present in previously mined blocks. We use our implementation of the detector to analyze MEV usage and profit redistribution, finding that miners make the lion's share of the profits, rather than independent users of the private relays. More specifically, (i) 73% of private transactions hide trading activity or re-distribute miner rewards, and 87.6% of MEV collection is accomplished with privately submitted transactions, (ii) our algorithm finds more than $6M worth of MEV profit in a period of 12 days, two thirds of which go directly to miners, and (iii) MEV represents 9.2% of miners' profit from transaction fees.   Furthermore, in those 12 days, we also identify four blocks that contain enough MEV profits to make time-bandit forking attacks economically viable for large miners, undermining the security and stability of Ethereum as a whole. ","authors":"Julien Piet, Jaiden Fairoze, Nicholas Weaver","pdf":"http://arxiv.org/pdf/2203.15930v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.14850v1","published":"Mon, 28 Mar 2022 15:42:33 GMT","title":"A Fly in the Ointment: An Empirical Study on the Characteristics of   Ethereum Smart Contracts Code Weaknesses and Vulnerabilities","summary":"  Context: Smart contracts are computer programs that are automatically executed on the blockchain. Vulnerabilities in their implementation have led to severe loss of cryptocurrency. Smart contracts become immutable when deployed to the Ethereum blockchain. Therefore, it is essential to understand the nature of vulnerabilities in Ethereum smart contracts to prevent them in the future. Existing classifications exist, but are limited in several ways. Objective: We aim to characterize vulnerabilities in Ethereum smart contracts written in Solidity, and unify existing classifications schemes. Method: We extracted 2143 vulnerabilities from public coding platforms and popular vulnerability databases and categorized them using a card sorting approach. We targeted the Ethereum blockchain in this paper, as it is the first and most popular blockchain to support the deployment of smart contracts, and Solidity as the most widely used language to implement smart contracts. We devised a classification scheme of smart contract vulnerabilities according to their error source and impact. Afterwards, we mapped existing classification schemes to our classification. Results: The resulting classification consists of 11 categories describing the error source of a vulnerability and 13 categories describing potential impacts. Our findings show that the language specific coding and the structural data flow categories are the dominant categories, but that the frequency of occurrence differs substantially between the data sources. Conclusions: Our findings enable researchers to better understand smart contract vulnerabilities by defining various dimensions of the problem and supporting our classification with mappings with literature-based classifications and frequency distributions of the defined categories. ","authors":"Majd Soud, Grischa Liebel, Mohammad Hamdaqa","pdf":"http://arxiv.org/pdf/2203.14850v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.14684v1","published":"Mon, 28 Mar 2022 12:29:34 GMT","title":"Investigating transactions in cryptocurrencies","summary":"  This thesis presents techniques to investigate transactions in uncharted cryptocurrencies and services. Cryptocurrencies are used to securely send payments online. Payments via the first cryptocurrency, Bitcoin, use pseudonymous addresses that have limited privacy and anonymity guarantees. Research has shown that this pseudonymity can be broken, allowing users to be tracked using clustering and tagging heuristics. Such tracking allows crimes to be investigated. If a user has coins stolen, investigators can track addresses to identify the destination of the coins. This, combined with an explosion in the popularity of blockchain, has led to a vast increase in new coins and services. These offer new features ranging from coins focused on increased anonymity to scams shrouded as smart contracts. In this study, we investigated the extent to which transaction privacy has improved and whether users can still be tracked in these new ecosystems. We began by analysing the privacy-focused coin Zcash, a Bitcoin-forked cryptocurrency, that is considered to have strong anonymity properties due to its background in cryptographic research. We revealed that the user anonymity set can be considerably reduced using heuristics based on usage patterns. Next, we analysed cross-chain transactions collected from the exchange ShapeShift, revealing that users can be tracked as they move across different ledgers. Finally, we present a measurement study on the smart-contract pyramid scheme Forsage, a scam that cycled $267 million USD (of Ethereum) within its first year, showing that at least 88% of the participants in the scheme suffered a loss. The significance of this study is the revelation that users can be tracked in newer cryptocurrencies and services by using our new heuristics, which informs those conducting investigations and developing these technologies. ","comment":"166 pages. PhD dissertation","authors":"Haaroon Yousaf","pdf":"http://arxiv.org/pdf/2203.14684v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.14633v1","published":"Mon, 28 Mar 2022 10:41:18 GMT","title":"An Effective Framework of Private Ethereum Blockchain Networks for Smart   Grid","summary":"  A smart grid is an important application in Industry 4.0 with a lot of new technologies and equipment working together. Hence, sensitive data stored in the smart grid is vulnerable to malicious modification and theft. This paper proposes a framework to build a smart grid based on a highly effective private Ethereum network. Our framework provides a real smart grid that includes modern hardware and a smart contract to secure data in the blockchain network. To obtain high throughput but a low uncle rate, the difficulty calculation method used in the mining process of the Ethereum consensus mechanism is modified to adapt to the practical smart grid setup. The performance in terms of throughput and latency are evaluated by simulation and verified by the real smart grid setup. The enhanced private Ethereum-based smart grid has significantly better performance than the public one. Moreover, this framework can be applied to any system used to store data in the Ethereum network. ","comment":"6 pages, conference","authors":"Do Hai Son, Tran Thi Thuy Quynh, Tran Viet Khoa, Dinh Thai Hoang, Nguyen Linh Trung, Nguyen Viet Ha, Dusit Niyato, Nguyen N. Diep, Eryk Dutkiewicz","pdf":"http://arxiv.org/pdf/2203.14633v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.14601v4","published":"Mon, 28 Mar 2022 09:27:20 GMT","title":"Bribes to Miners: Evidence from Ethereum","summary":"  In blockchain, bribery is an inevitable problem since users with various goals can bribe miners by transferring cryptoassets. To alleviate the negative effects of such collusion, Ethereum blockchain implemented new transaction fee mechanism in the London Fork, which was deployed on August 5th, 2021. In this paper, we first filter potential bribery by scanning Ethereum transactions, and the potential bribers and bribees are centralized in a small group. Then we construct bribing proxies to measure the active level of bribery and then investigate the effects of bribery. Consequently, bribery can influence both Ethereum and other mainstream blockchains, in aspects of underlying cryptocurrency, transaction statistics, and network adoption. Moreover, the London Fork shows complicated effects on relationship between bribery and blockchain factors. Besides, bribery in Ethereum relates to stock markets, e.g., S&P 500 and Nasdaq, implying implicit interlinks between blockchain and traditional finance. ","authors":"Xiaotong Sun","pdf":"http://arxiv.org/pdf/2203.14601v4","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.14159v1","published":"Sat, 26 Mar 2022 21:31:12 GMT","title":"A Novel Neuromorphic Processors Realization of Spiking Deep   Reinforcement Learning for Portfolio Management","summary":"  The process of continuously reallocating funds into financial assets, aiming to increase the expected return of investment and minimizing the risk, is known as portfolio management. Processing speed and energy consumption of portfolio management have become crucial as the complexity of their real-world applications increasingly involves high-dimensional observation and action spaces and environment uncertainty, which their limited onboard resources cannot offset. Emerging neuromorphic chips inspired by the human brain increase processing speed by up to 1000 times and reduce power consumption by several orders of magnitude. This paper proposes a spiking deep reinforcement learning (SDRL) algorithm that can predict financial markets based on unpredictable environments and achieve the defined portfolio management goal of profitability and risk reduction. This algorithm is optimized forIntel's Loihi neuromorphic processor and provides 186x and 516x energy consumption reduction is observed compared to the competitors, respectively. In addition, a 1.3x and 2.0x speed-up over the high-end processors and GPUs, respectively. The evaluations are performed on cryptocurrency market between 2016 and 2021 the benchmark. ","authors":"Seyyed Amirhossein Saeidi, Forouzan Fallah, Soroush Barmaki, Hamed Farbeh","pdf":"http://arxiv.org/pdf/2203.14159v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.12435v1","published":"Wed, 23 Mar 2022 14:13:58 GMT","title":"Stateful to Stateless: Modelling Stateless Ethereum","summary":"  The concept of 'Stateless Ethereum' was conceived with the primary aim of mitigating Ethereum's unbounded state growth. The key facilitator of Stateless Ethereum is through the introduction of 'witnesses' into the ecosystem. The changes and potential consequences that these additional data packets pose on the network need to be identified and analysed to ensure that the Ethereum ecosystem can continue operating securely and efficiently. In this paper we propose a Bayesian Network model, a probabilistic graphical modelling approach, to capture the key factors and their interactions in Ethereum mainnet, the public Ethereum blockchain, focussing on the changes being introduced by Stateless Ethereum to estimate the health of the resulting Ethereum ecosystem. We use a mixture of empirical data and expert knowledge, where data are unavailable, to quantify the model. Based on the data and expert knowledge available to use at the time of modelling, the Ethereum ecosystem is expected to remain healthy following the introduction of Stateless Ethereum. ","comment":"In Proceedings MARS 2022, arXiv:2203.09299","authors":"Sandra Johnson, ConsenSys Software Inc, Australia, David Hyland-Wood, ConsenSys Software Inc, Australia, Anders L Madsen, Aalborg University, Denmark, Kerrie Mengersen, Queensland University of Technology","pdf":"http://arxiv.org/pdf/2203.12435v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.12363v2","published":"Wed, 23 Mar 2022 12:35:59 GMT","title":"Ethereum Fraud Detection with Heterogeneous Graph Neural Networks","summary":"  While transactions with cryptocurrencies such as Ethereum are becoming more prevalent, fraud and other criminal transactions are not uncommon. Graph analysis algorithms and machine learning techniques detect suspicious transactions that lead to phishing in large transaction networks. Many graph neural network (GNN) models have been proposed to apply deep learning techniques to graph structures. Although there is research on phishing detection using GNN models in the Ethereum transaction network, models that address the scale of the number of vertices and edges and the imbalance of labels have not yet been studied. In this paper, we compared the model performance of GNN models on the actual Ethereum transaction network dataset and phishing reported label data to exhaustively compare and verify which GNN models and hyperparameters produce the best accuracy. Specifically, we evaluated the model performance of representative homogeneous GNN models which consider single-type nodes and edges and heterogeneous GNN models which support different types of nodes and edges. We showed that heterogeneous models had better model performance than homogeneous models. In particular, the RGCN model achieved the best performance in the overall metrics. ","comment":"8 pages, 5 figures","authors":"Hiroki Kanezashi, Toyotaro Suzumura, Xin Liu, Takahiro Hirofuchi","pdf":"http://arxiv.org/pdf/2203.12363v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2203.12323v1","published":"Wed, 23 Mar 2022 10:58:50 GMT","title":"CollaChain: A BFT Collaborative Middleware for Decentralized   Applications","summary":"  The sharing economy is centralizing services, leading to misuses of the Internet. We can list growing damages of data hacks, global outages and even the use of data to manipulate their owners. Unfortunately, there is no decentralized web where users can interact peer-to-peer in a secure way. Blockchains incentivize participants to individually validate every transaction and impose their block to the network. As a result, the validation of smart contract requests is computationally intensive while the agreement on a unique state does not make full use of the network. In this paper, we propose Collachain, a new byzantine fault tolerant blockchain compatible with the largest ecosystem of DApps that leverages collaboration. First, the pariticipants executing smart contracts collaborate to validate the transactions, hence halving the number of validations required by modern blockchains (e.g., Ethereum, Libra). Second, the participants in the consensus collaborate to combine their block proposal into a superblock, hence improving throughput as the system grows to hundreds of nodes. In addition, Collachain offers the possibility to its users to interact securely with each other without downloading the blockchain, hence allowing interactions via mobile devices. Collachain is effective at outperforming the Concord and Quorum blockchains and its throughput peaks at 4500 TPS under a Twitter DApp (Decentralized Application) workload. Finally, we demonstrate Collachain's scalability by deploying it on 200 nodes located in 10 countries over 5 continents. ","authors":"Deepal Tennakoon, Yiding Hua, Vincent Gramoli","pdf":"http://arxiv.org/pdf/2203.12323v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12043v1","published":"Tue, 24 May 2022 12:51:59 GMT","title":"Static Replication of Impermanent Loss for Concentrated Liquidity   Provision in Decentralised Markets","summary":"  This article analytically characterizes the impermanent loss of concentrated liquidity provision for automatic market makers in decentralised markets such as Uniswap. We propose two static replication formulas for the impermanent loss by a combination of European calls or puts with strike prices supported on the liquidity provision price interval. It facilitates liquidity providers to hedge permanent loss by trading crypto options in more liquid centralised exchanges such as Deribit. Numerical examples illustrate the astonishing accuracy of the static replication. ","comment":"12pages, 1 figure","authors":"Jun Deng, Hua Zong","pdf":"http://arxiv.org/pdf/2205.12043v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07452v1","published":"Mon, 16 May 2022 05:38:13 GMT","title":"Constant Power Root Market Makers","summary":"  The paper introduces a new type of constant function market maker, the constant power root market marker. We show that the constant sum (used by mStable), constant product (used by Uniswap and Balancer), constant reserve (HOLD-ing), and constant harmonic mean trading functions are special cases of the constant power root trading function. We derive the value function for liquidity providers, marginal price function, price impact function, impermanent loss function, and greeks for constant power root market markers. In particular, we find that as the power q varies from the range of -infinity to 1, the power root function interpolates between the harmonic (q=-1), geometric (q=0), and arithmetic (q=1) means. This provides a toggle that trades off between price slippage for traders and impermanent loss for liquidity providers. As the power q approaches 1, slippage is low and impermanent loss is high. As q approaches to -1, price slippage increases and impermanent loss decreases. ","comment":"16 pages; proofs inline","authors":"Mike Wu, Will McTighe","pdf":"http://arxiv.org/pdf/2205.07452v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.00464v1","published":"Fri, 01 Apr 2022 14:22:40 GMT","title":"Differential Liquidity Provision in Uniswap v3 and Implications for   Contract Design","summary":"  Decentralized exchanges (DEXs) provide a means for users to trade pairs of assets on-chain without the need of a trusted third party to effectuate a trade. Amongst these, constant function market maker (CFMM) DEXs such as Uniswap handle the most volume of trades between ERC-20 tokens. With the introduction of Uniswap v3, liquidity providers are given the option to differentially allocate liquidity to be used for trades that occur within specific price intervals. In this paper, we formalize the profit and loss that liquidity providers can earn when providing specific liquidity positions to a contract. With this in hand, we are able to compute optimal liquidity allocations for liquidity providers who hold beliefs over how prices evolve over time. Ultimately, we use this tool to shed light on the design question regarding how v3 contracts should partition price space for permissible liquidity allocations. Our results show that a richer space of potential partitions can simultaneously benefit both liquidity providers and traders. ","comment":"48 pages, 13 figures","authors":"Zhou Fan, Francisco Marmolejo-Cossío, Ben Altschuler, He Sun, Xintong Wang, David C. Parkes","pdf":"http://arxiv.org/pdf/2204.00464v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.01333v1","published":"Wed, 01 Jun 2022 15:51:07 GMT","title":"Formal Analysis of Lending Pools in Decentralized Finance","summary":"  Decentralised Finance (DeFi) applications constitute an entire financial ecosystem deployed on blockchains. Such applications are based on complex protocols and incentive mechanisms whose financial safety is hard to determine. Besides, their adoption is rapidly growing, hence imperilling an increasingly higher amount of assets. Therefore, accurate formalisation and verification of DeFi applications is essential to assess their safety. We present a tool for the formal analysis of one of the most widespread DeFi applications: Lending Pools (LP). This was achieved by leveraging an existing formal model for LPs, the Maude verification environment and the MultiVeStA statistical analyser. The tool supports several analyses including reachability analysis, LTL model checking and statistical model checking. We show how the tool can be used to statistically analyse several parameters of LPs that are fundamental to assess and predict their behaviour. ","authors":"Massimo Bartoletti, James Chiang, Tommi Junttila, Alberto Lluch Lafuente, Massimiliano Mirelli, Andrea Vandin","pdf":"http://arxiv.org/pdf/2206.01333v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.00563v1","published":"Wed, 01 Jun 2022 15:20:06 GMT","title":"Preparing Majorana zero modes on a noisy quantum processor","summary":"  The simulation of systems of interacting fermions is one of the most anticipated applications of quantum computers. The most interesting simulations will require a fault-tolerant quantum computer, and building such a device remains a long-term goal. However, the capabilities of existing noisy quantum processors have steadily improved, sparking an interest in running simulations that, while not necessarily classically intractable, may serve as device benchmarks and help elucidate the challenges to achieving practical applications on near-term devices. Systems of non-interacting fermions are ideally suited to serve these purposes. While they display rich physics and generate highly entangled states when simulated on a quantum processor, their classical tractability enables experimental results to be verified even at large system sizes that would typically defy classical simulation. In this work, we use a noisy superconducting quantum processor to prepare Majorana zero modes as eigenstates of the Kitaev chain Hamiltonian, a model of non-interacting fermions. Our work builds on previous experiments with non-interacting fermionic systems. Previous work demonstrated error mitigation techniques applicable to the special case of Slater determinants. Here, we show how to extend these techniques to the case of general fermionic Gaussian states, and demonstrate them by preparing Majorana zero modes on systems of up to 7 qubits. ","comment":"8 pages, 5 figures","authors":"Kevin J. Sung, Marko J. Rančić, Olivia T. Lanes, Nicholas T. Bronn","pdf":"http://arxiv.org/pdf/2206.00563v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14699v1","published":"Sun, 29 May 2022 16:00:29 GMT","title":"Manage Risk in DeFi Portfolio","summary":"  Decentralized Finance (DeFi) is a new financial industry built on blockchain technologies. Decentralized financial services increased consequantly, the ability to lend, borrow and invest in decentralized investment vehicules, allowing investors to bypass third party intermediaries. DeFI promise is to reduce transactions costs, management fees while increasing the trust between agents of this financial industry 3.0. This paper provides an overview of Decentralized Finance different components as well as the risks involved in investing through these new vehicles. It also proposes an allocation methodology which integrate and quantify these risks. ","authors":"Hugo Inzirillo, Stanislas de Quenetain","pdf":"http://arxiv.org/pdf/2205.14699v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.13295v1","published":"Thu, 26 May 2022 12:18:41 GMT","title":"Unpredictable repeatability in molecular evolution","summary":"  The extent of parallel evolution at the genotypic level is quantitatively linked to the distribution of beneficial fitness effects (DBFE) of mutations. The standard view, based on light-tailed distributions (i.e. distributions with finite moments), is that the probability of parallel evolution in duplicate populations is inversely proportional to the number of available mutations, and moreover that the DBFE is sufficient to determine the probability when the number of available mutations is large. Here we show that when the DBFE is heavy-tailed, as found in several recent experiments, these expectations are defied. The probability of parallel evolution decays anomalously slowly in the number of mutations or even becomes independent of it, implying higher repeatability of evolution. At the same time, the probability of parallel evolution is non-self-averaging, that is, it does not converge to its mean value even when a large number of mutations are involved. This behavior arises because the evolutionary process is dominated by only a few mutations of high weight. Consequently, the probability varies widely across systems with the same DBFE. Contrary to the standard view, the DBFE is no longer sufficient to determine the extent of parallel evolution, making it much less predictable. We illustrate these ideas theoretically and through analysis of empirical data on antibiotic resistance evolution. ","authors":"Suman G Das, Joachim Krug","pdf":"http://arxiv.org/pdf/2205.13295v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.10257v1","published":"Fri, 20 May 2022 15:40:07 GMT","title":"Frontrunning Block Attack in PoA Clique: A Case Study","summary":"  As a fundamental technology of decentralized finance (DeFi), blockchain's ability to maintain a distributed fair ledger is threatened by manipulation of block/transaction order. In this paper, we propose a frontrunning block attack against the Clique-based Proof of Authority (PoA) algorithms. Our attack can frontrun blocks from honest in-turn sealers by breaking the proper order of leader selection. By falsifying the priority parameters (both \\\\textit{difficulty} and \\\\textit{delay time}), a malicious out-of-turn sealer can always successfully occupy the leader position and produce advantageous blocks that may contain profitable transactions. As a typical instance, we apply our attack to a mature Clique-engined project, HPB (\\\\$3,058,901, as of April 2022). Experimental results demonstrate the effectiveness and feasibility. Then, we further recommend fixes that make identity checks effective. Our investigation and suggestion have been submitted to its official team and got their approval. We believe this work can act as, at least, a warning case for Clique variants to avoid repeating these design mistakes. ","comment":"This work was in part presented at IEEE ICBC 2022","authors":"Xinrui Zhang, Qin Wang, Rujia Li, Qi Wang","pdf":"http://arxiv.org/pdf/2205.10257v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.09890v2","published":"Thu, 19 May 2022 22:43:00 GMT","title":"Replicating Portfolios: Constructing Permissionless Derivatives","summary":"  The current design space of derivatives in Decentralized Finance (DeFi) relies heavily on oracle systems. Replicating market makers (RMMs) provide a mechanism for converting specific payoff functions to an associated Constant Function Market Makers (CFMMs). We leverage RMMs to replicate the approximate payoff of a Black-Scholes covered call option. RMM-01 is the first implementation of an on-chain expiring option mechanism that relies on arbitrage rather than an external oracle for price. We provide frameworks for derivative instruments and structured products achievable on-chain without relying on oracles. We construct long and binary options and briefly discuss perpetual covered call strategies commonly referred to as \\theta vaults.\\ Moreover, we introduce a procedure to eliminate liquidation risk in lending markets. The results suggest that CFMMs are essential for structured product design with minimized trust dependencies. ","comment":"18 pages, 4 Figures","authors":"Estelle Sterrett, Waylon Jepsen, Evan Kim","pdf":"http://arxiv.org/pdf/2205.09890v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.03400v1","published":"Fri, 06 May 2022 17:57:45 GMT","title":"Defying Gravity: On the Complexity of the Hanano Puzzle","summary":"  Liu and Yang recently proved the Hanano Puzzle to be ${\\\\rm NP}$-$\\\\leq_m^p$-hard. We prove it is in fact ${\\\\rm PSPACE}$-$\\\\leq_m^p$-complete. Our paper introduces the notion of a planar grid and establishes a relationship between planar grids and instances of the Nondeterministic Constraint Logic (${\\\\rm NCL}$) problem (a known ${\\\\rm PSPACE}$-$\\\\leq_m^p$-complete problem) by using graph theoretic methods, and uses this connection to guide an indirect many-one reduction from the ${\\\\rm NCL}$ problem to the Hanano Puzzle. The technique introduced is versatile and can be reapplied to other games with gravity. ","comment":"20 pages, 10 figures","authors":"Michael C. Chavrimootoo","pdf":"http://arxiv.org/pdf/2205.03400v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.02948v1","published":"Thu, 05 May 2022 22:04:29 GMT","title":"High-Dimensional Survival Analysis: Methods and Applications","summary":"  In the era of precision medicine, time-to-event outcomes such as time to death or progression are routinely collected, along with high-throughput covariates. These high-dimensional data defy classical survival regression models, which are either infeasible to fit or likely to incur low predictability due to over-fitting. To overcome this, recent emphasis has been placed on developing novel approaches for feature selection and survival prognostication. We will review various cutting-edge methods that handle survival outcome data with high-dimensional predictors, highlighting recent innovations in machine learning approaches for survival prediction. We will cover the statistical intuitions and principles behind these methods and conclude with extensions to more complex settings, where competing events are observed. We exemplify these methods with applications to the Boston Lung Cancer Survival Cohort study, one of the largest cancer epidemiology cohorts investigating the complex mechanisms of lung cancer. ","authors":"Stephen Salerno, Yi Li","pdf":"http://arxiv.org/pdf/2205.02948v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.12813v1","published":"Wed, 27 Apr 2022 10:11:26 GMT","title":"Spin liquid state in a rare-earth hyperkagome lattice","summary":"  Quantum fluctuations enhanced by frustration and subtle interplay between competing degrees of freedom offer an ideal ground to realize novel states with fractional quantum numbers in quantum materials that defy standard theoretical paradigms. Quantum spin liquid (QSL) is a highly entangled state wherein frustration induced strong quantum fluctuations preclude symmetry breaking phase transitions down to zero temperature without any order parameter. Experimental realizations of QSL in quantum materials with spin dimensionality greater than one is very rare. Here, we present our thermodynamic, nuclear magnetic resonance, muon spin relaxation and inelastic neutron scattering studies of a new rare-earth hyperkagome compound Li3Yb3Te2O12 in which Yb3+ ions constitute a three dimensional spin-lattice without any detectable disorder. Our comprehensive experiments evince neither signature of magnetic ordering nor spin freezing down to 38 mK that suggest the realization of dynamic liquid-like ground state in this antiferromagnet. The ground state of this material is interpreted by a low energy Jeff = 1/2 degrees of freedom with short range spin correlations. The present results demonstrate a viable basis to explore spin-orbit driven enigmatic correlated quantum states in a new class of rare-earth based three dimensional frustrated magnets that may open new avenues in theoretical and experimental search for spin liquids. ","authors":"J. Khatua, S. Bhattacharya, Q. P. Ding, S. Vrtnik, A. M. Strydom, N. P. Butch, H. Luetkens, E. Kermarrec, M. S. Ramachandra Rao, A. Zorko, Y. Furukawa, P. Khuntia","pdf":"http://arxiv.org/pdf/2204.12813v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.11108v1","published":"Sat, 23 Apr 2022 17:02:46 GMT","title":"Coherent Atomic Orbital Polarization Probes the Geometric Phase in   Photodissociation of Polyatomic Molecules","summary":"  Quantum interference between multiple pathways in molecular photodissociation often results in angular momentum polarization of atomic products and this can give deep insight into fundamental physical processes. For dissociation of diatomic molecules the resulting orbital polarization is fully understood and consistent with quantum mechanical theory. For polyatomic molecules, however, coherent photofragment orbital polarization is frequently observed but so far has eluded theoretical explanation, and physical insight is lacking. Here we present a model of these effects for ozone photodissociation that reveals the importance of a novel manifestation of the geometric phase. We show this geometric phase effect permits the existence of coherent polarization in cases where it would otherwise vanish, and cancels it in some cases where it might otherwise exist. The model accounts for measurements in ozone that have hitherto defied explanation, and represents a step toward a deeper understanding of coherent electronic excitation in polyatomic molecules and a new role of the geometric phase. ","comment":"16 pages, 4 figures","authors":"Chaya Weeraratna, Arthur G. Suits, Oleg S. Vasyutinskii","pdf":"http://arxiv.org/pdf/2204.11108v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.10932v1","published":"Fri, 22 Apr 2022 21:25:12 GMT","title":"Listing, Verifying and Counting Lowest Common Ancestors in DAGs:   Algorithms and Fine-Grained Lower Bounds","summary":"  The AP-LCA problem asks, given an $n$-node directed acyclic graph (DAG), to compute for every pair of vertices $u$ and $v$ in the DAG a lowest common ancestor (LCA) of $u$ and $v$ if one exists. In this paper we study several interesting variants of AP-LCA, providing both algorithms and fine-grained lower bounds for them. The lower bounds we obtain are the first conditional lower bounds for LCA problems higher than $n^{\\\\omega-o(1)}$, where $\\\\omega$ is the matrix multiplication exponent. Some of our results include:   - In any DAG, we can detect all vertex pairs that have at most two LCAs and list all of their LCAs in $O(n^\\\\omega)$ time. This algorithm extends a result of [Kowaluk and Lingas ESA'07] which showed an $\\\\tilde{O}(n^\\\\omega)$ time algorithm that detects all pairs with a unique LCA in a DAG and outputs their corresponding LCAs.   - Listing $7$ LCAs per vertex pair in DAGs requires $n^{3-o(1)}$ time under the popular assumption that 3-uniform 5-hyperclique detection requires $n^{5-o(1)}$ time. This is surprising since essentially cubic time is sufficient to list all LCAs (if $\\\\omega=2$).   - Counting the number of LCAs for every vertex pair in a DAG requires $n^{3-o(1)}$ time under the Strong Exponential Time Hypothesis, and $n^{\\\\omega(1,2,1)-o(1)}$ time under the $4$-Clique hypothesis. This shows that the algorithm of [Echkardt, M\\\\\\{u}hling and Nowak ESA'07] for listing all LCAs for every pair of vertices is likely optimal.   - Given a DAG and a vertex $w_{u,v}$ for every vertex pair $u,v$, verifying whether all $w_{u,v}$ are valid LCAs requires $n^{2.5-o(1)}$ time assuming 3-uniform 4-hyperclique requires $n^{4 - o(1)}$ time. This defies the common intuition that verification is easier than computation since returning some LCA per vertex pair can be solved in $O(n^{2.447})$ time [Grandoni et al. SODA'21]. ","comment":"To appear in ICALP 2022. Abstract shortened to fit arXiv requirement","authors":"Surya Mathialagan, Virginia Vassilevska Williams, Yinzhan Xu","pdf":"http://arxiv.org/pdf/2204.10932v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.05640v1","published":"Tue, 12 Apr 2022 09:06:40 GMT","title":"Black holes: on the universality of the Kerr hypothesis","summary":"  To what extent are all astrophysical, dark, compact objects both black holes (BHs) and described by the Kerr geometry? We embark on the exercise of defying the universality of this remarkable idea, often called the \\Kerr hypothesis\\. After establishing its rationale and timeliness, we define a minimal set of reasonability criteria for alternative models of dark compact objects. Then, as proof of principle, we discuss concrete, dynamically robust non-Kerr BHs and horizonless imitators, that 1) pass the basic theoretical, and in particular dynamical, tests, 2) match (some of the) state of the art astrophysical observables and 3) only emerge at some (macroscopic) scales. These examples illustrate how the universality (at all macroscopic scales) of the Kerr hypothesis can be challenged. ","comment":"16 pages, 3 figures, contribution to the forthcoming book \\Modified   and Quantum Gravity - From theory to experimental searches on all scales\\","authors":"Carlos A. R. Herdeiro","pdf":"http://arxiv.org/pdf/2204.05640v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2204.04649v1","published":"Sun, 10 Apr 2022 10:49:56 GMT","title":"Neutron spectroscopy evidence for a possible magnetic-field-induced   gapless quantum-spin-liquid phase in a Kitaev material $α$-RuCl$_3$","summary":"  As one of the most promising Kitaev quantum-spin-liquid (QSL) candidates, $\\\\alpha$-RuCl$_3$ has received a great amount of attention. However, its ground state exhibits a long-range zigzag magnetic order, which defies the QSL phase. Nevertheless, the magnetic order is fragile and can be completely suppressed by applying an external magnetic field. Here, we explore the evolution of magnetic excitations of $\\\\alpha$-RuCl$_3$ under an in-plane magnetic field, by carrying out inelastic neutron scattering measurements on high-quality single crystals. Under zero field, there exist spin-wave excitations near the $M$ point and a continuum near the $\\\\mit\\\\Gamma$ point, which are believed to be associated with the zigzag magnetic order and fractional excitations of the Kitaev QSL state, respectively. By increasing the magnetic field, the spin-wave excitations gradually give way to the continuous excitations. On the verge of the critical field $\\\\mu_0H_{\\\\rm c}=7.5$ T, the former vanish and only the latter is left, indicating the emergence of a pure QSL state. By further increasing the field strength, the excitations near the $\\\\mit\\\\Gamma$ point become more intense. By following the gap evolution of the excitations near the $\\\\mit\\\\Gamma$ point, we are able to establish a phase diagram composed of three interesting phases, including a gapped zigzag order phase at low fields, possibly-gapless QSL phase near $\\\\mu_0H_{\\\\rm c}$, and gapped partially polarized phase at high fields. These results demonstrate that an in-plane magnetic field can drive $\\\\alpha$-RuCl$_3$ into a long-sought QSL state near the critical field. ","comment":"9 pages, 4 figures","authors":"Xiaoxue Zhao, Kejing Ran, Jinghui Wang, Song Bao, Yanyan Shangguan, Zhentao Huang, Junbo Liao, Bo Zhang, Shufan Cheng, Hao Xu, Wei Wang, Zhao-Yang Dong, Siqin Meng, Zhilun Lu, Shin-ichiro Yano, Shun-Li Yu, Jian-Xin Li, Jinsheng Wen","pdf":"http://arxiv.org/pdf/2204.04649v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12911v1","published":"Wed, 25 May 2022 17:03:38 GMT","title":"SoK: Cross-border Criminal Investigations and Digital Evidence","summary":"  Digital evidence underpin the majority of crimes as their analysis is an integral part of almost every criminal investigation. Even if we temporarily disregard the numerous challenges in the collection and analysis of digital evidence, the exchange of the evidence among the different stakeholders has many thorny issues. Of specific interest are cross-border criminal investigations as the complexity is significantly high due to the heterogeneity of legal frameworks which beyond time bottlenecks can also become prohibiting. The aim of this article is to analyse the current state of practice of cross-border investigations considering the efficacy of current collaboration protocols along with the challenges and drawbacks to be overcome. Further to performing a legally-oriented research treatise, we recall all the challenges raised in the literature and discuss them from a more practical yet global perspective. Thus, this article paves the way to enabling practitioners and stakeholders to leverage horizontal strategies to fill in the identified gaps timely and accurately. ","authors":"Fran Casino, Claudia Pina, Pablo López-Aguilar, Edgar Batista, Agusti Solanas, Constantinos Patsakis","pdf":"http://arxiv.org/pdf/2205.12911v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.06837v2","published":"Fri, 13 May 2022 18:07:03 GMT","title":"Strategic Latency Reduction in Blockchain Peer-to-Peer Networks","summary":"  Most permissionless blockchain networks run on peer-to-peer (P2P) networks, which offer flexibility and decentralization at the expense of performance (e.g., network latency). Historically, this tradeoff has not been a bottleneck for most blockchains. However, an emerging host of blockchain-based applications (e.g., decentralized finance) are increasingly sensitive to latency; users who can reduce their network latency relative to other users can accrue (sometimes significant) financial gains. In this work, we initiate the study of strategic latency reduction in blockchain P2P networks. We first define two classes of latency that are of interest in blockchain applications. We then show empirically that a strategic agent who controls only their local peering decisions can manipulate both types of latency, achieving 60\\\\% of the global latency gains provided by the centralized, paid service bloXroute, or, in targeted scenarios, comparable gains. Finally, we show that our results are not due to the poor design of existing P2P networks. Under a simple network model, we theoretically prove that an adversary can always manipulate the P2P network's latency to their advantage, provided the network experiences sufficient peer churn and transaction activity. ","authors":"Weizhao Tang, Lucianna Kiffer, Giulia Fanti, Ari Juels","pdf":"http://arxiv.org/pdf/2205.06837v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03664v1","published":"Wed, 08 Jun 2022 03:30:55 GMT","title":"Web3 Meets Behavioral Economics: An Example of Profitable Crypto Lottery   Mechanism Design","summary":"  We are often faced with a non-trivial task of designing incentive mechanisms in the era of Web3. As history has shown, many Web3 services failed mostly due to the lack of a rigorous incentive mechanism design based on token economics. However, traditional mechanism design, where there is an assumption that the users of services strategically make decisions so that their expected profits are maximized, often does not capture their real behavior well as it ignores humans' psychological bias in making decisions under uncertainty. In this paper, we propose an incentive mechanism design for crypto-enabled services using behavioral economics. Specifically, we take an example of crypto lottery game in this work and incorporate a seminal work of cumulative prospect theory into its lottery game mechanism (or rule) design. We designed four mechanisms and compared them in terms of utility, a metric of how appealing a mechanism is to participants, and a game operator's expected profit. Our approach is generic and will be applicable to a wide range of crypto-based services where a decision has to be made under uncertainty. ","comment":"Submitted to IEEE BRAINS 2022","authors":"Kentaroh Toyoda, Xuan-The Tran, Minh Sang Nguyen, Hung Tien Dinh","pdf":"http://arxiv.org/pdf/2206.03664v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03298v1","published":"Tue, 07 Jun 2022 13:45:08 GMT","title":"Optimal Spatiotemporal Pricing for Autonomous Mobility-on-Demand   Systems: A Decomposition and Dynamic Programming Approach","summary":"  This paper studies the optimal spatiotemporal pricing of autonomous mobility-on-demand (AMoD) systems. We consider a platform that operates a fleet of autonomous vehicles (AVs) and determines the pricing, rebalancing, and fleet sizing strategies over the transportation network in response to demand fluctuations. A network flow model is formulated to characterize the evolution of system states over space and time. Fundamental elements in AMoD markets are captured, including demand elasticity, passenger waiting time, vehicle-passenger matching, proactive vehicle rebalancing, and dynamic fleet sizing. The platform's profit maximization problem is cast as a constrained optimal control problem, which is highly nonconvex due to the nonlinear demand model and passenger-vehicle matching model. An integrated decomposition and dynamic programming approach is developed to tackle this optimal control problem, where we first relax the problem through a change of variables, then separate the relaxed problem into a few small-scale subproblems via dual decomposition, and finally obtain the exact solution to each relaxed subproblem through dynamic programming. Despite the non-convexity, the proposed method establishes a theoretical upper bound to evaluate the optimality gap of the obtained solution. The proposed approach is validated with numerical studies using real data from New York City. We find that the platform adopts distinct operation strategies in core and non-core areas of the city because of the asymmetric demand pattern. Furthermore, we also find that low-demand areas are less resilient than high-demand ones when demand surges unexpectedly, because the operator prioritizes supporting high-demand areas at the sacrifice of service quality in low-demand areas. ","authors":"Zhijie Lai, Sen Li","pdf":"http://arxiv.org/pdf/2206.03298v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03246v1","published":"Tue, 07 Jun 2022 13:00:29 GMT","title":"Portfolio Transformer for Attention-Based Asset Allocation","summary":"  Traditional approaches to financial asset allocation start with returns forecasting followed by an optimization stage that decides the optimal asset weights. Any errors made during the forecasting step reduce the accuracy of the asset weightings, and hence the profitability of the overall portfolio. The Portfolio Transformer (PT) network, introduced here, circumvents the need to predict asset returns and instead directly optimizes the Sharpe ratio, a risk-adjusted performance metric widely used in practice. The PT is a novel end-to-end portfolio optimization framework, inspired by the numerous successes of attention mechanisms in natural language processing. With its full encoder-decoder architecture, specialized time encoding layers, and gating components, the PT has a high capacity to learn long-term dependencies among portfolio assets and hence can adapt more quickly to changing market conditions such as the COVID-19 pandemic. To demonstrate its robustness, the PT is compared against other algorithms, including the current LSTM-based state of the art, on three different datasets, with results showing that it offers the best risk-adjusted performance. ","comment":"11 pages","authors":"Damian Kisiel, Denise Gorse","pdf":"http://arxiv.org/pdf/2206.03246v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03853v1","published":"Tue, 07 Jun 2022 12:29:40 GMT","title":"An Analysis of Selection Bias Issue for Online Advertising","summary":"  In online advertising, a set of potential advertisements can be ranked by a certain auction system where usually the top-1 advertisement would be selected and displayed at an advertising space. In this paper, we show a selection bias issue that is present in an auction system. We analyze that the selection bias destroy truthfulness of the auction, which implies that the buyers (advertisers) on the auction can not maximize their profits. Although selection bias is well known in the field of statistics and there are lot of studies for it, our main contribution is to combine the theoretical analysis of the bias with the auction mechanism. In our experiment using online A/B testing, we evaluate the selection bias on an auction system whose ranking score is the function of predicted CTR (click through rate) of advertisement. The experiment showed that the selection bias is drastically reduced by using a multi-task learning which learns the data for all advertisements. ","authors":"Shinya Suzumura, Hitoshi Abe","pdf":"http://arxiv.org/pdf/2206.03853v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03127v1","published":"Tue, 07 Jun 2022 09:07:49 GMT","title":"Data-driven evolutionary algorithm for oil reservoir well-placement and   control optimization","summary":"  Optimal well placement and well injection-production are crucial for the reservoir development to maximize the financial profits during the project lifetime. Meta-heuristic algorithms have showed good performance in solving complex, nonlinear and non-continuous optimization problems. However, a large number of numerical simulation runs are involved during the optimization process. In this work, a novel and efficient data-driven evolutionary algorithm, called generalized data-driven differential evolutionary algorithm (GDDE), is proposed to reduce the number of simulation runs on well-placement and control optimization problems. Probabilistic neural network (PNN) is adopted as the classifier to select informative and promising candidates, and the most uncertain candidate based on Euclidean distance is prescreened and evaluated with a numerical simulator. Subsequently, local surrogate model is built by radial basis function (RBF) and the optimum of the surrogate, found by optimizer, is evaluated by the numerical simulator to accelerate the convergence. It is worth noting that the shape factors of RBF model and PNN are optimized via solving hyper-parameter sub-expensive optimization problem. The results show the optimization algorithm proposed in this study is very promising for a well-placement optimization problem of two-dimensional reservoir and joint optimization of Egg model. ","authors":"Guodong Chen, Xin Luo, Jimmy Jiu Jiao, Xiaoming Xue","pdf":"http://arxiv.org/pdf/2206.03127v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03491v1","published":"Tue, 07 Jun 2022 07:45:45 GMT","title":"EiX-GNN : Concept-level eigencentrality explainer for graph neural   networks","summary":"  Explaining is a human knowledge transfer process regarding a phenomenon between an explainer and an explainee. Each word used to explain this phenomenon must be carefully selected by the explainer in accordance with the current explainee phenomenon-related knowledge level and the phenomenon itself in order to have a high understanding from the explainee of the phenomenon. Nowadays, deep models, especially graph neural networks, have a major place in daily life even in critical applications. In such context, those models need to have a human high interpretability also referred as being explainable, in order to improve usage trustability of them in sensitive cases. Explaining is also a human dependent task and methods that explain deep model behavior must include these social-related concerns for providing profitable and quality explanations. Current explaining methods often occlude such social aspect for providing their explanations and only focus on the signal aspect of the question. In this contribution we propose a reliable social-aware explaining method suited for graph neural network that includes this social feature as a modular concept generator and by both leveraging signal and graph domain aspect thanks to an eigencentrality concept ordering approach. Besides our method takes into account the human-dependent aspect underlying any explanation process, we also reach high score regarding state-of-the-art objective metrics assessing explanation methods for graph neural networks models. ","authors":"Pascal Bourdon, XLIM-ASALI, David Helbert, XLIM-ASALI, Adrien Raison","pdf":"http://arxiv.org/pdf/2206.03491v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02971v1","published":"Tue, 07 Jun 2022 02:22:07 GMT","title":"Human Trafficking in Mexico: Data sources, Network Analysis and the   Limits of Dismantling Strategies","summary":"  Human trafficking is a heartless crime that represents the second most profitable crime in the world. Mexico's geographical position makes it a country with high levels of human trafficking. Using the snowball sampling method, the major contribution of this paper is the abstraction of the human trafficking network on the southern border of Mexico. Based on a social network analysis, it is identified that the criminal network is moderately centralized (44.32%) and with medium density (0.401). Therefore, the network has minimal cohesiveness and members may find it difficult to share information, money, or products among themselves. To evaluate different dismantling strategies to tackle the criminal organization, three algorithms are evaluated. We found that the first actors to be removed are neither the most connected nor the most peripheral, but the actors who are moderately connected to people of their kind should be removed. In summary, this paper provides a significant step forward to understand quantitatively human trafficking networks and evaluate the limits of dismantling strategies. ","authors":"Sofía de la Mora Tostado, Mayra Núñez-López, Esteban A. Hernández-Vargas","pdf":"http://arxiv.org/pdf/2206.02971v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02603v1","published":"Mon, 06 Jun 2022 13:21:22 GMT","title":"CAN-MM: Multiplexed Message Authentication Code for Controller Area   Network message authentication in road vehicles","summary":"  The automotive market is increasingly profitable for cyberattacks with the constant shift toward fully interconnected vehicles. Electronic Control Units (ECUs) installed on cars often operate in a critical and hostile environment. Hence, both carmakers and governments have decided to support a series of initiatives to mitigate risks and threats belonging to the automotive domain. The Controller Area Network (CAN) is the primary communication protocol in the automotive field, and the integrity of the communication over this network is assured through Message Authentication Codes (MAC). However, limitations in throughput and frame size limit the application of this technique to specific versions of the CAN protocol, leaving several vehicles still unprotected. This paper presents CAN Multiplexed MAC (CAN-MM), a new approach exploiting frequency modulation to multiplex MAC data with standard CAN communication. CAN-MM allows transmitting MAC payloads maintaining full-back compatibility with all versions of the standard CAN protocol. Moreover, multiplexing allows sending DATA and MAC simultaneously. ","authors":"Franco Oberti, Ernesto Sanchez, Alessandro Savino, Filippo Parisi, Stefano Di Carlo","pdf":"http://arxiv.org/pdf/2206.02603v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02602v1","published":"Mon, 06 Jun 2022 13:19:57 GMT","title":"LIN-MM: Multiplexed Message Authentication Code for Local Interconnect   Network message authentication in road vehicles","summary":"  The automotive market is profitable for cyberattacks with the constant shift toward interconnected vehicles. Electronic Control Units (ECUs) installed on cars often operate in a critical and hostile environment. Hence, both carmakers and governments have supported initiatives to mitigate risks and threats belonging to the automotive domain. The Local Interconnect Network (LIN) is one of the most used communication protocols in the automotive field. Today's LIN buses have just a few light security mechanisms to assure integrity through Message Authentication Codes (MAC). However, several limitations with strong constraints make applying those techniques to LIN networks challenging, leaving several vehicles still unprotected. This paper presents LIN Multiplexed MAC (LINMM), a new approach for exploiting signal modulation to multiplex MAC data with standard LIN communication. LINMM allows for transmitting MAC payloads, maintaining fullback compatibility with all versions of the standard LIN protocol. ","authors":"Franco Oberti, Ernesto Sanchez, Alessandro Savino, Filippo Parisi, Mirco Brero, Stefano Di Carlo","pdf":"http://arxiv.org/pdf/2206.02602v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02412v1","published":"Mon, 06 Jun 2022 08:07:09 GMT","title":"Efficient and Scalable High-Order Portfolios Design via Parametric   Skew-t Distribution","summary":"  Since Markowitz's mean-variance framework, optimizing a portfolio that maximizes the profit and minimizes the risk has been ubiquitous in the financial industry. Initially, profit and risk were measured by the first two moments of the portfolio's return, a.k.a. the mean and variance, which are sufficient to characterize a Gaussian distribution. However, it is broadly believed that the first two moments are not enough to capture the characteristics of the returns' behavior, which have been recognized to be asymmetric and heavy-tailed. Although there is ample evidence that portfolio designs involving the third and fourth moments, i.e., skewness and kurtosis, will outperform the conventional mean-variance framework, they are non-trivial. Specifically, in the classical framework, the memory and computational cost of computing the skewness and kurtosis grow sharply with the number of assets. To alleviate the difficulty in high-dimensional problems, we consider an alternative expression for high-order moments based on parametric representations via a generalized hyperbolic skew-t distribution. Then, we reformulate the high-order portfolio optimization problem as a fixed-point problem and propose a robust fixed-point acceleration algorithm that solves the problem in an efficient and scalable manner. Empirical experiments also demonstrate that our proposed high-order portfolio optimization framework is of low complexity and significantly outperforms the state-of-the-art methods by 2 to 4 orders of magnitude. ","authors":"Xiwen Wang, Rui Zhou, Jiaxi Ying, Daniel P. Palomar","pdf":"http://arxiv.org/pdf/2206.02412v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.01064v1","published":"Thu, 02 Jun 2022 14:29:46 GMT","title":"Adaptive Robust Online Portfolio Selection","summary":"  The online portfolio selection (OLPS) problem differs from classical portfolio model problems, as it involves making sequential investment decisions. Many OLPS strategies described in the literature capture market movement based on various beliefs and are shown to be profitable. In this paper, we propose a robust optimization (RO)-based strategy that takes transaction costs into account. Moreover, unlike existing studies that calibrate model parameters from benchmark data sets, we develop a novel adaptive scheme that decides the parameters sequentially. With a wide range of parameters as input, our scheme captures market uptrend and protects against market downtrend while controlling trading frequency to avoid excessive transaction costs. We numerically demonstrate the advantages of our adaptive scheme against several benchmarks under various settings. Our adaptive scheme may also be useful in general sequential decision-making problems. Finally, we compare the performance of our strategy with that of existing OLPS strategies using both benchmark and newly collected data sets. Our strategy outperforms these existing OLPS strategies in terms of cumulative returns and competitive Sharpe ratios across diversified data sets, demonstrating its adaptability-driven superiority. ","authors":"Man Yiu Tsang, Tony Sit, Hoi Ying Wong","pdf":"http://arxiv.org/pdf/2206.01064v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.00390v1","published":"Wed, 01 Jun 2022 10:51:01 GMT","title":"Attention-embedded Quadratic Network (Qttention) for Effective and   Interpretable Bearing Fault Diagnosis","summary":"  Bearing fault diagnosis is of great importance to decrease the damage risk of rotating machines and further improve economic profits. Recently, machine learning, represented by deep learning, has made great progress in bearing fault diagnosis. However, applying deep learning to such a task still faces two major problems. On the one hand, deep learning loses its effectiveness when bearing data are noisy or big data are unavailable, making deep learning hard to implement in industrial fields. On the other hand, a deep network is notoriously a black box. It is difficult to know how a model classifies faulty signals from the normal and the physics principle behind the classification. To solve the effectiveness and interpretability issues, we prototype a convolutional network with recently-invented quadratic neurons. This quadratic neuron empowered network can qualify the noisy and small bearing data due to the strong feature representation ability of quadratic neurons. Moreover, we independently derive the attention mechanism from a quadratic neuron, referred to as qttention, by factorizing the learned quadratic function in analogue to the attention, making the model with quadratic neurons inherently interpretable. Experiments on the public and our datasets demonstrate that the proposed network can facilitate effective and interpretable bearing fault diagnosis. ","comment":"Bearing fault diagnosis, quadratic convolutional network (QCNN),   quadratic attention (qttention)","authors":"Jing-Xiao Liao, Hang-Cheng Dong, Zhi-Qi Sun, Jinwei Sun, Shiping Zhang, Feng-Lei Fan","pdf":"http://arxiv.org/pdf/2206.00390v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.00288v1","published":"Wed, 01 Jun 2022 07:46:17 GMT","title":"Sustaining Security and Safety in ICT: A Quest for Terminology,   Objectives, and Limits","summary":"  Security and safety are intertwined concepts in the world of computing. In recent years, the terms \\sustainable security\\ and \\sustainable safety\\ came into fashion and are being used referring to a variety of systems properties ranging from efficiency to profitability, and sometimes meaning that a product or service is good for people and planet. This leads to confusing perceptions of products where customers might expect a sustainable product to be developed without child labour, while the producer uses the term to signify that their new product uses marginally less power than the previous generation of that products. Even in research on sustainably safe and secure ICT, these different notions of terminology are prevalent. As researchers we often work towards optimising our subject of study towards one specific sustainability metric - let's say energy consumption - while being blissfully unaware of, e.g., social impacts, life-cycle impacts, or rebound effects of such optimisations.   In this paper I dissect the idea of sustainable safety and security, starting from the questions of what we want to sustain, and for whom we want to sustain it. I believe that a general \\people and planet\\ answer is inadequate here because this form of sustainability cannot be the property of a single industry sector but must be addressed by society as a whole. However, with sufficient understanding of life-cycle impacts we may very well be able to devise research and development efforts, and inform decision making processes towards the use of integrated safety and security solutions that help us to address societal challenges in the context of the climate and ecological crises, and that are aligned with concepts such as intersectionality and climate justice. Of course, these solutions can only be effective if they are embedded in societal and economic change towards more frugal uses of data and ICT. ","authors":"Jan Tobias Muehlberg","pdf":"http://arxiv.org/pdf/2206.00288v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.15715v1","published":"Tue, 31 May 2022 12:01:12 GMT","title":"Carrier dynamics in quantum-dot tunnel-injection structures: microscopic   theory and experiment","summary":"  Tunneling-injection structures are incorporated in semiconductor lasers in order to overcome the fundamental dynamical limitation due to hot carrier injection by providing a carrier transport path from a cold carrier reservoir. The tunneling process itself depends on band alignment between quantum-dot levels and the injector quantum well, especially as in these devices LO-phonon scattering is dominant. Quantum dots with their first excited state near the quantum well bottom profit most from tunnel coupling. As inhomogeneous broadening is omnipresent in quantum dot structures, this implies that individual members of the ensemble couple differently to the injector quantum well. Quantum dots with higher energy profit less, as the phonon couples to higher, less occupied states. Likewise, if the energy difference between ground state and quantum well exceeds the LO phonon energy, scattering becomes increasingly inefficient. Therefore, within 20-30meV we find Quantum Dots that benefit substantially different from the tunnel coupling. Furthermore, in quantum dots with increasing confinement depth, excited states become sucessively confined. Here, scattering gets more efficient again, as subsequent excited states reach the phonon resonance with the quantum well bottom. Our results provide guidelines for the optimization of tunnel-injection lasers. Theoretical results for electronic state caluluations in connection with carrier-phonon and carrier-carrier scattering are compared to experimental results of the temporal gain recovery after a short pulse perturbation. ","authors":"Michael Lorke, Igor Khanonkin, Stephan Michael, Johann Peter Reithmaier, Gadi Eisenstein, Frank Jahnke","pdf":"http://arxiv.org/pdf/2205.15715v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02630v1","published":"Tue, 31 May 2022 08:02:30 GMT","title":"Improving Ads-Profitability Using Traffic-Fingerprints","summary":"  This paper introduces the concept of traffic-fingerprints, i.e., normalized 24-dimensional vectors representing a distribution of daily traffic on a web page. Using k-means clustering we show that similarity of traffic-fingerprints is related to the similarity of profitability time patterns for ads shown on these pages. In other words, these fingerprints are correlated with the conversions rates, thus allowing us to argue about conversion rates on pages with negligible traffic. By blocking or unblocking whole clusters of pages we were able to increase the revenue of online campaigns by more than 50%. ","authors":"Adam Gabriel Dobrakowski, Andrzej Pacuk, Piotr Sankowski, Marcin Mucha, Paweł Brach","pdf":"http://arxiv.org/pdf/2206.02630v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.15398v1","published":"Mon, 30 May 2022 19:32:54 GMT","title":"Can I Invest in Metaverse? The Effect of Obtained information and   Perceived Risk on Purchase Intention by The Perspective of the Information   Adoption Model","summary":"  Metaverse is a virtual universe that combines the physical world and the digital world. People can socialize, play games and even shop with their avatars created in this virtual environment. Metaverse, which is growing very fast in terms of investment, is both a profitable and risky area for consumers. In order to enter the Metaverse for investment purposes, it is necessary to do a certain research and gather information. In this direction, the aim of the study is to determine the effect of the quality of the information obtained by the consumers about the metaverse world, the reliability of the information and the perceived risk, on the purchase intention from the point of view of the information adoption model. For the research, data were collected online from 495 consumers who were interested in metaverse investment. AMOS and SPSS package programs were used in the analysis. First, descriptive statistical analyzes were made for the basic structure of the variables. Then the reliability and validity of the model were tested. Finally, the structural equation model was used to test the proposed model. According to the findings, the reliability and quality of the information affect the purchase intention positively and significantly, while the perceived risk affects the purchase intention negatively and significantly. ","comment":"in Turkish language","authors":"İbrahim Halil Efendioğlu","pdf":"http://arxiv.org/pdf/2205.15398v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.15074v1","published":"Mon, 30 May 2022 13:04:13 GMT","title":"A Flow-based Distributed Trading Mechanism in Regional Electricity   Market with Energy Hub","summary":"  The concept of Energy Hub (EH) has been emerged to accommodate renewable energy sources in a multi-energy system to deploy the synergies between electricity and other energy sources. However, the market mechanisms for the integration of the EHs into the energy markets are not sufficiently elaborated. This paper proposes a flow-based two-level distributed trading mechanism in the regional electricity market with EH. At the lower level, the regional system operator coordinates the regional grids transactions in two markets, the local energy market with EH and the wholesale market of the upstream grid. Every nodal agent as an independent stakeholder leverages price discrepancy to cross arbitrage from different markets. At the upper level, the EH is a third player intending to maximize profit from trading in the regional electricity market and gas market. The regional electricity market clearing problem is formulated as a mathematical program with equilibrium constraints, for which we develop an ADMM-based distributed algorithm to obtain the equilibrium solution. The DC power flow is decomposed into optimization problems for the regional system operator and agents at different nodes, which can be solved in a distributed manner to achieve global optimality without violating the privacy of players. Case studies based on a realistic regional grid verify the effectiveness of the proposed algorithm and show that the mechanism is effective in decomposing power flow and increasing energy efficiency. ","authors":"Lu Wang, Mokhtar Bozorg, Mohammad Rayati, Rachid Cherkaoui","pdf":"http://arxiv.org/pdf/2205.15074v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.15056v1","published":"Mon, 30 May 2022 12:36:48 GMT","title":"Stock Trading Optimization through Model-based Reinforcement Learning   with Resistance Support Relative Strength","summary":"  Reinforcement learning (RL) is gaining attention by more and more researchers in quantitative finance as the agent-environment interaction framework is aligned with decision making process in many business problems. Most of the current financial applications using RL algorithms are based on model-free method, which still faces stability and adaptivity challenges. As lots of cutting-edge model-based reinforcement learning (MBRL) algorithms mature in applications such as video games or robotics, we design a new approach that leverages resistance and support (RS) level as regularization terms for action in MBRL, to improve the algorithm's efficiency and stability. From the experiment results, we can see RS level, as a market timing technique, enhances the performance of pure MBRL models in terms of various measurements and obtains better profit gain with less riskiness. Besides, our proposed method even resists big drop (less maximum drawdown) during COVID-19 pandemic period when the financial market got unpredictable crisis. Explanations on why control of resistance and support level can boost MBRL is also investigated through numerical experiments, such as loss of actor-critic network and prediction error of the transition dynamical model. It shows that RS indicators indeed help the MBRL algorithms to converge faster at early stage and obtain smaller critic loss as training episodes increase. ","authors":"Huifang Huang, Ting Gao, Yi Gui, Jin Guo, Peng Zhang","pdf":"http://arxiv.org/pdf/2205.15056v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14528v2","published":"Sat, 28 May 2022 21:44:41 GMT","title":"Measuring the Monetary Value of Online Volunteer Work","summary":"  Online volunteers are a crucial labor force that keeps many for-profit systems afloat (e.g. social media platforms and online review sites). Despite their substantial role in upholding highly valuable technological systems, online volunteers have no way of knowing the value of their work. This paper uses content moderation as a case study and measures its monetary value to make apparent volunteer labor's value. Using a novel dataset of private logs generated by moderators, we use linear mixed-effect regression and estimate that Reddit moderators worked a minimum of 466 hours per day in 2020. These hours amount to 3.4 million USD a year based on the median hourly wage for comparable content moderation services in the U.S. We discuss how this information may inform pathways to alleviate the one-sided relationship between technology companies and online volunteers. ","comment":"This is a preprint. The paper will be presented at the 2022   International Conference on Web and Social Media (ICWSM'22)","authors":"Hanlin Li, Brent Hecht, Stevie Chancellor","pdf":"http://arxiv.org/pdf/2205.14528v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.13888v2","published":"Fri, 27 May 2022 10:39:28 GMT","title":"Workload-Aware Game-Theoretic Framework for Wireless Federated Learning","summary":"  Federated learning (FL) has been proposed as a popular learning framework to protect the users' data privacy but it has difficulties in motivating the users to participate in task training. This paper proposes a Bertrand-game-based framework for FL in wireless networks, where the model server as a resource buyer can issue an FL task, whereas the employed user equipment (UEs) as the resource sellers can help train the model by using their local data. Specially, the influence of time-varying \\\\textit{task load} and \\\\textit{channel quality} on UE's motivation to participate in FL is considered. Firstly, we adopt the finite-state discrete-time Markov chain (FSDT-MC) method to predict the \\\\textit{existing task load} and \\\\textit{channel gain} of a UE during a FL task. Depending on the performance metrics set by the model server and the estimated overall energy cost for engaging in the FL task, each UE seeks the best price to maximize its own profit in the game. To this end, the Nash equilibrium (NE) of the game is obtained in closed form, and a distributed iterative algorithm is also developed to find the NE. Simulation result verifies the effectiveness of the proposed approach. ","authors":"Jiawei Liu, Guopeng Zhang, Kezhi Wang, Kun Yang","pdf":"http://arxiv.org/pdf/2205.13888v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03255v1","published":"Thu, 26 May 2022 22:02:54 GMT","title":"Do interests affect grant application success? The role of   organizational proximity","summary":"  Bias in grant allocation is a critical issue, as the expectation is that grants are given to the best researchers, and not to applicants that are socially, organizationally, or topic-wise near-by the decision-makers. In this paper, we investigate the effect of organizational proximity, defined as an applicant with the same affiliation as one of the panel members (a near-by panelist), on the probability of getting a grant. This study is based on one of the most prominent grant schemes in Europe, with overall excellent scientists as panel members. Various aspects of this organizational proximity are analyzed: Who gains from it? Does it have a gender dimension? Is it bias, or can it be explained by performance differences? We do find that the probability to get funded increases significantly for those that apply in a panel where there is a panelist from the institution where the applicant has agreed to use the grant. At the same time, the effect differs between disciplines and countries, and men profit more of it than women do. Finally, depending on how one defines what counts as the best researchers, the near-by panelist effect can be interpreted as preferential attachment (quality links to quality) or as bias and particularism. ","comment":"20 pager, 2 figures, 6 tables, preprint","authors":"Charlie Mom, Peter van den Besselaar","pdf":"http://arxiv.org/pdf/2206.03255v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.13025v1","published":"Wed, 25 May 2022 19:26:55 GMT","title":"Railroad Bailouts in the Great Depression","summary":"  The Reconstruction Finance Corporation and Public Works Administration loaned 45 railroads over $802 million between 1932 and 1939. The government goal was to decrease the likelihood of bond defaults and increase employment. Bailed-out railroads did not increase profitability or employment. Instead, they reduced leverage. Bailing out a railroad had little effect on its stock price, but it resulted in an increase in its bond prices and reduced the likelihood of a ratings downgrade. However, bailouts did not help railroads avoid defaulting on their debt. We find some evidence that manufacturing firms located close to railroads benefited from the bailouts. ","comment":"40 pages, 4 figures, 11 tables","authors":"Lyndon Moore, Gertjan Verdickt","pdf":"http://arxiv.org/pdf/2205.13025v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12176v1","published":"Tue, 24 May 2022 16:19:32 GMT","title":"A Dynamic, Interpreted CheckList for Meaning-oriented NLG Metric   Evaluation -- through the Lens of Semantic Similarity Rating","summary":"  Evaluating the quality of generated text is difficult, since traditional NLG evaluation metrics, focusing more on surface form than meaning, often fail to assign appropriate scores. This is especially problematic for AMR-to-text evaluation, given the abstract nature of AMR. Our work aims to support the development and improvement of NLG evaluation metrics that focus on meaning, by developing a dynamic CheckList for NLG metrics that is interpreted by being organized around meaning-relevant linguistic phenomena. Each test instance consists of a pair of sentences with their AMR graphs and a human-produced textual semantic similarity or relatedness score. Our CheckList facilitates comparative evaluation of metrics and reveals strengths and weaknesses of novel and traditional metrics. We demonstrate the usefulness of CheckList by designing a new metric GraCo that computes lexical cohesion graphs over AMR concepts. Our analysis suggests that GraCo presents an interesting NLG metric worth future investigation and that meaning-oriented NLG metrics can profit from graph-based metric components using AMR. ","comment":"to appear in *SEM 2022","authors":"Laura Zeidler, Juri Opitz, Anette Frank","pdf":"http://arxiv.org/pdf/2205.12176v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.11295v1","published":"Mon, 23 May 2022 13:32:22 GMT","title":"Pareto-Improving Data-Sharing","summary":"  We study the effects of data sharing between firms on prices, profits, and consumer welfare. Although indiscriminate sharing of consumer data decreases firm profits due to the subsequent increase in competition, selective sharing can be beneficial. We show that there are data-sharing mechanisms that are strictly Pareto-improving, simultaneously increasing firm profits and consumer welfare. Within the class of Pareto-improving mechanisms, we identify one that maximizes firm profits and one that maximizes consumer welfare. ","authors":"Ronen Gradwohl, Moshe Tennenholtz","pdf":"http://arxiv.org/pdf/2205.11295v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.10910v1","published":"Sun, 22 May 2022 19:28:01 GMT","title":"Mechanisms without transfers for fully biased agents","summary":"  A principal must decide between two options. Which one she prefers depends on the private information of two agents. One agent always prefers the first option; the other always prefers the second. Transfers are infeasible. One application of this setting is the efficient division of a fixed budget between two competing departments. We first characterize all implementable mechanisms under arbitrary correlation. Second, we study when there exists a mechanism that yields the principal a higher payoff than she could receive by choosing the ex-ante optimal decision without consulting the agents. In the budget example, such a profitable mechanism exists if and only if the information of one department is also relevant for the expected returns of the other department. We generalize this insight to derive necessary and sufficient conditions for the existence of a profitable mechanism in the n-agent allocation problem with independent types. ","authors":"Deniz Kattwinkel, Axel Niemeyer, Justus Preusser, Alexander Winter","pdf":"http://arxiv.org/pdf/2205.10910v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.09673v1","published":"Thu, 19 May 2022 16:32:36 GMT","title":"Detect Professional Malicious User with Metric Learning in Recommender   Systems","summary":"  In e-commerce, online retailers are usually suffering from professional malicious users (PMUs), who utilize negative reviews and low ratings to their consumed products on purpose to threaten the retailers for illegal profits. Specifically, there are three challenges for PMU detection: 1) professional malicious users do not conduct any abnormal or illegal interactions (they never concurrently leave too many negative reviews and low ratings at the same time), and they conduct masking strategies to disguise themselves. Therefore, conventional outlier detection methods are confused by their masking strategies. 2) the PMU detection model should take both ratings and reviews into consideration, which makes PMU detection a multi-modal problem. 3) there are no datasets with labels for professional malicious users in public, which makes PMU detection an unsupervised learning problem. To this end, we propose an unsupervised multi-modal learning model: MMD, which employs Metric learning for professional Malicious users Detection with both ratings and reviews. MMD first utilizes a modified RNN to project the informational review into a sentiment score, which jointly considers the ratings and reviews. Then professional malicious user profiling (MUP) is proposed to catch the sentiment gap between sentiment scores and ratings. MUP filters the users and builds a candidate PMU set. We apply a metric learning-based clustering to learn a proper metric matrix for PMU detection. Finally, we can utilize this metric and labeled users to detect PMUs. Specifically, we apply the attention mechanism in metric learning to improve the model's performance. The extensive experiments in four datasets demonstrate that our proposed method can solve this unsupervised detection problem. Moreover, the performance of the state-of-the-art recommender models is enhanced by taking MMD as a preprocessing stage. ","comment":"Accepted by IEEE Transactions on Knowledge and Data Engineering   (TKDE)","authors":"Yuanbo Xu, Yongjian Yang, En Wang, Fuzhen Zhuang, Hui Xiong","pdf":"http://arxiv.org/pdf/2205.09673v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.09434v1","published":"Thu, 19 May 2022 09:49:46 GMT","title":"Time-dependent effects hinder cooperation on the public goods game","summary":"  The public goods game is a model of a society investing some assets and regaining a profit, although can also model biological populations. In the classic public goods game only two strategies compete: either cooperate or defect; a third strategy is often implemented to asses punishment, which is a mechanism to promote cooperation. The conditions of the game can be of a dynamical nature, therefore we study time-dependent effects such an as oscillation in the enhancement factor, which accounts for productivity changes over time. Furthermore, we continue to study time dependencies on the game with a delay on the punishment time. We conclude that both the oscillations on the productivity and the punishment delay concur in the detriment of cooperation. ","comment":"Accepted in the journal Chaos Solitons and Fractals, May 2022","authors":"Gaspar Alfaro, Miguel A. F. Sanjuan","pdf":"http://arxiv.org/pdf/2205.09434v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.08956v2","published":"Wed, 18 May 2022 14:31:40 GMT","title":"Marx after Okishio: Falling Rate of Profit with Constant Rate of   Exploitation","summary":"  Can cost-reducing technical change lead to a fall in the long run rate of profit if class struggle manages to keep the rate of exploitation constant? In a general circulating capital model, we derive sufficient conditions for cost-reducing technical change to both keep the rate of exploitation constant and lead to a fall in the equilibrium rate of profit. Further, if the real wage bundle is such that the maximum price-value ratio is larger than 1 plus the rate of exploitation, then starting from any configuration of technology and real wage, we can always find a viable, CU-LS technical change that satisfies the sufficient conditions for the previous result. Taken together, these results vindicate Marx's claim in Volume III of Capital, that if the rate of exploitation remains unchanged then viable, CU-LS technical change in capitalist economies can lead to a fall in the long run rate of profit. ","authors":"Deepankar Basu, Oscar Orellana","pdf":"http://arxiv.org/pdf/2205.08956v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.08493v1","published":"Tue, 17 May 2022 17:08:30 GMT","title":"Faster Knapsack Algorithms via Bounded Monotone Min-Plus-Convolution","summary":"  We present new exact and approximation algorithms for 0-1-Knapsack and Unbounded Knapsack:   * Exact Algorithm for 0-1-Knapsack: 0-1-Knapsack has known algorithms running in time $\\\\widetilde{O}(n + \\\\min\\\\{n OPT, n W, OPT^2, W^2\\\\})$, where $n$ is the number of items, $W$ is the weight budget, and $OPT$ is the optimal profit. We present an algorithm running in time $\\\\widetilde{O}(n + (W + OPT)^{1.5})$. This improves the running time in case $n,W,OPT$ are roughly equal.   * Exact Algorithm for Unbounded Knapsack: Unbounded Knapsack has known algorithms running in time $\\\\widetilde{O}(n + \\\\min\\\\{n \\\\cdot p_{\\\\max}, n \\\\cdot w_{\\\\max}, p_{\\\\max}^2, w_{\\\\max}^2\\\\})$ [Axiotis, Tzamos '19, Jansen, Rohwedder '19, Chan, He '20], where $n$ is the number of items, $w_{\\\\max}$ is the largest weight of any item, and $p_{\\\\max}$ is the largest profit of any item. We present an algorithm running in time $\\\\widetilde{O}(n + (p_{\\\\max} + w_{\\\\max})^{1.5})$, giving a similar improvement as for 0-1-Knapsack.   * Approximating Unbounded Knapsack with Resource Augmentation: Unbounded Knapsack has a known FPTAS with running time $\\\\widetilde{O}(\\\\min\\\\{n/\\\\varepsilon, n + 1/\\\\varepsilon^2\\\\})$ [Jansen, Kraft '18]. We study weak approximation algorithms, which approximate the optimal profit but are allowed to overshoot the weight constraint. We present the first approximation scheme for Unbounded Knapsack in this setting, achieving running time $\\\\widetilde{O}(n + 1/\\\\varepsilon^{1.5})$.   Our algorithms can be seen as reductions to Min-Plus-Convolution on monotone sequences with bounded entries. These structured instances of Min-Plus-Convolution can be solved in time $O(n^{1.5})$ [Chi,Duan,Xie,Zhang '22] (in contrast to the conjectured $n^{2-o(1)}$ lower bound for the general case). ","comment":"Shortened abstract. Appears at ICALP '22","authors":"Karl Bringmann, Alejandro Cassis","pdf":"http://arxiv.org/pdf/2205.08493v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07617v1","published":"Mon, 16 May 2022 12:22:46 GMT","title":"Analysis of Distributed Ledger Technologies for Industrial Manufacturing","summary":"  In recent years, industrial manufacturing has undergone massive technological changes that embrace digitalization and automation towards the vision of intelligent manufacturing plants. With the aim of maximizing efficiency and profitability in production, an important goal is to enable flexible manufacturing, both, for the customer (desiring more individualized products) and for the manufacturer (to adjust to market demands). Manufacturing-as-a-service can support this through manufacturing plants that are used by different tenants who utilize the machines in the plant, which are offered by different providers. To enable such pay-per-use business models, Distributed Ledger Technology (DLT) is a viable option to establish decentralized trust and traceability. Thus, in this paper, we study potential DLT technologies for an efficient and intelligent integration of DLT-based solutions in manufacturing environments. We propose a general framework to adapt DLT in manufacturing, then we introduce the use case of shared manufacturing, which we utilize to study the communication and computation efficiency of selected DLTs in resource-constrained wireless IoT networks. ","comment":"19 pages, 4 figures, submitted for publication","authors":"Lam Duc Nguyen, Arne Broering, Massimo Pizzol, Petar Popovski","pdf":"http://arxiv.org/pdf/2205.07617v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07615v1","published":"Mon, 16 May 2022 12:15:41 GMT","title":"Approximate dynamic programming for profit estimation of connected hydro   reservoirs","summary":"  In this paper, we study the operational problem of connected hydro power reservoirs which involves sequential decision-making in an uncertain and dynamic environment. The problem is traditionally formulated as a stochastic dynamic program accounting for the uncertainty of electricity prices and reservoir inflows. This formulation suffers from the curse of dimensionality, as the state space explodes with the number of reservoirs and the history of prices and inflows. To avoid computing the expectation of future value functions, the proposed model takes advantage of the so-called post-decision state. To further tackle the dimensionality issue, we propose an approximate dynamic programming approach that estimates the future value of water using a linear approximation architecture. When the time series of prices and inflows follow autoregressive processes, our approximation provides an upper bound on the future value function. We use an offline training algorithm based on the historical data of prices and inflows and run both in-sample and out-of-sample simulations. Two realistic test systems of cascade and network connected reservoirs serve to demonstrate the computational tractability of our approach. In particular, we provide numerical evidence of convergence and quality of solutions. For our test systems, our results show that profit estimation is improved by 20% when including inflows in the linear approximation. ","authors":"Farzaneh Pourahmadi, Trine Krogh Boomsma","pdf":"http://arxiv.org/pdf/2205.07615v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07486v1","published":"Mon, 16 May 2022 07:37:14 GMT","title":"Polarization and Quid Pro Quo: The Role of Party Cohesiveness","summary":"  When can an interest group exploit ideological and affective polarization between political parties to its advantage? We study a model where an interest group credibly promises payments to legislators conditional on voting for its favored policy. Legislators value voting as their friends within their party, and suffer an ideological-disutility upon voting against their party's ideologically preferred policy. Affective polarization, owing to its interpersonal nature, is modeled by assuming a legislator values distinguishing her voting decision from legislators in the opposite party. Our main finding is that an aggregate measure of relative cohesiveness of social networks in the two parties determines whether the interest group can profitably exploit increasing polarization. However, the significance of relative cohesiveness vanishes if there is no ideological polarization between the two parties. ","authors":"Ratul Das Chaudhury, C. Matthew Leister, Birendra Rai","pdf":"http://arxiv.org/pdf/2205.07486v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07334v1","published":"Sun, 15 May 2022 17:09:25 GMT","title":"Mack-Net model: Blending Mack's model with Recurrent Neural Networks","summary":"  In general insurance companies, a correct estimation of liabilities plays a key role due to its impact on management and investing decisions. Since the Financial Crisis of 2007-2008 and the strengthening of regulation, the focus is not only on the total reserve but also on its variability, which is an indicator of the risk assumed by the company. Thus, measures that relate profitability with risk are crucial in order to understand the financial position of insurance firms. Taking advantage of the increasing computational power, this paper introduces a stochastic reserving model whose aim is to improve the performance of the traditional Mack's reserving model by applying an ensemble of Recurrent Neural Networks. The results demonstrate that blending traditional reserving models with deep and machine learning techniques leads to a more accurate assessment of general insurance liabilities. ","authors":"Eduardo Ramos-Pérez, Pablo J. Alonso-González, José Javier Núñez-Velázquez","pdf":"http://arxiv.org/pdf/2205.07334v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.06812v1","published":"Fri, 13 May 2022 17:59:23 GMT","title":"Principal-Agent Hypothesis Testing","summary":"  Consider the relationship between the FDA (the principal) and a pharmaceutical company (the agent). The pharmaceutical company wishes to sell a product to make a profit, and the FDA wishes to ensure that only efficacious drugs are released to the public. The efficacy of the drug is not known to the FDA, so the pharmaceutical company must run a costly trial to prove efficacy to the FDA. Critically, the statistical protocol used to establish efficacy affects the behavior of a strategic, self-interested pharmaceutical company; a lower standard of statistical evidence incentivizes the pharmaceutical company to run more trials for drugs that are less likely to be effective, since the drug may pass the trial by chance, resulting in large profits. The interaction between the statistical protocol and the incentives of the pharmaceutical company is crucial to understanding this system and designing protocols with high social utility. In this work, we discuss how the principal and agent can enter into a contract with payoffs based on statistical evidence. When there is stronger evidence for the quality of the product, the principal allows the agent to make a larger profit. We show how to design contracts that are robust to an agent's strategic actions, and derive the optimal contract in the presence of strategic behavior. ","authors":"Stephen Bates, Michael I. Jordan, Michael Sklar, Jake A. Soloff","pdf":"http://arxiv.org/pdf/2205.06812v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.06760v1","published":"Fri, 13 May 2022 16:44:51 GMT","title":"Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning","summary":"  Advances in artificial intelligence often stem from the development of new environments that abstract real-world situations into a form where research can be done conveniently. This paper contributes such an environment based on ideas inspired by elementary Microeconomics. Agents learn to produce resources in a spatially complex world, trade them with one another, and consume those that they prefer. We show that the emergent production, consumption, and pricing behaviors respond to environmental conditions in the directions predicted by supply and demand shifts in Microeconomics. We also demonstrate settings where the agents' emergent prices for goods vary over space, reflecting the local abundance of goods. After the price disparities emerge, some agents then discover a niche of transporting goods between regions with different prevailing prices -- a profitable strategy because they can buy goods where they are cheap and sell them where they are expensive. Finally, in a series of ablation experiments, we investigate how choices in the environmental rewards, bartering actions, agent architecture, and ability to consume tradable goods can either aid or inhibit the emergence of this economic behavior. This work is part of the environment development branch of a research program that aims to build human-like artificial general intelligence through multi-agent interactions in simulated societies. By exploring which environment features are needed for the basic phenomena of elementary microeconomics to emerge automatically from learning, we arrive at an environment that differs from those studied in prior multi-agent reinforcement learning work along several dimensions. For example, the model incorporates heterogeneous tastes and physical abilities, and agents negotiate with one another as a grounded form of communication. ","authors":"Michael Bradley Johanson, Edward Hughes, Finbarr Timbers, Joel Z. Leibo","pdf":"http://arxiv.org/pdf/2205.06760v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07627v1","published":"Fri, 13 May 2022 10:34:57 GMT","title":"KnowGraph-PM: a Knowledge Graph based Pricing Model for Semiconductors   Supply Chains","summary":"  Semiconductor supply chains are described by significant demand fluctuation that increases as one moves up the supply chain, the so-called bullwhip effect. To counteract, semiconductor manufacturers aim to optimize capacity utilization, to deliver with shorter lead times and exploit this to generate revenue. Additionally, in a competitive market, firms seek to maintain customer relationships while applying revenue management strategies such as dynamic pricing. Price change potentially generates conflicts with customers. In this paper, we present KnowGraph-PM, a knowledge graph-based dynamic pricing model. The semantic model uses the potential of faster delivery and shorter lead times to define premium prices, thus entail increased profits based on the customer profile. The knowledge graph enables the integration of customer-related information, e.g., customer class and location to customer order data. The pricing algorithm is realized as a SPARQL query that relies on customer profile and order behavior to determine the corresponding price premium. We evaluate the approach by calculating the revenue generated after applying the pricing algorithm. Based on competency questions that translate to SPARQL queries, we validate the created knowledge graph. We demonstrate that semantic data integration enables customer-tailored revenue management. ","authors":"Nour Ramzy, Soren Auer, Javad Chamanara, Hans Ehm","pdf":"http://arxiv.org/pdf/2205.07627v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.04661v1","published":"Tue, 10 May 2022 04:15:21 GMT","title":"Pricing with algorithms","summary":"  This paper studies Markov perfect equilibria in a repeated duopoly model where sellers choose algorithms. An algorithm is a mapping from the competitor's price to own price. Once set, algorithms respond quickly. Customers arrive randomly and so do opportunities to revise the algorithm. In the simple game with two possible prices, monopoly outcome is the unique equilibrium for standard functional forms of the profit function. More generally, with multiple prices, exercise of market power is the rule -- in all equilibria, the expected payoff of both sellers is above the competitive outcome, and that of at least one seller is close to or above the monopoly outcome. Sustenance of such collusion seems outside the scope of standard antitrust laws for it does not involve any direct communication. ","authors":"Rohit Lamba, Sergey Zhuk","pdf":"http://arxiv.org/pdf/2205.04661v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.04319v1","published":"Mon, 09 May 2022 14:22:15 GMT","title":"Competition and Cooperation of Autonomous Ridepooling Services:   Game-Based Simulation of a Broker Concept","summary":"  Autonomous mobility on demand services have the potential to disrupt the future mobility system landscape. Ridepooling services in particular can decrease land consumption and increase transportation efficiency by increasing the average vehicle occupancy. Nevertheless, because ridepooling services require a sufficient user base for pooling to take effect, their performance can suffer if multiple operators offer such a service and must split the demand. This study presents a simulation framework for evaluating the impact of competition and cooperation among multiple ridepooling providers. Two different kinds of interaction via a broker platform are compared with the base cases of a single monopolistic operator and two independent operators with divided demand. In the first, the broker presents trip offers from all operators to customers (similar to a mobility-as-a-service platform), who can then freely choose an operator. In the second, a regulated broker platform can manipulate operator offers with the goal of shifting the customer-operator assignment from a user equilibrium towards a system optimum. To model adoptions of the service design depending on the different interaction scenario, a game setting is introduced. Within alternating turns between operators, operators can adapt parameters of their service (fleet size and objective function) to maximize profit. Results for a case study based on Manhattan taxi data, show that operators generate the highest profit in the broker setting while operating the largest fleet. Additionally, pooling efficiency can nearly be maintained compared to a single operator. With the resulting increased service rate, the regulated competition benefits not only operators (profit) and cities (increased pooling efficiency), but also customers. Contrarily, when users can decide freely, the lowest pooling efficiency and operator profit is observed. ","comment":"Submitted to Frontiers in Future Transportation","authors":"Roman Engelhardt, Patrick Malcolm, Florian Dandl, Klaus Bogenberger","pdf":"http://arxiv.org/pdf/2205.04319v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.03495v1","published":"Fri, 06 May 2022 22:51:25 GMT","title":"Credible Persuasion","summary":"  We propose a new notion of credibility for Bayesian persuasion problems. A disclosure policy is credible if the sender cannot profit from tampering with her messages while keeping the message distribution unchanged. We show that the credibility of a disclosure policy is equivalent to a cyclical monotonicity condition on its induced distribution over states and actions. We also characterize how credibility restricts the Sender's ability to persuade under different payoff structures. In particular, when the sender's payoff is state-independent, all disclosure policies are credible. We apply our results to the market for lemons, and show that no useful information can be credibly disclosed by the seller, even though a seller who can commit to her disclosure policy would perfectly reveal her private information to maximize profit. ","authors":"Xiao Lin, Ce Liu","pdf":"http://arxiv.org/pdf/2205.03495v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.02017v1","published":"Wed, 04 May 2022 11:56:33 GMT","title":"So (2, 1) algebra, local Fermi velocity, and position-dependent mass   Dirac equation","summary":"  We investigate the (1+1)-dimensional position-dependent mass Dirac equation within the confines of so(2,1) potential algebra by utilizing the character of a spatial varying Fermi velocity. We examine the combined effects of the two when the Dirac equation is equipped with an external pseuodoscalar potential. Solutions of the three cases induced by so(2, 1) are explored by profitably making use of a point canonical transformation. ","comment":"11 pages","authors":"Bijan Bagchi, Rahul Ghosh, Christiane Quesne","pdf":"http://arxiv.org/pdf/2205.02017v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.01802v1","published":"Tue, 03 May 2022 22:13:33 GMT","title":"A Review on Pushing the Limits of Baseline Recommendation Systems with   the integration of Opinion Mining & Information Retrieval Techniques","summary":"  Recommendations Systems allow users to identify trending items among a community while being timely and relevant to the user's expectations. When the purpose of various Recommendation Systems differs, the required type of recommendations also differs for each use case. While one Recommendation System may focus on recommending popular items, another may focus on recommending items that are comparable to the user's interests. Content-based filtering, user-to-user & item-to-item Collaborative filtering, and more recently; Deep Learning methods have been brought forward by the researchers to achieve better quality recommendations.   Even though each of these methods has proven to perform well individually, there have been attempts to push the boundaries of their limitations. Following a wide range of methods, researchers have tried to expand on the capabilities of standard recommendation systems to provide the most effective recommendations to users while being more profitable from a business's perspective. This has been achieved by taking a hybrid approach when building models and architectures for Recommendation Systems.   This paper is a review of the novel models & architectures of hybrid Recommendation Systems. The author identifies possibilities of expanding the capabilities of baseline models & the advantages and drawbacks of each model with selected use cases in this review. ","authors":"Dinuka Ravijaya Piyadigama, Guhanathan Poravi","pdf":"http://arxiv.org/pdf/2205.01802v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.01768v1","published":"Tue, 03 May 2022 20:35:17 GMT","title":"Traversing Supervisor Problem: An Approximately Optimal Approach to   Multi-Robot Assistance","summary":"  The number of multi-robot systems deployed in field applications has increased dramatically over the years. Despite the recent advancement of navigation algorithms, autonomous robots often encounter challenging situations where the control policy fails and the human assistance is required to resume robot tasks. Human-robot collaboration can help achieve high-levels of autonomy, but monitoring and managing multiple robots at once by a single human supervisor remains a challenging problem. Our goal is to help a supervisor decide which robots to assist in which order such that the team performance can be maximized. We formulate the one-to-many supervision problem in uncertain environments as a dynamic graph traversal problem. An approximation algorithm based on the profitable tour problem on a static graph is developed to solve the original problem, and the approximation error is bounded and analyzed. Our case study on a simulated autonomous farm demonstrates superior team performance than baseline methods in task completion time and human working time, and that our method can be deployed in real-time for robot fleets with moderate size. ","comment":"RSS 2022 Camera Ready Version","authors":"Tianchen Ji, Roy Dong, Katherine Driggs-Campbell","pdf":"http://arxiv.org/pdf/2205.01768v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.01313v1","published":"Tue, 03 May 2022 05:39:22 GMT","title":"cuPSO: GPU Parallelization for Particle Swarm Optimization Algorithms","summary":"  Particle Swarm Optimization (PSO) is a stochastic technique for solving the optimization problem. Attempts have been made to shorten the computation times of PSO based algorithms with massive threads on GPUs (graphic processing units), where thread groups are formed to calculate the information of particles and the computed outputs for the particles are aggregated and analyzed to find the best solution. In particular, the reduction-based method is considered as a common approach to handle the data aggregation and analysis for the calculated particle information. Nevertheless, based on our analysis, the reduction-based method would suffer from excessive memory accesses and thread synchronization overheads. In this paper, we propose a novel algorithm to alleviate the above overheads with the atomic functions. The threads within a thread group update the calculated results atomically to the intra-group data queue conditionally, which prevents the frequent accesses to the memory as done by the parallel reduction operations. Furthermore, we develop an enhanced version of the algorithm to alleviate the synchronization barrier among the thread groups, which is achieved by allowing the thread groups to run asynchronously and updating to the global, lock-protected variables occasionally if necessary. Our experimental results show that our proposed algorithm running on the Nvidia GPU is about 200 times faster than the serial version executed by the Intel Xeon CPU. Moreover, the novel algorithm outperforms the state-of-the-art method (the parallel reduction approach) by a factor of 2.2. ","comment":"Permission to make digital or hard copies of part or all of this work   for personal or classroom use is granted without fee provided that copies are   not made or distributed for profit or commercial advantage and that copies   bear this notice and the full citation on the first page. Copyrights for   third-party components of this work must be honored. For all other uses,   contact the owner/author(s)","authors":"Chuan-Chi Wang, Chun-Yen Ho, Chia-Heng Tu, Shih-Hao Hung","pdf":"http://arxiv.org/pdf/2205.01313v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.04634v1","published":"Thu, 09 Jun 2022 17:29:32 GMT","title":"The Economics of Automated Market Makers","summary":"  This paper studies the question whether automated market maker protocols such as Uniswap can sustainably retain a portion of their trading fees for the protocol. We approach the problem by modelling how to optimally choose a pool's take rate, i.e\\\\ the fraction of fee revenue that remains with the protocol, in order to maximize the protocol's revenue. The model suggest that if AMMs have a portion of loyal trade volume, they can sustainably set a non-zero take rate, even without losing liquidity to competitors with a zero take rate. Furthermore, we determine the optimal take rate depending on a number of model parameters including how much loyal trade volume pools have and how high the competitors' take rates are. ","authors":"Robin Fritsch, Samuel Käser, Roger Wattenhofer","pdf":"http://arxiv.org/pdf/2206.04634v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.04185v1","published":"Wed, 08 Jun 2022 22:52:24 GMT","title":"A Flash(bot) in the Pan: Measuring Maximal Extractable Value in Private   Pools","summary":"  The rise of Ethereum has lead to a flourishing decentralized marketplace that has, unfortunately, fallen victim to frontrunning and Maximal Extractable Value (MEV) activities, where savvy participants game transaction orderings within a block for profit. One popular solution to address such behavior is Flashbots, a private pool with infrastructure and design goals aimed at eliminating the negative externalities associated with MEV. While Flashbots has established laudable goals to address MEV behavior, no evidence has been provided to show that these goals are achieved in practice.   In this paper, we measure the popularity of Flashbots and evaluate if it is meeting its chartered goals. We find that (1) Flashbots miners account for over 99.9% of the hashing power in the Ethereum network, (2) powerful miners are making more than $2\\\\times$ what they were making prior to using Flashbots, while non-miners' slice of the pie has shrunk commensurately, (3) mining is just as centralized as it was prior to Flashbots with more than 90% of Flashbots blocks coming from just two miners, and (4) while more than 80% of MEV extraction in Ethereum is happening through Flashbots, 13.2% is coming from other private pools. ","comment":"15 pages","authors":"Ben Weintraub, Christof Ferreira Torres, Cristina Nita-Rotaru, Radu State","pdf":"http://arxiv.org/pdf/2206.04185v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.04184v1","published":"Wed, 08 Jun 2022 22:36:54 GMT","title":"Abstraction not Memory: BERT and the English Article System","summary":"  Article prediction is a task that has long defied accurate linguistic description. As such, this task is ideally suited to evaluate models on their ability to emulate native-speaker intuition. To this end, we compare the performance of native English speakers and pre-trained models on the task of article prediction set up as a three way choice (a/an, the, zero). Our experiments with BERT show that BERT outperforms humans on this task across all articles. In particular, BERT is far superior to humans at detecting the zero article, possibly because we insert them using rules that the deep neural model can easily pick up. More interestingly, we find that BERT tends to agree more with annotators than with the corpus when inter-annotator agreement is high but switches to agreeing more with the corpus as inter-annotator agreement drops. We contend that this alignment with annotators, despite being trained on the corpus, suggests that BERT is not memorising article use, but captures a high level generalisation of article use akin to human intuition. ","comment":"Accepted for publication at 2022 Annual Conference of the North   American Chapter of the Association for Computational Linguistics (NAACL   2022). Data and code available at   https://github.com/H-TayyarMadabushi/Abstraction-not-Memory-BERT-and-the-English-Article-System-NAACL-2022","authors":"Harish Tayyar Madabushi, Dagmar Divjak, Petar Milin","pdf":"http://arxiv.org/pdf/2206.04184v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.04141v1","published":"Wed, 08 Jun 2022 20:08:15 GMT","title":"Role of Blockchain in Revolutionizing Online Transactional Security","summary":"  This paper highlights the necessity to use modern blockchain technology in traditional banking sector to reduce frauds and enable high-security transactions on a permanent blockchain ledger. Reviewing different channels through which the traditional banking servers could integrate blockchain use, it is signified how a huge anti-fraud stand can be taken against bank servers allowing fraudulent transactions daily. Usage of a blockchain-based ledger is highly impactful in terms of security of a banking organization. Blockchain-based currency tokens, also referred to as Cryptocurrencies are not regulated by the government, highly volatile, and anonymous to use. Furthermore, there is no security for any funds invested in a cryptocurrency market. However, the integration of a blockchain ledger in a traditional banking organization would strengthen the security to provide more stability and confidence to its customers and at the same time, make blockchain a more reliable method to consider due to being trusted by large financial organizations. ","authors":"Rishav Kumar","pdf":"http://arxiv.org/pdf/2206.04141v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03737v1","published":"Wed, 08 Jun 2022 08:24:01 GMT","title":"Decentralized, not Dehumanized in the Metaverse: Bringing Utility to   NFTs through Multimodal Interaction","summary":"  User Interaction for NFTs (Non-fungible Tokens) is gaining increasing attention. Although NFTs have been traditionally single-use and monolithic, recent applications aim to connect multimodal interaction with human behaviour. This paper reviews the related technological approaches and business practices in NFT art. We highlight that multimodal interaction is a currently under-studied issue in mainstream NFT art, and conjecture that multimodal interaction is a crucial enabler for decentralization in the NFT community. We propose a framework that combines a bottom-up approach with AI multimodal process. Through this framework, we put forward integrating human behaviour data into generative NFT units, as \\multimodal interactive NFT\\. Our work displays the possibilities of NFTs in the art world, beyond the traditional 2D and 3D static content. ","comment":"7 pages, 5 figures","authors":"Anqi Wang, Ze Gao, Lik-Hang Lee, Tristan Braud, Pan Hui","pdf":"http://arxiv.org/pdf/2206.03737v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03018v1","published":"Tue, 07 Jun 2022 05:22:42 GMT","title":"What is the Metaverse? An Immersive Cyberspace and Open Challenges","summary":"  The Metaverse refers to a virtual-physical blended space in which multiple users can concurrently interact with a unified computer-generated environment and other users, which can be regarded as the next significant milestone of the current cyberspace. This article primarily discusses the development and challenges of the Metaverse. We first briefly describe the development of cyberspace and the necessity of technology enablers. Accordingly, our bottom-up approach highlights three critical technology enablers for the Metaverse: networks, systems, and users. Also, we highlight a number of indispensable issues, under technological and ecosystem perspectives, that build and sustain the Metaverse. ","comment":"7 pages, 2 figures","authors":"Lik-Hang Lee, Pengyuan Zhou, Tristan Braud, Pan Hui","pdf":"http://arxiv.org/pdf/2206.03018v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02892v1","published":"Mon, 06 Jun 2022 20:32:58 GMT","title":"Discriminative Models Can Still Outperform Generative Models in Aspect   Based Sentiment Analysis","summary":"  Aspect-based Sentiment Analysis (ABSA) helps to explain customers' opinions towards products and services. In the past, ABSA models were discriminative, but more recently generative models have been used to generate aspects and polarities directly from text. In contrast, discriminative models commonly first select aspects from the text, and then classify the aspect's polarity. Previous results showed that generative models outperform discriminative models on several English ABSA datasets. Here, we evaluate and contrast two state-of-the-art discriminative and generative models in several settings: cross-lingual, cross-domain, and cross-lingual and domain, to understand generalizability in settings other than English mono-lingual in-domain. Our more thorough evaluation shows that, contrary to previous studies, discriminative models can still outperform generative models in almost all settings. ","authors":"Dhruv Mullick, Alona Fyshe, Bilal Ghanem","pdf":"http://arxiv.org/pdf/2206.02892v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02389v1","published":"Mon, 06 Jun 2022 06:45:43 GMT","title":"A sentiment analysis model for car review texts based on adversarial   training and whole word mask BERT","summary":"  In the field of car evaluation, more and more netizens choose to express their opinions on the Internet platform, and these comments will affect the decision-making of buyers and the trend of car word-of-mouth. As an important branch of natural language processing (NLP), sentiment analysis provides an effective research method for analyzing the sentiment types of massive car review texts. However, due to the lexical professionalism and large text noise of review texts in the automotive field, when a general sentiment analysis model is applied to car reviews, the accuracy of the model will be poor. To overcome these above challenges, we aim at the sentiment analysis task of car review texts. From the perspective of word vectors, pre-training is carried out by means of whole word mask of proprietary vocabulary in the automotive field, and then training data is carried out through the strategy of an adversarial training set. Based on this, we propose a car review text sentiment analysis model based on adversarial training and whole word mask BERT(ATWWM-BERT). ","authors":"Xingchen Liu, Yawen Li, Yingxia Shao, Ang Li, Jian Liang","pdf":"http://arxiv.org/pdf/2206.02389v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02160v1","published":"Sun, 05 Jun 2022 12:17:46 GMT","title":"Sentiment Analysis of Online Travel Reviews Based on Capsule Network and   Sentiment Lexicon","summary":"  With the development of online travel services, it has great application prospects to timely mine users' evaluation emotions for travel services and use them as indicators to guide the improvement of online travel service quality. In this paper, we study the text sentiment classification of online travel reviews based on social media online comments and propose the SCCL model based on capsule network and sentiment lexicon. SCCL model aims at the lack of consideration of local features and emotional semantic features of the text in the language model that can efficiently extract text context features like BERT and GRU. Then make the following improvements to their shortcomings. On the one hand, based on BERT-BiGRU, the capsule network is introduced to extract local features while retaining good context features. On the other hand, the sentiment lexicon is introduced to extract the emotional sequence of the text to provide richer emotional semantic features for the model. To enhance the universality of the sentiment lexicon, the improved SO-PMI algorithm based on TF-IDF is used to expand the lexicon, so that the lexicon can also perform well in the field of online travel reviews. ","authors":"Jia Wang, Junping Du, Yingxia Shao, Ang Li","pdf":"http://arxiv.org/pdf/2206.02160v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.02156v1","published":"Sun, 05 Jun 2022 11:54:48 GMT","title":"Perspectives of Non-Expert Users on Cyber Security and Privacy: An   Analysis of Online Discussions on Twitter","summary":"  Current research on users` perspectives of cyber security and privacy related to traditional and smart devices at home is very active, but the focus is often more on specific modern devices such as mobile and smart IoT devices in a home context. In addition, most were based on smaller-scale empirical studies such as online surveys and interviews. We endeavour to fill these research gaps by conducting a larger-scale study based on a real-world dataset of 413,985 tweets posted by non-expert users on Twitter in six months of three consecutive years (January and February in 2019, 2020 and 2021). Two machine learning-based classifiers were developed to identify the 413,985 tweets. We analysed this dataset to understand non-expert users` cyber security and privacy perspectives, including the yearly trend and the impact of the COVID-19 pandemic. We applied topic modelling, sentiment analysis and qualitative analysis of selected tweets in the dataset, leading to various interesting findings. For instance, we observed a 54% increase in non-expert users` tweets on cyber security and/or privacy related topics in 2021, compared to before the start of global COVID-19 lockdowns (January 2019 to February 2020). We also observed an increased level of help-seeking tweets during the COVID-19 pandemic. Our analysis revealed a diverse range of topics discussed by non-expert users across the three years, including VPNs, Wi-Fi, smartphones, laptops, smart home devices, financial security, and security and privacy issues involving different stakeholders. Overall negative sentiment was observed across almost all topics non-expert users discussed on Twitter in all the three years. Our results confirm the multi-faceted nature of non-expert users` perspectives on cyber security and privacy and call for more holistic, comprehensive and nuanced research on different facets of such perspectives. ","comment":"18 pages, 5 figures, submitted to Computers & Security","authors":"Nandita Pattnaik, Shujun Li, Jason R. C. Nurse","pdf":"http://arxiv.org/pdf/2206.02156v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.00192v1","published":"Wed, 01 Jun 2022 02:30:12 GMT","title":"Order-sensitive Shapley Values for Evaluating Conceptual Soundness of   NLP Models","summary":"  Previous works show that deep NLP models are not always conceptually sound: they do not always learn the correct linguistic concepts. Specifically, they can be insensitive to word order. In order to systematically evaluate models for their conceptual soundness with respect to word order, we introduce a new explanation method for sequential data: Order-sensitive Shapley Values (OSV). We conduct an extensive empirical evaluation to validate the method and surface how well various deep NLP models learn word order. Using synthetic data, we first show that OSV is more faithful in explaining model behavior than gradient-based methods. Second, applying to the HANS dataset, we discover that the BERT-based NLI model uses only the word occurrences without word orders. Although simple data augmentation improves accuracy on HANS, OSV shows that the augmented model does not fundamentally improve the model's learning of order. Third, we discover that not all sentiment analysis models learn negation properly: some fail to capture the correct syntax of the negation construct. Finally, we show that pretrained language models such as BERT may rely on the absolute positions of subject words to learn long-range Subject-Verb Agreement. With each NLP task, we also demonstrate how OSV can be leveraged to generate adversarial examples. ","authors":"Kaiji Lu, Anupam Datta","pdf":"http://arxiv.org/pdf/2206.00192v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.15930v1","published":"Tue, 31 May 2022 16:21:00 GMT","title":"Uzbek Sentiment Analysis based on local Restaurant Reviews","summary":"  Extracting useful information for sentiment analysis and classification problems from a big amount of user-generated feedback, such as restaurant reviews, is a crucial task of natural language processing, which is not only for customer satisfaction where it can give personalized services, but can also influence the further development of a company. In this paper, we present a work done on collecting restaurant reviews data as a sentiment analysis dataset for the Uzbek language, a member of the Turkic family which is heavily affected by the low-resource constraint, and provide some further analysis of the novel dataset by evaluation using different techniques, from logistic regression based models, to support vector machines, and even deep learning models, such as recurrent neural networks, as well as convolutional neural networks. The paper includes detailed information on how the data was collected, how it was pre-processed for better quality optimization, as well as experimental setups for the evaluation process. The overall evaluation results indicate that by performing pre-processing steps, such as stemming for agglutinative languages, the system yields better results, eventually achieving 91% accuracy result in the best performing model ","comment":"The International Conference on Agglutinative Language Technologies   as a challenge of Natural Language Processing (ALTNLP) 2022, Koper, Slovenia","authors":"Sanatbek Matlatipov, Hulkar Rahimboeva, Jaloliddin Rajabov, Elmurod Kuriyozov","pdf":"http://arxiv.org/pdf/2205.15930v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.15514v1","published":"Tue, 31 May 2022 03:07:51 GMT","title":"A Knowledge-Enhanced Adversarial Model for Cross-lingual Structured   Sentiment Analysis","summary":"  Structured sentiment analysis, which aims to extract the complex semantic structures such as holders, expressions, targets, and polarities, has obtained widespread attention from both industry and academia. Unfortunately, the existing structured sentiment analysis datasets refer to a few languages and are relatively small, limiting neural network models' performance. In this paper, we focus on the cross-lingual structured sentiment analysis task, which aims to transfer the knowledge from the source language to the target one. Notably, we propose a Knowledge-Enhanced Adversarial Model (\\\\texttt{KEAM}) with both implicit distributed and explicit structural knowledge to enhance the cross-lingual transfer. First, we design an adversarial embedding adapter for learning an informative and robust representation by capturing implicit semantic information from diverse multi-lingual embeddings adaptively. Then, we propose a syntax GCN encoder to transfer the explicit semantic information (e.g., universal dependency tree) among multiple languages. We conduct experiments on five datasets and compare \\\\texttt{KEAM} with both the supervised and unsupervised methods. The extensive experimental results show that our \\\\texttt{KEAM} model outperforms all the unsupervised baselines in various metrics. ","authors":"Qi Zhang, Jie Zhou, Qin Chen, Qingchun Bai, Jun Xiao, Liang He","pdf":"http://arxiv.org/pdf/2205.15514v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.15511v1","published":"Tue, 31 May 2022 02:44:24 GMT","title":"Enhancing Event-Level Sentiment Analysis with Structured Arguments","summary":"  Previous studies about event-level sentiment analysis (SA) usually model the event as a topic, a category or target terms, while the structured arguments (e.g., subject, object, time and location) that have potential effects on the sentiment are not well studied. In this paper, we redefine the task as structured event-level SA and propose an End-to-End Event-level Sentiment Analysis ($\\\\textit{E}^{3}\\\\textit{SA}$) approach to solve this issue. Specifically, we explicitly extract and model the event structure information for enhancing event-level SA. Extensive experiments demonstrate the great advantages of our proposed approach over the state-of-the-art methods. Noting the lack of the dataset, we also release a large-scale real-world dataset with event arguments and sentiment labelling for promoting more researches\\\\footnote{The dataset is available at https://github.com/zhangqi-here/E3SA}. ","authors":"Qi Zhang, Jie Zhou, Qin Chen, Qinchun Bai, Liang He","pdf":"http://arxiv.org/pdf/2205.15511v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.15465v1","published":"Mon, 30 May 2022 23:30:16 GMT","title":"Analyzing Modality Robustness in Multimodal Sentiment Analysis","summary":"  Building robust multimodal models are crucial for achieving reliable deployment in the wild. Despite its importance, less attention has been paid to identifying and improving the robustness of Multimodal Sentiment Analysis (MSA) models. In this work, we hope to address that by (i) Proposing simple diagnostic checks for modality robustness in a trained multimodal model. Using these checks, we find MSA models to be highly sensitive to a single modality, which creates issues in their robustness; (ii) We analyze well-known robust training strategies to alleviate the issues. Critically, we observe that robustness can be achieved without compromising on the original performance. We hope our extensive study-performed across five models and two benchmark datasets-and proposed procedures would make robustness an integral component in MSA research. Our diagnostic checks and robust training solutions are simple to implement and available at https://github. com/declare-lab/MSA-Robustness. ","comment":"NAACL 2022","authors":"Devamanyu Hazarika, Yingting Li, Bo Cheng, Shuai Zhao, Roger Zimmermann, Soujanya Poria","pdf":"http://arxiv.org/pdf/2205.15465v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14728v2","published":"Sun, 29 May 2022 17:51:00 GMT","title":"L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models,   and Library","summary":"  Despite being the third most popular language in India, the Marathi language lacks useful NLP resources. Moreover, popular NLP libraries do not have support for the Marathi language. With L3Cube-MahaNLP, we aim to build resources and a library for Marathi natural language processing. We present datasets and transformer models for supervised tasks like sentiment analysis, named entity recognition, and hate speech detection. We have also published a monolingual Marathi corpus for unsupervised language modeling tasks. Overall we present MahaCorpus, MahaSent, MahaNER, and MahaHate datasets and their corresponding MahaBERT models fine-tuned on these datasets. We aim to move ahead of benchmark datasets and prepare useful resources for Marathi. The resources are available at https://github.com/l3cube-pune/MarathiNLP. ","authors":"Raviraj Joshi","pdf":"http://arxiv.org/pdf/2205.14728v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14492v1","published":"Sat, 28 May 2022 17:53:20 GMT","title":"A New High-Performance Approach to Approximate Pattern-Matching for   Plagiarism Detection in Blockchain-Based Non-Fungible Tokens (NFTs)","summary":"  We are presenting a fast and innovative approach to performing approximate pattern-matching for plagiarism detection, using an NDFA-based approach that significantly enhances performance compared to other existing similarity measures. We outline the advantages of our approach in the context of blockchain-based non-fungible tokens (NFTs). We present, formalize, discuss and test our proposed approach in several real-world scenarios and with different similarity measures commonly used in plagiarism detection, and observe significant throughput enhancements throughout the entire spectrum of tests, with little to no compromises on the accuracy of the detection process overall. We conclude that our approach is suitable and adequate to perform approximate pattern-matching for plagiarism detection, and outline research directions for future improvements. ","authors":"Ciprian Pungila, Darius Galis, Viorel Negru","pdf":"http://arxiv.org/pdf/2205.14492v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14206v1","published":"Fri, 27 May 2022 19:25:32 GMT","title":"Network Digital Twin: Context, Enabling Technologies and Opportunities","summary":"  The proliferation of emergent network applications (e.g., telesurgery, metaverse) is increasing the difficulty of managing modern communication networks. These applications entail stringent network requirements (e.g., ultra-low deterministic latency), which hinders network operators to manage their resources efficiently. In this article, we introduce the network digital twin (NDT), a renovated concept of classical network modeling tools whose goal is to build accurate data-driven network models that can operate in real-time. We describe the general architecture of the NDT and argue that modern machine learning (ML) technologies enable building some of its core components. Then, we present a case study that leverages a ML-based NDT for network performance evaluation and apply it to routing optimization in a QoS-aware use case. Lastly, we describe some key open challenges and research opportunities yet to be explored to achieve effective deployment of NDTs in real-world networks. ","comment":"7 pages, 4 figures. arXiv admin note: text overlap with   arXiv:2201.01144","authors":"Paul Almasan, Miquel Ferriol-Galmés, Jordi Paillisse, José Suárez-Varela, Diego Perino, Diego López, Antonio Agustin Pastor Perales, Paul Harvey, Laurent Ciavaglia, Leon Wong, Vishnu Ram, Shihan Xiao, Xiang Shi, Xiangle Cheng, Albert Cabellos-Aparicio, Pere Barlet-Ros","pdf":"http://arxiv.org/pdf/2205.14206v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.13148v1","published":"Thu, 26 May 2022 04:40:31 GMT","title":"Grammar Detection for Sentiment Analysis through Improved Viterbi   Algorithm","summary":"  Grammar Detection, also referred to as Parts of Speech Tagging of raw text, is considered an underlying building block of the various Natural Language Processing pipelines like named entity recognition, question answering, and sentiment analysis. In short, forgiven a sentence, Parts of Speech tagging is the task of specifying and tagging each word of a sentence with nouns, verbs, adjectives, adverbs, and more. Sentiment Analysis may well be a procedure accustomed to determining if a given sentence's emotional tone is neutral, positive or negative. To assign polarity scores to the thesis or entities within phrase, in-text analysis and analytics, machine learning and natural language processing, approaches are incorporated. This Sentiment Analysis using POS tagger helps us urge a summary of the broader public over a specific topic. For this, we are using the Viterbi algorithm, Hidden Markov Model, Constraint based Viterbi algorithm for POS tagging. By comparing the accuracies, we select the foremost accurate result of the model for Sentiment Analysis for determining the character of the sentence. ","authors":"Surya Teja Chavali, Charan Tej Kandavalli, Sugash T M","pdf":"http://arxiv.org/pdf/2205.13148v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12700v1","published":"Wed, 25 May 2022 11:58:38 GMT","title":"Textual Backdoor Attacks with Iterative Trigger Injection","summary":"  The backdoor attack has become an emerging threat for Natural Language Processing (NLP) systems. A victim model trained on poisoned data can be embedded with a \\backdoor\\, making it predict the adversary-specified output (e.g., the positive sentiment label) on inputs satisfying the trigger pattern (e.g., containing a certain keyword). In this paper, we demonstrate that it's possible to design an effective and stealthy backdoor attack by iteratively injecting \\triggers\\ into a small set of training data. While all triggers are common words that fit into the context, our poisoning process strongly associates them with the target label, forming the model backdoor. Experiments on sentiment analysis and hate speech detection show that our proposed attack is both stealthy and effective, raising alarm on the usage of untrusted training data. We further propose a defense method to combat this threat. ","authors":"Jun Yan, Vansh Gupta, Xiang Ren","pdf":"http://arxiv.org/pdf/2205.12700v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12626v1","published":"Wed, 25 May 2022 10:05:28 GMT","title":"On non-detectability of non-computability and the degree of   non-computability of solutions of circuit and wave equations on digital   computers","summary":"  It is known that there exist mathematical problems of practical relevance which cannot be computed on a Turing machine. An important example is the calculation of the first derivative of continuously differentiable functions. This paper precisely classifies the non-computability of the first derivative, and of the maximum-norm of the first derivative in the Zheng-Weihrauch hierarchy. Based on this classification, the paper investigates whether it is possible that a Turing machine detects this non-computability of the first derivative by observing the data of the problem, and whether it is possible to detect upper bounds for the peak value of the first derivative of continuously differentiable functions. So from a practical point of view, the question is whether it is possible to implement an exit-flag functionality for observing non-computability of the first derivative. This paper even studies two different types of exit-flag functionality. A strong one, where the Turing machine always has to stop, and a weak one, where the Turing machine stops if and only if the input lies within the corresponding set of interest. It will be shown that non-computability of the first derivative is not detectable by a Turing machine for two concrete examples, namely for the problem of computing the input--output behavior of simple analog circuits and for solutions of the three-dimensional wave equation. In addition, it is shown that it is even impossible to detect an upper bound for the maximum norm of the first derivative. In particular, it is shown that all three problems are not even semidecidable. Finally, we briefly discuss implications of these results for analog and quantum computing. ","comment":"To appear in IEEE Trans. Inf. Theory. This paper influenced the   article of F. Fitzek and H. Boche \\Metaverse at the campfire of the future\\   in Germany's major newspaper, the Frankfurter Allgemeine Zeitung (FAZ),   https://www.faz.net/aktuell/wirtschaft/digitec/metaverse-am-lagerfeuer-der-zukunft-18051009.html.   Technological challenges for the design of the Metaverse are discussed in   this article","authors":"Holger Boche, Volker Pohl","pdf":"http://arxiv.org/pdf/2205.12626v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12600v1","published":"Wed, 25 May 2022 09:25:06 GMT","title":"ORCA: Interpreting Prompted Language Models via Locating Supporting Data   Evidence in the Ocean of Pretraining Data","summary":"  Large pretrained language models have been performing increasingly well in a variety of downstream tasks via prompting. However, it remains unclear from where the model learns the task-specific knowledge, especially in a zero-shot setup. In this work, we want to find evidence of the model's task-specific competence from pretraining and are specifically interested in locating a very small subset of pretraining data that directly supports the model in the task. We call such a subset supporting data evidence and propose a novel method ORCA to effectively identify it, by iteratively using gradient information related to the downstream task. This supporting data evidence offers interesting insights about the prompted language models: in the tasks of sentiment analysis and textual entailment, BERT shows a substantial reliance on BookCorpus, the smaller corpus of BERT's two pretraining corpora, as well as on pretraining examples that mask out synonyms to the task verbalizers. ","authors":"Xiaochuang Han, Yulia Tsvetkov","pdf":"http://arxiv.org/pdf/2205.12600v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12328v1","published":"Tue, 24 May 2022 19:16:06 GMT","title":"Multilevel sentiment analysis in arabic","summary":"  In this study, we aimed to improve the performance results of Arabic sentiment analysis. This can be achieved by investigating the most successful machine learning method and the most useful feature vector to classify sentiments in both term and document levels into two (positive or negative) categories. Moreover, specification of one polarity degree for the term that has more than one is investigated. Also to handle the negations and intensifications, some rules are developed. According to the obtained results, Artificial Neural Network classifier is nominated as the best classifier in both term and document level sentiment analysis (SA) for Arabic Language. Furthermore, the average F-score achieved in the term level SA for both positive and negative testing classes is 0.92. In the document level SA, the average F-score for positive testing classes is 0.94, while for negative classes is 0.93. ","comment":"10 pages, 3 figures, Published in: 2019 IEEE 7th Palestinian   International Conference on Electrical and Computer Engineering (PICECE),   Date of Conference: 26-27 March 2019","authors":"Ahmed Nassar, Ebru Sezer","pdf":"http://arxiv.org/pdf/2205.12328v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12022v2","published":"Tue, 24 May 2022 12:15:33 GMT","title":"Improving Human Image Synthesis with Residual Fast Fourier   Transformation and Wasserstein Distance","summary":"  With the rapid development of the Metaverse, virtual humans have emerged, and human image synthesis and editing techniques, such as pose transfer, have recently become popular. Most of the existing techniques rely on GANs, which can generate good human images even with large variants and occlusions. But from our best knowledge, the existing state-of-the-art method still has the following problems: the first is that the rendering effect of the synthetic image is not realistic, such as poor rendering of some regions. And the second is that the training of GAN is unstable and slow to converge, such as model collapse. Based on the above two problems, we propose several methods to solve them. To improve the rendering effect, we use the Residual Fast Fourier Transform Block to replace the traditional Residual Block. Then, spectral normalization and Wasserstein distance are used to improve the speed and stability of GAN training. Experiments demonstrate that the methods we offer are effective at solving the problems listed above, and we get state-of-the-art scores in LPIPS and PSNR. ","comment":"This paper is accepted by IJCNN2022","authors":"Jianhan Wu, Shijing Si, Jianzong Wang, Jing Xiao","pdf":"http://arxiv.org/pdf/2205.12022v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.11935v1","published":"Tue, 24 May 2022 09:56:33 GMT","title":"CryptoTL: Private, efficient and secure transfer learning","summary":"  Big data has been a pervasive catchphrase in recent years, but dealing with data scarcity has become a crucial question for many real-world deep learning (DL) applications. A popular methodology to efficiently enable the training of DL models to perform tasks in scenarios where only a small dataset is available is transfer learning (TL). TL allows knowledge transfer from a general domain to a specific target one; however, such a knowledge transfer may put privacy at risk when it comes to sensitive or private data. With CryptoTL we introduce a solution to this problem, and show for the first time a cryptographic privacy-preserving TL approach based on homomorphic encryption that is efficient and feasible for real-world use cases. We demonstrate this by focusing on classification tasks with small datasets and show the applicability of our approach for sentiment analysis. Additionally we highlight how our approach can be combined with differential privacy to further increase the security guarantees. Our extensive benchmarks show that using CryptoTL leads to high accuracy while still having practical fine-tuning and classification runtimes despite using homomorphic encryption. Concretely, one forward-pass through the encrypted layers of our setup takes roughly 1s on a notebook CPU. ","authors":"Roman Walch, Samuel Sousa, Lukas Helminger, Stefanie Lindstaedt, Christian Rechberger, Andreas Trügler","pdf":"http://arxiv.org/pdf/2205.11935v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.11821v1","published":"Tue, 24 May 2022 06:36:23 GMT","title":"MetaSID: Singer Identification with Domain Adaptation for Metaverse","summary":"  Metaverse has stretched the real world into unlimited space. There will be more live concerts in Metaverse. The task of singer identification is to identify the song belongs to which singer. However, there has been a tough problem in singer identification, which is the different live effects. The studio version is different from the live version, the data distribution of the training set and the test set are different, and the performance of the classifier decreases. This paper proposes the use of the domain adaptation method to solve the live effect in singer identification. Three methods of domain adaptation combined with Convolutional Recurrent Neural Network (CRNN) are designed, which are Maximum Mean Discrepancy (MMD), gradient reversal (Revgrad), and Contrastive Adaptation Network (CAN). MMD is a distance-based method, which adds domain loss. Revgrad is based on the idea that learned features can represent different domain samples. CAN is based on class adaptation, it takes into account the correspondence between the categories of the source domain and target domain. Experimental results on the public dataset of Artist20 show that CRNN-MMD leads to an improvement over the baseline CRNN by 0.14. The CRNN-RevGrad outperforms the baseline by 0.21. The CRNN-CAN achieved state of the art with the F1 measure value of 0.83 on album split. ","comment":"Accepted by IJCNN2022 (The 2022 International Joint Conference on   Neural Networks)","authors":"Xulong Zhang, Jianzong Wang, Ning Cheng, Jing Xiao","pdf":"http://arxiv.org/pdf/2205.11821v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.11817v1","published":"Tue, 24 May 2022 06:30:50 GMT","title":"Singer Identification for Metaverse with Timbral and Middle-Level   Perceptual Features","summary":"  Metaverse is an interactive world that combines reality and virtuality, where participants can be virtual avatars. Anyone can hold a concert in a virtual concert hall, and users can quickly identify the real singer behind the virtual idol through the singer identification. Most singer identification methods are processed using the frame-level features. However, expect the singer's timbre, the music frame includes music information, such as melodiousness, rhythm, and tonal. It means the music information is noise for using frame-level features to identify the singers. In this paper, instead of only the frame-level features, we propose to use another two features that address this problem. Middle-level feature, which represents the music's melodiousness, rhythmic stability, and tonal stability, and is able to capture the perceptual features of music. The timbre feature, which is used in speaker identification, represents the singers' voice features. Furthermore, we propose a convolutional recurrent neural network (CRNN) to combine three features for singer identification. The model firstly fuses the frame-level feature and timbre feature and then combines middle-level features to the mix features. In experiments, the proposed method achieves comparable performance on an average F1 score of 0.81 on the benchmark dataset of Artist20, which significantly improves related works. ","comment":"Accepted by IJCNN2022 (The 2022 International Joint Conference on   Neural Networks). arXiv admin note: text overlap with arXiv:2002.06817 by   other authors","authors":"Xulong Zhang, Jianzong Wang, Ning Cheng, Jing Xiao","pdf":"http://arxiv.org/pdf/2205.11817v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.11097v1","published":"Mon, 23 May 2022 07:37:04 GMT","title":"A Fine-grained Interpretability Evaluation Benchmark for Neural NLP","summary":"  While there is increasing concern about the interpretability of neural models, the evaluation of interpretability remains an open problem, due to the lack of proper evaluation datasets and metrics. In this paper, we present a novel benchmark to evaluate the interpretability of both neural models and saliency methods. This benchmark covers three representative NLP tasks: sentiment analysis, textual similarity and reading comprehension, each provided with both English and Chinese annotated data. In order to precisely evaluate the interpretability, we provide token-level rationales that are carefully annotated to be sufficient, compact and comprehensive. We also design a new metric, i.e., the consistency between the rationales before and after perturbations, to uniformly evaluate the interpretability of models and saliency methods on different tasks. Based on this benchmark, we conduct experiments on three typical models with three saliency methods, and unveil their strengths and weakness in terms of interpretability. We will release this benchmark at \\\\url{https://xyz} and hope it can facilitate the research in building trustworthy systems. ","authors":"Lijie Wang, Yaozong Shen, Shuyuan Peng, Shuai Zhang, Xinyan Xiao, Hao Liu, Hongxuan Tang, Ying Chen, Hua Wu, Haifeng Wang","pdf":"http://arxiv.org/pdf/2205.11097v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.11087v2","published":"Mon, 23 May 2022 07:07:01 GMT","title":"MetaSlicing: A Novel Resource Allocation Framework for Metaverse","summary":"  Creating and maintaining the Metaverse requires enormous resources that have never been seen before, especially computing resources for intensive data processing to support the extended reality, enormous storage resources, and massive networking resources for maintaining ultra high-speed and low-latency connections. Therefore, this work aims to propose a novel framework, namely MetaSlicing, that can provide a highly effective and comprehensive solution in managing and allocating different types of resources for Metaverse applications. In particular, by observing that Metaverse applications may have common functions, we first propose grouping applications into clusters, called MetaInstances. In a MetaInstance, common functions can be shared among applications. As such, the same resources can be used by multiple applications simultaneously, thereby enhancing resource utilization dramatically. To address the real-time characteristic and resource demand's dynamic and uncertainty in the Metaverse, we develop an effective framework based on the semi-Markov decision process and propose an intelligent admission control algorithm that can maximize resource utilization and enhance the Quality-of-Service for end-users. Extensive simulation results show that our proposed solution outperforms the Greedy-based policy by up to 80% and 47% in terms of long-term revenue for Metaverse providers and request acceptance probability, respectively. ","authors":"Nam H. Chu, Dinh Thai Hoang, Diep N. Nguyen, Khoa T. Phan, Eryk Dutkiewicz","pdf":"http://arxiv.org/pdf/2205.11087v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.11082v1","published":"Mon, 23 May 2022 06:55:34 GMT","title":"YouTube Ad View Sentiment Analysis using Deep Learning and Machine   Learning","summary":"  Sentiment Analysis is currently a vital area of research. With the advancement in the use of the internet, the creation of social media, websites, blogs, opinions, ratings, etc. has increased rapidly. People express their feedback and emotions on social media posts in the form of likes, dislikes, comments, etc. The rapid growth in the volume of viewer-generated or user-generated data or content on YouTube has led to an increase in YouTube sentiment analysis. Due to this, analyzing the public reactions has become an essential need for information extraction and data visualization in the technical domain. This research predicts YouTube Ad view sentiments using Deep Learning and Machine Learning algorithms like Linear Regression (LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), and Artificial Neural Network (ANN). Finally, a comparative analysis is done based on experimental results acquired from different models. ","comment":"5 pages, 9 figures, Published with International Journal of Computer   Applications (IJCA)","authors":"Tanvi Mehta, Ganesh Deshmukh","pdf":"http://arxiv.org/pdf/2205.11082v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.10517v2","published":"Sat, 21 May 2022 06:44:59 GMT","title":"Pre-training Data Quality and Quantity for a Low-Resource Language: New   Corpus and BERT Models for Maltese","summary":"  Multilingual language models such as mBERT have seen impressive cross-lingual transfer to a variety of languages, but many languages remain excluded from these models. In this paper, we analyse the effect of pre-training with monolingual data for a low-resource language that is not included in mBERT -- Maltese -- with a range of pre-training set ups. We conduct evaluations with the newly pre-trained models on three morphosyntactic tasks -- dependency parsing, part-of-speech tagging, and named-entity recognition -- and one semantic classification task -- sentiment analysis. We also present a newly created corpus for Maltese, and determine the effect that the pre-training data size and domain have on the downstream performance. Our results show that using a mixture of pre-training domains is often superior to using Wikipedia text only. We also find that a fraction of this corpus is enough to make significant leaps in performance over Wikipedia-trained models. We pre-train and compare two models on the new corpus: a monolingual BERT model trained from scratch (BERTu), and a further pre-trained multilingual BERT (mBERTu). The models achieve state-of-the-art performance on these tasks, despite the new corpus being considerably smaller than typically used corpora for high-resourced languages. On average, BERTu outperforms or performs competitively with mBERTu, and the largest gains are observed for higher-level tasks. ","comment":"DeepLo 2022 camera-ready version","authors":"Kurt Micallef, Albert Gatt, Marc Tanti, Lonneke van der Plas, Claudia Borg","pdf":"http://arxiv.org/pdf/2205.10517v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.10271v1","published":"Fri, 20 May 2022 16:05:22 GMT","title":"Compression ensembles quantify aesthetic complexity and the evolution of   visual art","summary":"  The quantification of visual aesthetics and complexity have a long history, the latter previously operationalized via the application of compression algorithms. Here we generalize and extend the compression approach beyond simple complexity measures to quantify algorithmic distance in historical and contemporary visual media. The proposed \\ensemble\\ approach works by compressing a large number of transformed versions of a given input image, resulting in a vector of associated compression ratios. This approach is more efficient than other compression-based algorithmic distances, and is particularly suited for the quantitative analysis of visual artifacts, because human creative processes can be understood as algorithms in the broadest sense. Unlike comparable image embedding methods using machine learning, our approach is fully explainable through the transformations. We demonstrate that the method is cognitively plausible and fit for purpose by evaluating it against human complexity judgments, and on automated detection tasks of authorship and style. We show how the approach can be used to reveal and quantify trends in art historical data, both on the scale of centuries and in rapidly evolving contemporary NFT art markets. We further quantify temporal resemblance to disambiguate artists outside the documented mainstream from those who are deeply embedded in Zeitgeist. Finally, we note that compression ensembles constitute a quantitative representation of the concept of visual family resemblance, as distinct sets of dimensions correspond to shared visual characteristics otherwise hard to pin down. Our approach provides a new perspective for the study of visual art, algorithmic image analysis, and quantitative aesthetics more generally. ","authors":"Andres Karjus, Mar Canet Solà, Tillmann Ohm, Sebastian E. Ahnert, Maximilian Schich","pdf":"http://arxiv.org/pdf/2205.10271v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.09020v1","published":"Wed, 18 May 2022 15:55:52 GMT","title":"Toward Timed-Release Encryption in Web3 An Efficient Dual-Propose   Proof-of-Work Consensus","summary":"  Many existing timed-release encryption schemes uses time-lock puzzles to avoid relying on a trusted timeserver or a key holder which could be a weak spot in data security. However, it is unavoidable to consume massive computing power for solving time-lock puzzles and it is difficult for encryptors to predict the amount of time to solve a puzzle by decryptors. In this study, an efficient dual-propose proof-of-work consensus allows users to release a time-locked content, which is encrypted by an asymmetric key encryption scheme on a blockchain, without trust in any third-party agents. The release time is predictable as the block time in a proof-of-work blockchain is adaptively controlled. The mining work is reproposed so that once a new block was mined on the blockchain network, time-lock puzzles were also solved immediately. No additional work is required to reveal the time-locked contents and the encryption is secured by monetary incentive mechanisms since it would be very costly to arrange an attack attempt, which must overtake the total hash rate of the whole blockchain network. ","authors":"Fanghao Yang, Xingqiu Yuan","pdf":"http://arxiv.org/pdf/2205.09020v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07769v1","published":"Mon, 16 May 2022 15:47:59 GMT","title":"A BenchCouncil View on Benchmarking Emerging and Future Computing","summary":"  The measurable properties of the artifacts or objects in the computer, management, or finance disciplines are extrinsic, not inherent -- dependent on their problem definitions and solution instantiations. Only after the instantiation can the solutions to the problem be measured. The processes of definition, instantiation, and measurement are entangled, and they have complex mutual influences. Meanwhile, the technology inertia brings instantiation bias -- trapped into a subspace or even a point at a high-dimension solution space. These daunting challenges, which emerging computing aggravates, make metrology can not work for benchmark communities. It is pressing to establish independent benchmark science and engineering.   This article presents a unifying benchmark definition, a conceptual framework, and a traceable and supervised learning-based benchmarking methodology, laying the foundation for benchmark science and engineering. I also discuss BenchCouncil's plans for emerging and future computing. The ongoing projects include defining the challenges of intelligence, instinct, quantum computers, Metaverse, planet-scale computers, and reformulating data centers, artificial intelligence for science, and CPU benchmark suites. Also, BenchCouncil will collaborate with ComputerCouncil on open-source computer systems for planet-scale computing, AI for science systems, and Metaverse. ","comment":"To appear BenchCouncil Transactions on Benchmarks, Standards and   Evaluation (TBench)","authors":"Jianfeng Zhan","pdf":"http://arxiv.org/pdf/2205.07769v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.07590v1","published":"Mon, 16 May 2022 11:50:14 GMT","title":"Metaverse: Security and Privacy Issues","summary":"  The metaverse promises a host of bright opportunities for business, economics, and society. Though, a number of critical aspects are still to be considered and the analysis of their impact is almost non-existent. In this paper, we provide several contributions. We start by analysing the foundations of the metaverse, later we focus on the novel privacy and security issues introduced by this new paradigm, and finally we broaden the scope of the contribution highlighting some of the far-reaching yet logical implications of the metaverse on a number of domains, not all of them in tech. Throughout the paper, we also discuss possible research directions. We believe that the provided holistic view on the foundations, technology, and issues related to the metaverse-with a focus on security and privacy-, other than being an interesting contribution on its own, could also pave the way for a few multidisciplinary research avenues. ","comment":"The 3rd IEEE International Conference on Trust, Privacy and Security   in Intelligent Systems and Applications (TPS'21)","authors":"Roberto Di Pietro, Stefano Cresci","pdf":"http://arxiv.org/pdf/2205.07590v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.05140v1","published":"Fri, 10 Jun 2022 14:25:12 GMT","title":"Evolution of a Relativistic Outflow and X-ray Corona in the Extreme   Changing-Look AGN 1ES 1927+654","summary":"  1ES 1927+654 is a paradigm-defying AGN and one of the most peculiar X-ray nuclear transients. In early 2018, this well-known AGN underwent a changing-look event, in which broad optical emission lines appeared and the optical flux increased. Yet, by July 2018, the X-ray flux had dropped by over two orders of magnitude, indicating a dramatic change to the inner accretion flow. With three years of observations with NICER, XMM-Newton, and NuSTAR, we present the X-ray evolution of 1ES 1927+654, which can be broken into three phases-(1) an early super-Eddington phase with rapid variability in X-ray luminosity and spectral parameters, (2) a stable super-Eddington phase at the peak X-ray luminosity, and (3) a steady decline back to the pre-outburst luminosity and spectral parameters. For the first time, we witnessed the formation of the X-ray corona, as the X-ray spectrum transitioned from thermally-dominated to primarily Comptonized. We also track the evolution of the prominent, broad 1 keV feature in the early X-ray spectra and show that this feature can be modeled with blueshifted reflection (z = -0.33) from a single-temperature blackbody irradiating spectrum using xillverTDE, a new flavor of the xillver models. Thus, we propose that the 1 keV feature could arise from reflected emission off the base of an optically thick outflow from a geometrically thick, super-Eddington inner accretion flow, connecting the inner accretion flow with outflows launched during extreme accretion events (e.g. tidal disruption events). Lastly, we compare 1ES 1927+654 to other nuclear transients and discuss applications of xillverTDE to super-Eddington accretors. ","comment":"25 pages, 10 figures, accepted for publication in ApJ","authors":"Megan Masterson, Erin Kara, Claudio Ricci, Javier A. García, Andrew C. Fabian, Ciro Pinto, Peter Kosec, Ronald A. Remillard, Michael Loewenstein, Benny Trakhtenbrot, Iair Arcavi","pdf":"http://arxiv.org/pdf/2206.05140v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.05081v1","published":"Fri, 10 Jun 2022 13:19:54 GMT","title":"The Evolution Of Centralisation on Cryptocurrency Platforms","summary":"  More than ten years ago the blockchain was acclaimed as the solution to overcome centralised trusted third parties for online payments. Through the years the crypto-movement changed and evolved, although decentralisation remained the core ideology and the necessary feature every new crypto-project should provide. In this paper we study the concept of centralisation in cryptocurrencies using a wide array of methodologies from the complex systems literature, on a comparative collection of blockchains, in order to define the many different levels a blockchain system may display (de-)centralisation and to question whether the present state of cryptocurrencies is, in a technological and economical sense, actually decentralised. ","authors":"Carlo Campajola, Raffaele Cristodaro, Francesco Maria De Collibus, Tao Yan, Nicolo' Vallarano, Claudio J. Tessone","pdf":"http://arxiv.org/pdf/2206.05081v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.05042v1","published":"Fri, 10 Jun 2022 12:31:56 GMT","title":"Sentiment analysis on electricity twitter posts","summary":"  In today's world, everyone is expressive in some way, and the focus of this project is on people's opinions about rising electricity prices in United Kingdom and India using data from Twitter, a micro-blogging platform on which people post messages, known as tweets. Because many people's incomes are not good and they have to pay so many taxes and bills, maintaining a home has become a disputed issue these days. Despite the fact that Government offered subsidy schemes to compensate people electricity bills but it is not welcomed by people. In this project, the aim is to perform sentiment analysis on people's expressions and opinions expressed on Twitter. In order to grasp the electricity prices opinion, it is necessary to carry out sentiment analysis for the government and consumers in energy market. Furthermore, text present on these medias are unstructured in nature, so to process them we firstly need to pre-process the data. There are so many feature extraction techniques such as Bag of Words, TF-IDF (Term Frequency-Inverse Document Frequency), word embedding, NLP based features like word count. In this project, we analysed the impact of feature TF-IDF word level on electricity bills dataset of sentiment analysis. We found that by using TF-IDF word level performance of sentiment analysis is 3-4 higher than using N-gram features. Analysis is done using four classification algorithms including Naive Bayes, Decision Tree, Random Forest, and Logistic Regression and considering F-Score, Accuracy, Precision, and Recall performance parameters. ","comment":"Keywords: Sentiment Analysis, Machine Learning, Electricity, opinion   mining, polarity assessment","authors":"Pardeep Kaur, Maryam Edalati","pdf":"http://arxiv.org/pdf/2206.05042v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.04803v1","published":"Tue, 07 Jun 2022 16:22:55 GMT","title":"Detecting Anomalous Cryptocurrency Transactions: an AML/CFT Application   of Machine Learning-based Forensics","summary":"  The rise of blockchain and distributed ledger technologies (DLTs) in the financial sector has generated a socio-economic shift that triggered legal concerns and regulatory initiatives. While the anonymity of DLTs may safeguard the right to privacy, data protection and other civil liberties, lack of identification hinders accountability, investigation and enforcement. The resulting challenges extend to the rules to combat money laundering and the financing of terrorism and proliferation (AML/CFT). As law enforcement agencies and analytics companies have begun to successfully apply forensics to track currency across blockchain ecosystems, in this paper we focus on the increasing relevance of these techniques. In particular, we offer insights into the application to the Internet of Money (IoM) of machine learning, network and transaction graph analysis. After providing some background on the notion of anonymity in the IoM and on the interplay between AML/CFT and blockchain forensics, we focus on anomaly detection approaches leading to our experiments. Namely, we analyzed a real-world dataset of Bitcoin transactions represented as a directed graph network through various machine learning techniques. Our claim is that the AML/CFT domain could benefit from novel graph analysis methods in machine learning. Indeed, our findings show that the Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) neural network types represent a promising solution for AML/CFT compliance. ","authors":"Nadia Pocher, Mirko Zichichi, Fabio Merizzi, Muhammad Zohaib Shafiq, Stefano Ferretti","pdf":"http://arxiv.org/pdf/2206.04803v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.14699v2","published":"Sun, 29 May 2022 16:00:29 GMT","title":"Managing Risk in DeFi Portfolios","summary":"  Decentralized Finance (DeFi) is a new financial industry built on blockchain technologies. Decentralized financial services have consequently increased the ability to lend, borrow, and invest in decentralized investment vehicles, allowing investors to bypass third party intermediaries. DeFi's promise is to reduce the cost of transaction and management fees whilst increasing trust between agents of the Financial Industry 3.0. This paper provides an overview of the different components of DeFi, as well as the risks involved in investing through these new vehicles. We will also propose an allocation methodology which will integrate and quantify these risks. ","authors":"Hugo Inzirillo, Stanislas de Quenetain","pdf":"http://arxiv.org/pdf/2205.14699v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.06029v1","published":"Mon, 13 Jun 2022 10:31:18 GMT","title":"Mediators: Conversational Agents Explaining NLP Model Behavior","summary":"  The human-centric explainable artificial intelligence (HCXAI) community has raised the need for framing the explanation process as a conversation between human and machine. In this position paper, we establish desiderata for Mediators, text-based conversational agents which are capable of explaining the behavior of neural models interactively using natural language. From the perspective of natural language processing (NLP) research, we engineer a blueprint of such a Mediator for the task of sentiment analysis and assess how far along current research is on the path towards dialogue-based explanations. ","comment":"Accepted to IJCAI-ECAI 2022 Workshop on Explainable Artificial   Intelligence (XAI)","authors":"Nils Feldhus, Ajay Madhavan Ravichandran, Sebastian Möller","pdf":"http://arxiv.org/pdf/2206.06029v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.06010v1","published":"Mon, 13 Jun 2022 09:57:16 GMT","title":"Constant-Round Linear-Broadcast Secure Computation with Penalties","summary":"  It is known that Bitcoin enables achieving fairness in secure computation by imposing monetary penalties on adversarial parties. This functionality is called secure computation with penalties. Bentov and Kumaresan (Crypto 2014) introduced the claim-or-refund functionality that can be implemented via Bitcoin. They achieved secure computation with penalties with $O(n)$ rounds and $O(n)$ broadcasts for any function, where $n$ is the number of parties. After that, Kumaresan and Bentov (CCS 2014) showed a constant-round protocol. Unfortunately, this protocol requires $O(n^2)$ broadcasts. As far as we know, no protocol achieves $O(1)$ rounds and $O(n)$ broadcasts based on Bitcoin. This work accomplishes such efficiency in secure computation with penalties. We first show a protocol in a slightly relaxed setting called secure computation with non-equivalent penalties. This setting is the same as secure computation with penalties except that every honest party receives more than a predetermined amount of compensation, while the previous one requires that every honest party receives the same amount of compensation. Namely, our setting allows the compensations for honest parties to be non-equivalent. Moreover, we present a technique to remove the non-equivalence of our protocol without sacrificing efficiency. We then propose a new ideal functionality called claim-refund-or-give that can be implemented via Bitcoin. ","comment":"32 pages","authors":"Takeshi Nakai, Kazumasa Shinagawa","pdf":"http://arxiv.org/pdf/2206.06010v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.05964v1","published":"Mon, 13 Jun 2022 08:21:50 GMT","title":"Techno Economic Modeling for Agrivoltaics: Can Agrivoltaics be more   profitable than Ground mounted PV?","summary":"  Agrivoltaics (AV) is a dual land-use approach to collocate solar energy generation with agriculture for preserving the terrestrial ecosystem and enabling food-energy-water synergies. Here, we present a systematic approach to model the economic performance of AV relative to standalone ground-mounted PV (GMPV) and explore how the module design configuration can affect the dual food-energy economic performance. A remarkably simple criterion for economic feasibility is quantified that relates the land preservation cost to dual food-energy profit. We explore case studies including both high and low value crops under fixed tilt bifacial modules oriented either along the conventional North/South (N/S) facings or vertical East/West (E/W) facings. For each module configuration, the array density is varied to explore an economically feasible design space relative to GMPV for a range of module to land cost ratio (M_L) - a location-specific indicator relating the module technology (hardware and installation) costs to the soft (land acquisition, tax, overheads, etc.) costs. To offset a typically higher AV module cost needed to preserve the cropland, both E/W and N/S orientated modules favor high value crops, reduced (<60%) module density, and higher M_L (>25). In contrast, higher module density and an increased feed-in-tariff (FIT) relative to GMPV are desirable at lower M_L. The economic trends vary sharply for M_L< 10 but tend to saturate for M_L> 20. For low value crops, ~15% additional FIT can enable economic equivalence to GMPV at standard module density. The proposed modeling framework can provide a valuable tool for AV stakeholders to assess, predict, and optimize the techno-economic design for AV ","comment":"Submitted to IEEE Journal of Photovoltaics","authors":"Habeel Alam, Muhammad Ashraful Alam, Nauman Zafar Butt","pdf":"http://arxiv.org/pdf/2206.05964v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.05950v1","published":"Mon, 13 Jun 2022 07:45:31 GMT","title":"Deadline-constrained Multi-resource Task Mapping and Allocation for   Edge-Cloud Systems","summary":"  In an edge-cloud system, mobile devices can offload their computation intensive tasks to an edge or cloud server to guarantee the quality of service or satisfy task deadline requirements. However, it is challenging to determine where tasks should be offloaded and processed, and how much network and computation resources should be allocated to them, such that a system with limited resources can obtain a maximum profit while meeting the deadlines. A key challenge in this problem is that the network and computation resources could be allocated on different servers, since the server to which a task is offloaded (e.g., a server with an access point) may be different from the server on which the task is eventually processed. To address this challenge, we first formulate the task mapping and resource allocation problem as a non-convex Mixed-Integer Nonlinear Programming (MINLP) problem, known as NP-hard. We then propose a zero-slack based greedy algorithm (ZSG) and a linear discretization method (LDM) to solve this MINLP problem. Experiment results with various synthetic tasksets show that ZSG has an average of $2.98\\\\%$ worse performance than LDM with a minimum unit of 5 but has an average of $6.88\\\\%$ better performance than LDM with a minimum unit of 15. ","authors":"Chuanchao Gao, Aryaman Shaan, Arvind Easwaran","pdf":"http://arxiv.org/pdf/2206.05950v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.05910v1","published":"Mon, 13 Jun 2022 05:40:03 GMT","title":"Safe-FinRL: A Low Bias and Variance Deep Reinforcement Learning   Implementation for High-Freq Stock Trading","summary":"  In recent years, many practitioners in quantitative finance have attempted to use Deep Reinforcement Learning (DRL) to build better quantitative trading (QT) strategies. Nevertheless, many existing studies fail to address several serious challenges, such as the non-stationary financial environment and the bias and variance trade-off when applying DRL in the real financial market. In this work, we proposed Safe-FinRL, a novel DRL-based high-freq stock trading strategy enhanced by the near-stationary financial environment and low bias and variance estimation. Our main contributions are twofold: firstly, we separate the long financial time series into the near-stationary short environment; secondly, we implement Trace-SAC in the near-stationary financial environment by incorporating the general retrace operator into the Soft Actor-Critic. Extensive experiments on the cryptocurrency market have demonstrated that Safe-FinRL has provided a stable value estimation and a steady policy improvement and reduced bias and variance significantly in the near-stationary financial environment. ","authors":"Zitao Song, Xuyang Jin, Chenliang Li","pdf":"http://arxiv.org/pdf/2206.05910v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.05676v1","published":"Sun, 12 Jun 2022 06:33:37 GMT","title":"VeriBlock: A Blockchain-Based Verifiable Trust Management Architecture   with Provable Interactions","summary":"  There has been considerable advancement in the use of blockchain for trust management in large-scale dynamic systems. In such systems, blockchain is mainly used to store the trust score or trust-related information of interactions among the various entities. However, present trust management architectures using blockchain lack verifiable interactions among the entities on which the trust score is calculated. In this paper, we propose a blockchain-based trust management framework that allows independent trust providers to implement different trust metrics on a common set of trust evidence and provide individual trust value. We employ geo-location as proof of interaction. Some of the existing proposals rely upon geo-location data, but they do not support trust calculation by multiple trust providers. Instead, they can only support a centralised system. Our proposed architecture does not depend upon a single centralised third-party entity to ensure trusted interactions. Our architecture is supported by provable interactions that can easily be verified using blockchain. Therefore, it allows a high degree of confidence in trust management by ensuring the actual interactions between the entities. We provide a detailed design and development of the architecture using real-world use case examples. The proof of prototype was implemented on the Ethereum blockchain platform. Experimental results demonstrate that the employment of independent trust providers adequately provides a high degree of trust scores and that the proposed architecture can be used in a real-world environment. ","authors":"Shantanu Pal, Ambrose Hill, Tahiry Rabehaja, Michael Hitchens","pdf":"http://arxiv.org/pdf/2206.05676v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.09922v2","published":"Fri, 20 May 2022 01:32:07 GMT","title":"Nonlinear Forecasts and Impulse Responses for Causal-Noncausal (S)VAR   Models","summary":"  We introduce the closed-form formulas of nonlinear forecasts and nonlinear impulse response functions (IRF) for the mixed causal-noncausal (Structural) Vector Autoregressive (S)VAR models. We also discuss the identification of nonlinear causal innovations of the model to which the shocks are applied. Our approach is illustrated by a simulation study and an application to a bivariate process of Bitcoin/USD and Ethereum/USD exchange rates. ","comment":"53 pages, 17 figures","authors":"Christian Gourieroux, Joann Jasiak","pdf":"http://arxiv.org/pdf/2205.09922v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.06935v1","published":"Tue, 14 Jun 2022 15:56:32 GMT","title":"OSN Dashboard Tool For Sentiment Analysis","summary":"  The amount of opinionated data on the internet is rapidly increasing. More and more people are sharing their ideas and opinions in reviews, discussion forums, microblogs and general social media. As opinions are central in all human activities, sentiment analysis has been applied to gain insights in this type of data. There are proposed several approaches for sentiment classification. The major drawback is the lack of standardized solutions for classification and high-level visualization. In this study, a sentiment analyzer dashboard for online social networking analysis is proposed. This, to enable people gaining insights in topics interesting to them. The tool allows users to run the desired sentiment analysis algorithm in the dashboard. In addition to providing several visualization types, the dashboard facilitates raw data results from the sentiment classification which can be downloaded for further analysis. ","comment":"Keywords Sentiment Analysis Machine Learning Twitter Opinion Mining   Polarity Assessment","authors":"Andreas Kilde Lien, Lars Martin Randem, Hans Petter Fauchald Taralrud, Maryam Edalati","pdf":"http://arxiv.org/pdf/2206.06935v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.06723v1","published":"Tue, 14 Jun 2022 10:11:35 GMT","title":"Development of a hybrid method for stock trading based on TOPSIS, EMD   and ELM","summary":"  Deciding when to buy or sell a stock is not an easy task because the market is hard to predict, being influenced by political and economic factors. Thus, methodologies based on computational intelligence have been applied to this challenging problem. In this work, every day the stocks are ranked by technique for order preference by similarity to ideal solution (TOPSIS) using technical analysis criteria, and the most suitable stock is selected for purchase. Even so, it may occur that the market is not favorable to purchase on certain days, or even, the TOPSIS make an incorrect selection. To improve the selection, another method should be used. So, a hybrid model composed of empirical mode decomposition (EMD) and extreme learning machine (ELM) is proposed. The EMD decomposes the series into several sub-series, and thus the main omponent (trend) is extracted. This component is processed by the ELM, which performs the prediction of the next element of component. If the value predicted by the ELM is greater than the last value, then the purchase of the stock is confirmed. The method was applied in a universe of 50 stocks in the Brazilian market. The selection made by TOPSIS showed promising results when compared to the random selection and the return generated by the Bovespa index. Confirmation with the EMD-ELM hybrid model was able to increase the percentage of profit tradings. ","authors":"Elivelto Ebermam, Helder Knidel, Renato A. Krohling","pdf":"http://arxiv.org/pdf/2206.06723v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.06443v1","published":"Mon, 13 Jun 2022 19:48:43 GMT","title":"The impact of NFT profile pictures within social network communities","summary":"  This paper presents an analysis of the role of social media, specifically Twitter, in the context of non-fungible tokens, better known as NFTs. Such emerging technology framing the creation and exchange of digital object, started years ago with early projects such as \\CryptoPunks\\ and since early 2021, has received an increasing interest by a community of people creating, buying, selling NFT's and by the media reporting to the general public. In this work it is shown how the landscape of one class of projects, specifically those used as social media profile pictures, has become mainstream with leading projects such as \\Bored Ape Yacht Club\\, \\Cool Cats\\ and \\Doodles\\. This work illustrates how heterogeneous data was collected from the Ethereum blockchain and Twitter and then analysed using algorithms and state-of-art metrics related to graphs. The initial results show that from a social network perspective, the collections of most popular NFTs can be considered as a single community around NFTs. Thus, while each project has its own value and volume of exchange, on a social level all of them are primarily influenced by the evolution of values and trades of \\Bored Ape Yacht Club\\ collection. ","comment":"Paper submitted and under review to the ACM International Conference   on Information Technology for Social Good (GoodIT'22), September 07--09,   2022, Cyprus","authors":"Simone Casale-Brunet, Mirko Zichichi, Lee Hutchinson, Marco Mattavelli, Stefano Ferretti","pdf":"http://arxiv.org/pdf/2206.06443v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.06780v1","published":"Wed, 08 Jun 2022 11:18:02 GMT","title":"Memory-Oriented Design-Space Exploration of Edge-AI Hardware for XR   Applications","summary":"  Low-Power Edge-AI capabilities are essential for on-device extended reality (XR) applications to support the vision of Metaverse. In this work, we investigate two representative XR workloads: (i) Hand detection and (ii) Eye segmentation, for hardware design space exploration. For both applications, we train deep neural networks and analyze the impact of quantization and hardware specific bottlenecks. Through simulations, we evaluate a CPU and two systolic inference accelerator implementations. Next, we compare these hardware solutions with advanced technology nodes. The impact of integrating state-of-the-art emerging non-volatile memory technology (STT/SOT/VGSOT MRAM) into the XR-AI inference pipeline is evaluated. We found that significant energy benefits (>=80%) can be achieved for hand detection (IPS=40) and eye segmentation (IPS=6) by introducing non-volatile memory in the memory hierarchy for designs at 7nm node while meeting minimum IPS (inference per second). Moreover, we can realize substantial reduction in area (>=30%) owing to the small form factor of MRAM compared to traditional SRAM. ","authors":"Vivek Parmar, Syed Shakib Sarwar, Ziyun Li, Hsien-Hsin S. Lee, Barbara De Salvo, Manan Suri","pdf":"http://arxiv.org/pdf/2206.06780v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.07476v1","published":"Wed, 15 Jun 2022 12:26:12 GMT","title":"OpenCitations, an open e-infrastructure to foster maximum reuse of   citation data","summary":"  OpenCitations is an independent not-for-profit infrastructure organization for open scholarship dedicated to the publication of open bibliographic and citation data by the use of Semantic Web (Linked Data) technologies. OpenCitations collaborates with projects that are part of the Open Science ecosystem and complies with the UNESCO founding principles of Open Science, the I4OC recommendations, and the FAIR data principles that data should be Findable, Accessible, Interoperable and Reusable. Since its data satisfies all the Reuse guidelines provided by FAIR in terms of richness, provenance, usage licenses and domain-relevant community standards, OpenCitations provides an example of a successful open e-infrastructure in which the reusability of data is integral to its mission. ","authors":"Chiara Di Giambattista, Ivan Heibi, Silvio Peroni, David Shotton","pdf":"http://arxiv.org/pdf/2206.07476v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.07384v1","published":"Wed, 15 Jun 2022 08:47:51 GMT","title":"Blockchain-based Federated Learning for Industrial Metaverses: Incentive   Scheme with Optimal AoI","summary":"  The emerging industrial metaverses realize the mapping and expanding operations of physical industry into virtual space for significantly upgrading intelligent manufacturing. The industrial metaverses obtain data from various production and operation lines by Industrial Internet of Things (IIoT), and thus conduct effective data analysis and decision-making, thereby enhancing the production efficiency of the physical space, reducing operating costs, and maximizing commercial value. However, there still exist bottlenecks when integrating metaverses into IIoT, such as the privacy leakage of sensitive data with commercial secrets, IIoT sensing data freshness, and incentives for sharing these data. In this paper, we design a user-defined privacy-preserving framework with decentralized federated learning for the industrial metaverses. To further improve privacy protection of industrial metaverse, a cross-chain empowered federated learning framework is further utilized to perform decentralized, secure, and privacy-preserving data training on both physical and virtual spaces through a hierarchical blockchain architecture with a main chain and multiple subchains. Moreover, we introduce the age of information as the data freshness metric and thus design an age-based contract model to motivate data sensing among IIoT nodes. Numerical results indicate the efficiency of the proposed framework and incentive mechanism in the industrial metaverses ","authors":"Jiawen Kang, Dongdong Ye, Jiangtian Nie, Jiang Xiao, Xianjun Deng, Siming Wang, Zehui Xiong, Rong Yu, Dusit Niyato","pdf":"http://arxiv.org/pdf/2206.07384v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.07215v1","published":"Wed, 15 Jun 2022 00:01:06 GMT","title":"SPENDER: A Platform for Secure and Privacy-Preserving Decentralized P2P   E-Commerce","summary":"  The blockchain technology empowers secure, trustless, and privacy-preserving trading with cryptocurrencies. However, existing blockchain-based trading platforms only support trading cryptocurrencies with digital assets (e.g., NFTs). Although several payment service providers have started to accept cryptocurrency as a payment method for tangible goods (e.g., Visa, PayPal), customers still need to trust and hand over their private information to centralized E-commerce platforms (e.g., Amazon, eBay). To enable trustless and privacy-preserving trading between cryptocurrencies and real goods, we propose SPENDER, a smart-contract-based platform for Secure and Privacy-PresErviNg Decentralized P2P E-commeRce. The design of our platform enables various advantageous features and brings unlimited future potential. Moreover, our platform provides a complete paradigm for designing real-world Web3 infrastructures on the blockchain, which broadens the application scope and exploits the intrinsic values of cryptocurrencies. The platform has been built and tested on the Terra ecosystem, and we plan to open-source the code later. ","comment":"9 pages, 2 figures, preprint","authors":"Shuhao Zheng, Junliang Luo, Erqun Dong, Can Chen, Xue Liu","pdf":"http://arxiv.org/pdf/2206.07215v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2205.12897v2","published":"Wed, 25 May 2022 16:30:55 GMT","title":"Cryptocurrency Giveaway Scam with YouTube Live Stream","summary":"  This paper investigates the cryptocurrency giveaway scam with the YouTube live stream carried out on 5/15/2022 and 5/16/2022. In this scam scheme, the scammer plays a recorded video of a famous person in a YouTube live stream annotated with a cryptocurrency giveaway announcement. In the annotated announcement, the victims are directed to the scammer's webpage. The scammer's webpage is designed intelligently to deceive victims such that they believe the legitimacy of the giveaway. The scammer claims that whatever donation the victim sends to a cryptocurrency wallet address, the giveaway scheme will double the donated amount and immediately send it back to the victim. By analyzing the scammers' wallet addresses, it can be seen that scammers could steal a significant amount of money in a short time. After analyzing the attackers' techniques, tactics, and procedures, this paper discusses the countermeasures that can be applied to mitigate such a fraudulent activity in the future. ","authors":"Iman Vakilinia","pdf":"http://arxiv.org/pdf/2205.12897v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08202v1","published":"Thu, 16 Jun 2022 14:20:19 GMT","title":"Token Spammers, Rug Pulls, and SniperBots: An Analysis of the Ecosystem   of Tokens in Ethereum and the Binance Smart Chain (BNB)","summary":"  In this work, we perform a longitudinal analysis of the BNB Smart Chain and Ethereum blockchain from their inception to March 2022. We study the ecosystem of the tokens and liquidity pools, highlighting analogies and differences between the two blockchains. We estimate the lifetime of the tokens, discovering that about 60% of them are active for less than one day. Moreover, we find that 1% of addresses create an anomalous number of tokens (between 20% and 25%). We present an exit scam fraud and quantify its prevalence on both blockchains. We find that token spammers use short lifetime tokens as disposable tokens to perpetrate these frauds serially. Finally, we present a new kind of trader bot involved in these activities, and we detect their presence and quantify their activity in the exit scam operations. ","authors":"Federico Cernera, Massimo La Morgia, Alessandro Mei, Francesco Sassi","pdf":"http://arxiv.org/pdf/2206.08202v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08132v1","published":"Thu, 16 Jun 2022 12:48:58 GMT","title":"Adaptive versus Static Multi-oracle Algorithms, and Quantum Security of   a Split-key PRF","summary":"  In the first part of the paper, we show a generic compiler that transforms any oracle algorithm that can query multiple oracles {\\\\em adaptively}, i.e., can decide on {\\\\em which} oracle to query at what point dependent on previous oracle responses, into a {\\\\em static} algorithm that fixes these choices at the beginning of the execution. Compared to naive ways of achieving this, our compiler controls the blow-up in query complexity for each oracle {\\\\em individually}, and causes a very mild blow-up only. In the second part of the paper, we use our compiler to show the security of the very efficient hash-based {\\\\em split-key PRF} proposed by Giacon, Heuer and Poettering (PKC~2018), in the {\\\\em quantum} random-oracle model. Using a split-key PRF as the key-derivation function gives rise to a secure KEM combiner. Thus, our result shows that the hash-based construction of Giacon {\\\\em et al.}\\\\ can be safely used in the context of quantum attacks, for instance to combine a well-established but only classically-secure KEM with a candidate KEM that is believed to be quantum-secure. Our security proof for the split-key PRF crucially relies on our adaptive-to-static compiler, but we expect our compiler to be useful beyond this particular application. Indeed, we discuss a couple of other, known results from the literature that would have profitted from our compiler, in that these works had to go though serious complications in oder to deal with adaptivity. ","authors":"Jelle Don, Serge Fehr, Yu-Hsuan Huang","pdf":"http://arxiv.org/pdf/2206.08132v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.07981v1","published":"Thu, 16 Jun 2022 07:47:57 GMT","title":"Multi-scale Cooperative Multimodal Transformers for Multimodal Sentiment   Analysis in Videos","summary":"  Multimodal sentiment analysis in videos is a key task in many real-world applications, which usually requires integrating multimodal streams including visual, verbal and acoustic behaviors. To improve the robustness of multimodal fusion, some of the existing methods let different modalities communicate with each other and modal the crossmodal interaction via transformers. However, these methods only use the single-scale representations during the interaction but forget to exploit multi-scale representations that contain different levels of semantic information. As a result, the representations learned by transformers could be biased especially for unaligned multimodal data. In this paper, we propose a multi-scale cooperative multimodal transformer (MCMulT) architecture for multimodal sentiment analysis. On the whole, the \\multi-scale\\ mechanism is capable of exploiting the different levels of semantic information of each modality which are used for fine-grained crossmodal interactions. Meanwhile, each modality learns its feature hierarchies via integrating the crossmodal interactions from multiple level features of its source modality. In this way, each pair of modalities progressively builds feature hierarchies respectively in a cooperative manner. The empirical results illustrate that our MCMulT model not only outperforms existing approaches on unaligned multimodal sequences but also has strong performance on aligned multimodal sequences. ","authors":"Lianyang Ma, Yu Yao, Tao Liang, Tongliang Liu","pdf":"http://arxiv.org/pdf/2206.07981v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.07895v1","published":"Thu, 16 Jun 2022 03:03:02 GMT","title":"Dual-channel Early Warning Framework for Ethereum Ponzi Schemes","summary":"  Blockchain technology supports the generation and record of transactions, and maintains the fairness and openness of the cryptocurrency system. However, many fraudsters utilize smart contracts to create fraudulent Ponzi schemes for profiting on Ethereum, which seriously affects financial security. Most existing Ponzi scheme detection techniques suffer from two major restricted problems: the lack of motivation for temporal early warning and failure to fuse multi-source information finally cause the lagging and unsatisfactory performance of Ethereum Ponzi scheme detection. In this paper, we propose a dual-channel early warning framework for Ethereum Ponzi schemes, named Ponzi-Warning, which performs feature extraction and fusion on both code and transaction levels. Moreover, we represent a temporal evolution augmentation strategy for generating transaction graph sequences, which can effectively increase the data scale and introduce temporal information. Comprehensive experiments on our Ponzi scheme datasets demonstrate the effectiveness and timeliness of our framework for detecting the Ponzi contract accounts. ","authors":"Jie Jin, Jiajun Zhou, Chengxiang Jin, Shanqing Yu, Ziwan Zheng, Qi Xuan","pdf":"http://arxiv.org/pdf/2206.07895v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.07831v1","published":"Wed, 15 Jun 2022 22:02:05 GMT","title":"Analysis of inter-transaction time fluctuations in the cryptocurrency   market","summary":"  We analyse tick-by-tick data representing major cryptocurrencies traded on some different cryptocurrency trading platforms. We focus on such quantities like the inter-transaction times, the number of transactions in time unit, the traded volume, and volatility. We show that the inter-transaction times show long-range power-law autocorrelations that lead to multifractality expressed by the right-side asymmetry of the singularity spectra $f(\\\\alpha)$ indicating that the periods of increased market activity are characterised by richer multifractality compared to the periods of quiet market. We show that the inter-transaction times show long-range power-law autocorrelations. These lead to multifractality expressed by the right-side asymmetry of the singularity spectra $f(\\\\alpha)$ indicating that the periods of increased market activity are characterised by richer multifractality compared to the periods of quiet market. We also show that neither the stretched exponential distribution nor the power-law-tail distribution are able to model universally the cumulative distribution functions of the quantities considered in this work. For each quantity, some data sets can be modeled by the former, some data sets by the latter, while both fail in other cases. An interesting, yet difficult to account for, observation is that parallel data sets from different trading platforms can show disparate statistical properties. ","authors":"Jarosław Kwapień, Marcin Wątorek, Marija Bezbradica, Martin Crane, Tai Tan Mai, Stanisław Drożdż","pdf":"http://arxiv.org/pdf/2206.07831v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08133v1","published":"Wed, 15 Jun 2022 17:56:06 GMT","title":"Equilibria in Network Constrained Energy Markets","summary":"  We study the equilibrium state of an energy market composed of producers who compete to supply energy to different markets and want to maximize their profits. The energy market is modeled by means of a graph that represents a constrained power network where nodes represent the markets and links are the physical lines with a finite capacity connecting them. Producers play a networked Cournot game on such a network together with a centralized authority, called market maker, that facilitates the trade between geographically separate markets via the constrained power network and aims to maximize a certain welfare function. We study existence of uniqueness of the Nash equilibria and prove a connection between capacity bottlenecks in the power network and the emergence of price differences between different markets that are separated by bottlenecked lines. ","authors":"Leonardo Massai, Giacomo Como, Fabio Fagnani","pdf":"http://arxiv.org/pdf/2206.08133v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.07981v2","published":"Thu, 16 Jun 2022 07:47:57 GMT","title":"Multi-scale Cooperative Multimodal Transformers for Multimodal Sentiment   Analysis in Videos","summary":"  Multimodal sentiment analysis in videos is a key task in many real-world applications, which usually requires integrating multimodal streams including visual, verbal and acoustic behaviors. To improve the robustness of multimodal fusion, some of the existing methods let different modalities communicate with each other and modal the crossmodal interaction via transformers. However, these methods only use the single-scale representations during the interaction but forget to exploit multi-scale representations that contain different levels of semantic information. As a result, the representations learned by transformers could be biased especially for unaligned multimodal data. In this paper, we propose a multi-scale cooperative multimodal transformer (MCMulT) architecture for multimodal sentiment analysis. On the whole, the \\multi-scale\\ mechanism is capable of exploiting the different levels of semantic information of each modality which are used for fine-grained crossmodal interactions. Meanwhile, each modality learns its feature hierarchies via integrating the crossmodal interactions from multiple level features of its source modality. In this way, each pair of modalities progressively builds feature hierarchies respectively in a cooperative manner. The empirical results illustrate that our MCMulT model not only outperforms existing approaches on unaligned multimodal sequences but also has strong performance on aligned multimodal sequences. ","authors":"Lianyang Ma, Yu Yao, Tao Liang, Tongliang Liu","pdf":"http://arxiv.org/pdf/2206.07981v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08905v1","published":"Fri, 17 Jun 2022 17:30:00 GMT","title":"What makes Ethereum blockchain transactions be processed fast or slow?   An empirical study","summary":"  The Ethereum platform allows developers to implement and deploy applications called Dapps onto the blockchain for public use through the use of smart contracts. To execute code within a smart contract, a paid transaction must be issued towards one of the functions that are exposed in the interface of a contract. However, such a transaction is only processed once one of the miners in the peer-to-peer network selects it, adds it to a block, and appends that block to the blockchain This creates a delay between transaction submission and code execution. It is crucial for Dapp developers to be able to precisely estimate when transactions will be processed, since this allows them to define and provide a certain Quality of Service (QoS) level (e.g., 95% of the transactions processed within 1 minute). However, the impact that different factors have on these times have not yet been studied. Processing time estimation services are used by Dapp developers to achieve predefined QoS. Yet, these services offer minimal insights into what factors impact processing times. Considering the vast amount of data that surrounds the Ethereum blockchain, changes in processing times are hard for Dapp developers to predict, making it difficult to maintain said QoS. In our study, we build random forest models to understand the factors that are associated with transaction processing times. We engineer several features that capture blockchain internal factors, as well as gas pricing behaviors of transaction issuers. By interpreting our models, we conclude that features surrounding gas pricing behaviors are very strongly associated with transaction processing times. Based on our empirical results, we provide Dapp developers with concrete insights that can help them provide and maintain high levels of QoS. ","comment":"Under Peer review in Empirical Software Engineering Journal","authors":"Michael Pacheco, Gustavo A. Oliva, Gopi Krishnan Rajbahadur, Ahmed E. Hassan","pdf":"http://arxiv.org/pdf/2206.08905v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08821v1","published":"Fri, 17 Jun 2022 15:01:23 GMT","title":"Exploring Web3 From the View of Blockchain","summary":"  Web3 is the most hyped concept from 2020 to date, greatly motivating the prosperity of the Internet of Value and Metaverse. However, no solid evidence stipulates the exact definition, criterion, or standard in the sense of such a buzzword. To fill the gap, we aim to clarify the term in this work. We narrow down the connotation of Web3 by separating it from high-level controversy argues and, instead, focusing on its protocol, architecture, and evaluation from the perspective of blockchain fields. Specifically, we have identified all potential architectural design types and evaluated each of them by employing the scenario-based architecture evaluation method. The evaluation shows that existing applications are neither secure nor adoptable as claimed. Meanwhile, we also discuss opportunities and challenges surrounding the Web3 space and answer several prevailing questions from communities. A primary result is that Web3 still relies on traditional internet infrastructure, not as independent as advocated. This report, as of June 2022, provides the first strict research on Web3 in the view of blockchain. We hope that this work would provide a guide for the development of future Web3 services. ","comment":"Tech Report 2022","authors":"Qin Wang, Rujia Li, Qi Wang, Shiping Chen, Mark Ryan, Thomas Hardjono","pdf":"http://arxiv.org/pdf/2206.08821v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08415v1","published":"Thu, 16 Jun 2022 19:14:54 GMT","title":"CS-UM6P at SemEval-2022 Task 6: Transformer-based Models for Intended   Sarcasm Detection in English and Arabic","summary":"  Sarcasm is a form of figurative language where the intended meaning of a sentence differs from its literal meaning. This poses a serious challenge to several Natural Language Processing (NLP) applications such as Sentiment Analysis, Opinion Mining, and Author Profiling. In this paper, we present our participating system to the intended sarcasm detection task in English and Arabic languages. Our system\\\\footnote{The source code of our system is available at \\\\url{https://github.com/AbdelkaderMH/iSarcasmEval}} consists of three deep learning-based models leveraging two existing pre-trained language models for Arabic and English. We have participated in all sub-tasks. Our official submissions achieve the best performance on sub-task A for Arabic language and rank second in sub-task B. For sub-task C, our system is ranked 7th and 11th on Arabic and English datasets, respectively. ","authors":"Abdelkader El Mahdaouy, Abdellah El Mekki, Kabil Essefar, Abderrahman Skiredj, Ismail Berrada","pdf":"http://arxiv.org/pdf/2206.08415v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08401v1","published":"Thu, 16 Jun 2022 18:26:38 GMT","title":"Are decentralized finance really decentralized? A social network   analysis of the Aave protocol on the Ethereum blockchain","summary":"  Decentralized finance (DeFi) has the potential to disrupt centralized finance by validating peer-to-peer transactions through tamper-proof smart contracts and thus significantly lower the transaction cost charged by financial intermediaries. However, the actual realization of peer-to-peer transactions and the levels and effect of decentralization are largely unknown. Our research pioneers a blockchain network study that applies social network analysis to measure the level, dynamics, and impacts of decentralization in DeFi token transactions on Ethereum blockchain. First, we find a significant core-periphery structure in the AAVE token transaction network where the cores include the two largest centralized crypto exchanges. Second, we provide evidence that multiple network features consistently characterize decentralization dynamics. Finally, we document that a more decentralized network significantly predicts a higher return and lower volatilities of the DeFi tokens. We point out that our approach is seminal for inspiring future extensions related to the facets of application scenarios, research questions, and methodologies on the mechanics of blockchain decentralization. ","comment":"Accepted at 29th Annual Global Finance Conference featuring Professor   Robert Engle, The 2003 Nobel Laureate in Economic Sciences","authors":"Ziqiao Ao, Gergely Horvath, Luyao Zhang","pdf":"http://arxiv.org/pdf/2206.08401v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08132v2","published":"Thu, 16 Jun 2022 12:48:58 GMT","title":"Adaptive versus Static Multi-oracle Algorithms, and Quantum Security of   a Split-key PRF","summary":"  In the first part of the paper, we show a generic compiler that transforms any oracle algorithm that can query multiple oracles *adaptively*, i.e., can decide on *which* oracle to query at what point dependent on previous oracle responses, into a *static* algorithm that fixes these choices at the beginning of the execution. Compared to naive ways of achieving this, our compiler controls the blow-up in query complexity for each oracle *individually*, and causes a very mild blow-up only. In the second part of the paper, we use our compiler to show the security of the very efficient hash-based *split-key PRF* proposed by Giacon, Heuer and Poettering (PKC~2018), in the *quantum* random-oracle model. Using a split-key PRF as the key-derivation function gives rise to a secure KEM combiner. Thus, our result shows that the hash-based construction of Giacon et al. can be safely used in the context of quantum attacks, for instance to combine a well-established but only classically-secure KEM with a candidate KEM that is believed to be quantum-secure. Our security proof for the split-key PRF crucially relies on our adaptive-to-static compiler, but we expect our compiler to be useful beyond this particular application. Indeed, we discuss a couple of other, known results from the literature that would have profitted from our compiler, in that these works had to go though serious complications in oder to deal with adaptivity. ","authors":"Jelle Don, Serge Fehr, Yu-Hsuan Huang","pdf":"http://arxiv.org/pdf/2206.08132v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.10280v1","published":"Tue, 21 Jun 2022 12:06:03 GMT","title":"muBoost: An Effective Method for Solving Indic Multilingual Text   Classification Problem","summary":"  Text Classification is an integral part of many Natural Language Processing tasks such as sarcasm detection, sentiment analysis and many more such applications. Many e-commerce websites, social-media/entertainment platforms use such models to enhance user-experience to generate traffic and thus, revenue on their platforms. In this paper, we are presenting our solution to Multilingual Abusive Comment Identification Problem on Moj, an Indian video-sharing social networking service, powered by ShareChat. The problem dealt with detecting abusive comments, in 13 regional Indic languages such as Hindi, Telugu, Kannada etc., on the videos on Moj platform. Our solution utilizes the novel muBoost, an ensemble of CatBoost classifier models and Multilingual Representations for Indian Languages (MURIL) model, to produce SOTA performance on Indic text classification tasks. We were able to achieve a mean F1-score of 89.286 on the test data, an improvement over baseline MURIL model with a F1-score of 87.48. ","authors":"Manish Pathak, Aditya Jain","pdf":"http://arxiv.org/pdf/2206.10280v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.10257v1","published":"Tue, 21 Jun 2022 11:10:21 GMT","title":"Satoshi Nakamoto and the Origins of Bitcoin -- Narratio in Nomine, Datis   et Numeris","summary":"  The mystery about the ingenious creator of Bitcoin concealing behind the pseudonym Satoshi Nakamoto has been fascinating the global public for more than a decade. Suddenly jumping out of the dark in 2008, this persona hurled the highly disruptive distributed ledger technology \\blockchain\\ that has added the missing native value layer to the internet. Purposely agnostic without advocating any old or fielding new names, this paper first identifies the degrees of freedom Satoshi Nakamoto had available in the design of Bitcoin, and in fabricating snippets of personal data. By interweaving the substantial collection of previous and new circumstantial with direct evidence, like relevant locations and happenings in history and at the time, a consistent skeleton of Satoshi Nakamoto's biography transpires. The results underpin that the iconic creator of Bitcoin most likely encoded bits of information in his self-chosen alias, dates and blockchain parameters, which particularly point to the numbers 21 and 42, and the numeral systems used in Bitcoin's framework. Moreover, a psychogram of a reclusive and capricious genius is drawn, which sheds new light on Satoshi Nakamoto's background, mindset, pastimes, and penchant for puns; this study may also explain the motivation of his abrupt departure from the public, his continuing abstinence from engaging with the Bitcoin community, and from reaping the fruits of his mindboggling wealth. From a history of technology perspective, such an altruistic sacrifice for the benefit of his brainchild is entirely unprecedented. ","comment":"Main text:39 pages Number of references: 503 Appendix: 6 pages","authors":"Jens Ducrée","pdf":"http://arxiv.org/pdf/2206.10257v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.09680v1","published":"Mon, 20 Jun 2022 09:42:50 GMT","title":"Misspelling Semantics In Thai","summary":"  User-generated content is full of misspellings. Rather than being just random noise, we hypothesise that many misspellings contain hidden semantics that can be leveraged for language understanding tasks. This paper presents a fine-grained annotated corpus of misspelling in Thai, together with an analysis of misspelling intention and its possible semantics to get a better understanding of the misspelling patterns observed in the corpus. In addition, we introduce two approaches to incorporate the semantics of misspelling: Misspelling Average Embedding (MAE) and Misspelling Semantic Tokens (MST). Experiments on a sentiment analysis task confirm our overall hypothesis: additional semantics from misspelling can boost the micro F1 score up to 0.4-2%, while blindly normalising misspelling is harmful and suboptimal. ","comment":"To be published in LREC2022","authors":"Pakawat Nakwijit, Matthew Purver","pdf":"http://arxiv.org/pdf/2206.09680v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.09582v1","published":"Mon, 20 Jun 2022 06:07:33 GMT","title":"Analysis of Electric Vehicle Charging Station Usage and Profitability in   Germany based on Empirical Data","summary":"  Electric vehicles are booming and with them the required public charging stations. Knowing how charging stations are used is crucial for operators of the charging stations themselves, navigation systems, electricity grids, and many more. Given that there are now 2.5 as many vehicles per charging station compared to 2017, the system needs to allocate charging points intelligently and efficiently. This paper presents representative data on energy consumption, arrival times, occupation, and profitability of charging stations in Germany by combining usage data of 27,800 installations. Charging happens mainly during the day and on weekdays for AC charging stations while DC fast-charging stations are more popular on the weekend. Fast-chargers service approximately 3 times as many vehicles per connection point while also being substantially more profitable due to higher achieved margins. For AC chargers, up to 20 kWh of energy are charged in an average charge event while DC fast-chargers supply approximately 40 kWh. ","comment":"Paper currently under review. Please check if full paper is available   before citing. Accompanying data will be published alongside the full paper","authors":"Christopher Hecht, Jan Figgener, Dirk Uwe Sauer","pdf":"http://arxiv.org/pdf/2206.09582v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.09578v1","published":"Mon, 20 Jun 2022 05:41:19 GMT","title":"Performance-Oriented Design for Intelligent Reflecting Surface Assisted   Federated Learning","summary":"  To efficiently exploit the massive raw data that is pervading generated at mobile edge networks, federated learning (FL) has emerged as a promising distributed learning technique that was regarded as a substitute for centralized learning operations. By collaboratively training a shared learning model at edge devices, the raw data transmission and storage are bypassed via the local computed parameters/gradients exchange in FL. Hence, FL can overcome high communication latency and privacy issues. While the high dimensionality in iterative updates (millions of parameters/gradients may be included in the model training) still conflicts with the scarcity of communication resources. Over-the-air computation (AirComp) has come into the spotlight recently which profitably leverages the inherent superposition property of wireless channels to perform efficient model aggeration. However, the model aggregation accuracy is still severely damaged by the unfavorable wireless propagation channels. In this paper, we harness the intelligent reflecting surface (IRS) to program the wireless channel, thus acquiring a satisfying learning performance. Specifically, a performance-oriented design scheme that directly minimizes the optimality gap of the loss function is proposed to accelerate the convergence of AirComp based FL. Firstly, we analyze the convergence behavior of the FL procedure. Then, both offline and online design approaches are proposed based on the obtained optimality gap. We adopt the block coordinate descent (BCD) method to tackle the highly-intractable problem. Simulation results demonstrate that such a performance-oriented design strategy can achieve higher test accuracy than the conventional isolated mean square error (MSE) minimization approach in FL. ","comment":"This work has been submitted to the IEEE for possible publication","authors":"Yapeng Zhao, Qingqing Wu, Wen Chen","pdf":"http://arxiv.org/pdf/2206.09578v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.09083v1","published":"Sat, 18 Jun 2022 01:54:49 GMT","title":"Universal Behavior of Opponent Statistics and Applications to the MLB","summary":"  In most popular sports leagues, like the MLB, NBA, and NFL, none of the commonly used statistics take into account the strengths of the opponents a player faces. One of the main reasons for this is the conventional belief that a player's luck tends to even out over the course of a season. The other main reason is the difficulties of finding a sensible algorithm to both quantify the strengths of the opponents and incorporate such quantifications into a renormalization of a player's statistics.   In this paper, we first argue that certain statistics, such as Earned Run Average (ERA) or Fielding Independent Pitching (FIP) can be significantly skewed by opponents' strengths in the MLB. We then present an algorithm to renormalize such statistics, using FIP as the main example. This is achieved by observing that certain opponent statistics for all 30 teams in the MLB (e.g. the collection of each game's opponent FIP value over the course of a season) follow a universal distribution, up to scaling and shift.   This enables us to establish a data set for a hypothetical average team and to develop a pitching statistic based on FIP which accounts for the strength of a pitcher's schedule through methods based on equipercentile equating. It is called aFIP, which measures what a pitcher's FIP would have been if he had faced a league-average offensive team every time he pitched.   We find that there is a significant difference between aFIP and FIP for some pitchers during the 2019 season and other seasons as well, adding a new tool for player evaluation. This could make millions of dollars of difference in player contracts and in profits for teams as they enhance the accuracy with which they make player acquisitions. The universal distribution we observed also has many possible future applications throughout the sports world. ","comment":"20 pages, 4 figures, 3 tables","authors":"Francis Liu","pdf":"http://arxiv.org/pdf/2206.09083v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.09041v1","published":"Fri, 17 Jun 2022 22:52:56 GMT","title":"Accelerating Machine Learning Training Time for Limit Order Book   Prediction","summary":"  Financial firms are interested in simulation to discover whether a given algorithm involving financial machine learning will operate profitably. While many versions of this type of algorithm have been published recently by researchers, the focus herein is on a particular machine learning training project due to the explainable nature and the availability of high frequency market data. For this task, hardware acceleration is expected to speed up the time required for the financial machine learning researcher to obtain the results. As the majority of the time can be spent in classifier training, there is interest in faster training steps. A published Limit Order Book algorithm for predicting stock market direction is our subject, and the machine learning training process can be time-intensive especially when considering the iterative nature of model development. To remedy this, we deploy Graphical Processing Units (GPUs) produced by NVIDIA available in the data center where the computer architecture is geared to parallel high-speed arithmetic operations. In the studied configuration, this leads to significantly faster training time allowing more efficient and extensive model development. ","authors":"Mark Joseph Bennett","pdf":"http://arxiv.org/pdf/2206.09041v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.09011v1","published":"Fri, 17 Jun 2022 21:10:19 GMT","title":"Evolutionary Random Graph for Bitcoin Overlay and Blockchain Mining   Networks","summary":"  The world economy is experiencing the novel adoption of distributed currencies that are free from the control of central banks. Distributed currencies suffer from extreme volatility, and this can lead to catastrophic implications during future economic crisis. Understanding the dynamics of this new type of currencies is vital for empowering supervisory bodies from current reactive and manual incident responders to more proactive and well-informed planners. Bitcoin, the first and dominant distributed cryptocurrency, is still notoriously vague, especially for a financial instrument with market value exceeding 1 trillion. Modeling of bitcoin overlay network poses a number of important theoretical and methodological challenges. Current measuring approaches, for example, fail to identify the real network size of bitcoin miners. This drastically undermines the ability to predict forks, the suitable mining difficulty and most importantly the resilience of the network supporting bitcoin. In this work, we developed Evolutionary Random Graph, a theoretical model that describes the network of bitcoin miners. The correctness of this model has been validated using simulated and measure real bitcoin data. We then predicted forking, optimal mining difficulty, network size and consequently the network's inability to stand a drastic drop in bitcoin price using the current mining configuration. ","comment":"12 pages, 12 figures, 13 equations","authors":"Jacques Bou Abdo, Shuvalaxmi Dass, Basheer Qolomany, Liaquat Hossain","pdf":"http://arxiv.org/pdf/2206.09011v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.08959v1","published":"Fri, 17 Jun 2022 18:21:04 GMT","title":"Is my transaction done yet? An empirical study of transaction processing   times in the Ethereum Blockchain Platform","summary":"  Ethereum is one of the most popular platforms for the development of blockchain-powered applications. These applications are known as Dapps. When engineering Dapps, developers need to translate requests captured in the front-end of their application into one or more smart contract transactions. Developers need to pay for these transactions and, the more they pay (i.e., the higher the gas price), the faster the transaction is likely to be processed. Therefore developers need to optimize the balance between cost (transaction fees) and user experience (transaction processing times). Online services have been developed to provide transaction issuers (e.g., Dapp developers) with an estimate of how long transactions will take to be processed given a certain gas price. These estimation services are crucial in the Ethereum domain and several popular wallets such as Metamask rely on them. However, their accuracy has not been empirically investigated so far. In this paper, we quantify the transaction processing times in Ethereum, investigate the relationship between processing times and gas prices, and determine the accuracy of state-of-the-practice estimation services. We find that transactions are processed in a median of 57s and that 90% of the transactions are processed within 8m. The higher gas prices result in faster transaction processing times with diminishing returns. In particular, we observe no practical difference in processing time between expensive and very expensive transactions. In terms of accuracy of processing time estimation services, we note that they are equivalent. However, when stratifying transactions by gas prices, Etherscan's Gas Tracker is the most accurate estimation service for very cheap and cheap transaction. EthGasStation's Gas Price API, in turn, is the most accurate estimation service for regular, expensive, and very expensive transactions. ","comment":"Under review in Transactions of Software Engineering and Methodology   journal","authors":"Michael Pacheco, Gustavo A. Oliva, Gopi Krishnan Rajbahadur, Ahmed E. Hassan","pdf":"http://arxiv.org/pdf/2206.08959v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.10326v1","published":"Tue, 14 Jun 2022 14:21:33 GMT","title":"Sense The Physical, Walkthrough The Virtual, Manage The Metaverse: A   Data-centric Perspective","summary":"  In the Metaverse, the physical space and the virtual space co-exist, and interact simultaneously. While the physical space is virtually enhanced with information, the virtual space is continuously refreshed with real-time, real-world information. To allow users to process and manipulate information seamlessly between the real and digital spaces, novel technologies must be developed. These include smart interfaces, new augmented realities, efficient storage and data management and dissemination techniques. In this paper, we first discuss some promising co-space applications. These applications offer experiences and opportunities that neither of the spaces can realize on its own. We then argue that the database community has much to offer to this field. Finally, we present several challenges that we, as a community, can contribute towards managing the Metaverse. ","authors":"Beng Chin Ooi, Kian-Lee Tan, Anthony Tung, Gang Chen, Mike Zheng Shou, Xiaokui Xiao, Meihui Zhang","pdf":"http://arxiv.org/pdf/2206.10326v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.10993v1","published":"Wed, 22 Jun 2022 11:49:16 GMT","title":"SEnti-Analyzer: Joint Sentiment Analysis For Text-Based and Verbal   Communication in Software Projects","summary":"  Social aspects in software development teams are of particular importance for a successful project closure. To analyze sentiments in software projects, there are several tools and approaches available. These tools analyze text-based communication based on the used words to predict whether they appear to be positive, negative, or neutral for the receiver of the message. In the research project ComContA, we investigate so-called sentiment analysis striving to analyze the content of text-based communication in development teams with regard to the statement's polarity. That is, we analyze whether the communication appears to be adequate (i.e., positive or neutral) or negative. In a workshop paper, we presented a tool called SEnti-Analyzer that allows to apply sentiment analysis to verbal communication in meetings of software projects. In this technical report, we present the extended functionalities of the SEnti-Analyzer by also allowing the analysis of text-based communication, we improve the prediction of the tool by including established sentiment analysis tools, and we evaluate the tool with respect to its accuracy. We evaluate the tool by comparing the prediction of the SEnti-Analyzer to pre-labeled established data sets used for sentiment analysis in software engineering and to perceptions of computer scientists. Our results indicate that in almost all cases at least two of the three votes coincide, but in only about half of the cases all three votes coincide. Our results raise the question of the \\ultimate truth\\ of sentiment analysis outcomes: What do we want to predict with sentiment analysis tools? The pre-defined labels of established data sets? The perception of computer scientists? Or the perception of single computer scientists which appears to be the most meaningful objective? ","comment":"Technical Report. arXiv admin note: text overlap with   arXiv:2108.01985","authors":"Marc Herrmann, Martin Obaidi, Jil Klünder","pdf":"http://arxiv.org/pdf/2206.10993v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.10708v1","published":"Tue, 21 Jun 2022 19:56:54 GMT","title":"FlashSyn: Flash Loan Attack Synthesis via Counter Example Driven   Approximation","summary":"  In decentralized finance (DeFi) ecosystem, lenders can offer flash loans to borrowers, i.e., loans that are only valid within a blockchain transaction and must be repaid with some fees by the end of that transaction. Unlike normal loans, flash loans allow borrowers to borrow a large amount of assets without upfront collaterals deposits. Malicious adversaries can use flash loans to gather large amount of assets to launch costly exploitations targeting DeFi protocols. In this paper, we introduce a new framework for automated synthesis of adversarial contracts that exploit DeFi protocols using flash loans. To bypass the complexity of a DeFi protocol, we propose a new technique to approximate DeFi protocol functional behaviors using numerical methods. Then, we propose a novel algorithm to find an adversarial attack which constitutes of a sequence of invocations of functions in a DeFi protocol with the optimized parameters for profits. We implemented our framework in a tool called FlashSyn. We run FlashSyn on 5 DeFi protocols that were victims to flash loan attacks and DeFi protocols from Damn Vulnerable DeFi challenges. FlashSyn automatically synthesizes an adversarial attack for each one of them. ","comment":"29 pages, 8 figures, technical report","authors":"Zhiyang Chen, Sidi Mohamed Beillahi, Fan Long","pdf":"http://arxiv.org/pdf/2206.10708v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.10661v1","published":"Thu, 09 Jun 2022 16:43:54 GMT","title":"Mapping Philanthropic Support of Science","summary":"  While philanthropic support plays an increasing role in supporting research, there is limited quantitative knowledge about the patterns that characterize the distribution of philanthropic support. Here, we map philanthropic funding to universities and research institutions based on IRS tax forms from 685,397 non-profit organizations. We identify nearly one million grants supporting institutions involved in science, finding that in volume and scope, philanthropic funding is comparable to federal research funding. However, whereas federal funding relies on a few large organizations to distribute grants, the philanthropic ecosystem's support is fragmented among a large number of funders with diverse focus that support research institutions at varying levels. Furthermore, we find that distinct from government support, philanthropic funders tend to focus locally, indicating that other criteria, beyond research excellence, play a role in their funding decisions. We also show evidence of persistence, i.e., once a grant-giving relationship begins, it tends to continue in time. Finally, we discuss the policy implications of our findings for philanthropic funders, individual researchers, the science of science, and for quantitative studies of philanthropy in general. ","authors":"Louis M. Shekhtman, Alexander J. Gates, Albert-László Barabási","pdf":"http://arxiv.org/pdf/2206.10661v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.11822v1","published":"Thu, 23 Jun 2022 16:45:50 GMT","title":"DeepSafety:Multi-level Audio-Text Feature Extraction and Fusion Approach   for Violence Detection in Conversations","summary":"  Natural Language Processing has recently made understanding human interaction easier, leading to improved sentimental analysis and behaviour prediction. However, the choice of words and vocal cues in conversations presents an underexplored rich source of natural language data for personal safety and crime prevention. When accompanied by audio analysis, it makes it possible to understand the context of a conversation, including the level of tension or rift between people. Building on existing work, we introduce a new information fusion approach that extracts and fuses multi-level features including verbal, vocal, and text as heterogeneous sources of information to detect the extent of violent behaviours in conversations. Our multilevel multimodel fusion framework integrates four types of information from raw audio signals including embeddings generated from both BERT and Bi-long short-term memory (LSTM) models along with the output of 2D CNN applied to Mel-frequency Cepstrum (MFCC) as well as the output of audio Time-Domain dense layer. The embeddings are then passed to three-layer FC networks, which serve as a concatenated step. Our experimental setup revealed that the combination of the multi-level features from different modalities achieves better performance than using a single one with F1 Score=0.85. We expect that the findings derived from our method provides new approaches for violence detection in conversations. ","comment":"34 pages, 6 figures","authors":"Amna Anwar, Eiman Kanjo, Dario Ortega Anderez","pdf":"http://arxiv.org/pdf/2206.11822v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.11821v1","published":"Thu, 23 Jun 2022 16:45:44 GMT","title":"A Survey of DeFi Security: Challenges and Opportunities","summary":"  Decentralized finance (DeFi), which is a promising domain since the era of blockchain 2.0, locked \\\\$200 billion in April 2022. However, it quickly dropped to \\\\$100 billion in May 2022, which makes us realize that security issues in this area are still a challenging job. DeFi is more complex than traditional finance because it is decentralized through blockchain and without a trustworthy third-party institution to act as a guarantee. So it owns not only financial properties but also technical aspects. Existing synthesis work for DeFi tends to ignore the relevance of various layers of security for the whole system. In addition, distinct layers have different means of protection against specific vulnerabilities, which is not considered by existing analytical work. In this paper, we perform a vulnerability analysis for the entire technology layer of the DeFi application, and then we collect the most impactive attacks in recent years. Finally, we summarize the existing optimization approaches for different layers and provide some challenges and future directions. ","authors":"Wenkai Li, Jiuyang Bu, Xiaoqi Li, Hongli Peng, Yuanzheng Niu, Xianyi Chen","pdf":"http://arxiv.org/pdf/2206.11821v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.11433v1","published":"Thu, 23 Jun 2022 00:40:19 GMT","title":"Shilling Black-box Recommender Systems by Learning to Generate Fake User   Profiles","summary":"  Due to the pivotal role of Recommender Systems (RS) in guiding customers towards the purchase, there is a natural motivation for unscrupulous parties to spoof RS for profits. In this paper, we study Shilling Attack where an adversarial party injects a number of fake user profiles for improper purposes. Conventional Shilling Attack approaches lack attack transferability (i.e., attacks are not effective on some victim RS models) and/or attack invisibility (i.e., injected profiles can be easily detected). To overcome these issues, we present Leg-UP, a novel attack model based on the Generative Adversarial Network. Leg-UP learns user behavior patterns from real users in the sampled ``templates'' and constructs fake user profiles. To simulate real users, the generator in Leg-UP directly outputs discrete ratings. To enhance attack transferability, the parameters of the generator are optimized by maximizing the attack performance on a surrogate RS model. To improve attack invisibility, Leg-UP adopts a discriminator to guide the generator to generate undetectable fake user profiles. Experiments on benchmarks have shown that Leg-UP exceeds state-of-the-art Shilling Attack methods on a wide range of victim RS models. The source code of our work is available at: https://github.com/XMUDM/ShillingAttack. ","comment":"Accepted by TNNLS. 15 pages, 8 figures","authors":"Chen Lin, Si Chen, Meifang Zeng, Sheng Zhang, Min Gao, Hui Li","pdf":"http://arxiv.org/pdf/2206.11433v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.11846v1","published":"Wed, 22 Jun 2022 17:45:47 GMT","title":"Analysis of account behaviors in Ethereum during an economic impact   event","summary":"  One of the main events that involve the world economy in 2022 is the conflict between Russia and Ukraine. This event offers a rare opportunity to analyze how events of this magnitude can reflect the use of cryptocurrencies. This work aims to investigate the behavior of accounts and their transactions on the Ethereum cryptocurrency during this event. To this end, we collected all transactions that occurred two weeks before and two weeks after the beginning of the conflict, organized into two groups: the collection of the accounts involved in these transactions and the subset of these ones that interacted with a service in Ethereum, called Flashbots Auction. We modeled temporal graphs where each node represents an account, and each edge represents a transaction between two accounts. Then, we analyzed the behavior of these accounts with graph metrics for both groups during each observed week. The results showed changes in the behavior and activity of users and their accounts, as well as variations in the daily volume of transactions. ","comment":"13 pages, 5 figures","authors":"Pedro Henrique F. S. Oliveira, Daniel Muller Rezende, Heder Soares Bernardino, Saulo Moraes Villela, Alex Borges Vieira","pdf":"http://arxiv.org/pdf/2206.11846v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.11850v1","published":"Fri, 17 Jun 2022 11:55:05 GMT","title":"Neural network based human reliability analysis method in production   systems","summary":"  Purpose: In addition to playing an important role in creating economic security and investment development, insurance companies also invest. The country's insurance industry as one of the country's financial institutions has a special place in the investment process and special attention to appropriate investment policies in the field of insurance industry is essential. So that the efficiency of this industry in allocating the existing budget stimulates other economic sectors. This study seeks to model investment in the performance of dynamic networks of insurance companies.   Methodology: In this paper, a new investment model is designed to examine the dynamic network performance of insurance companies in Iran. The designed model is implemented using GAMS software and the outputs of the model are analyzed based on regression method. The required information has been collected based on the statistics of insurance companies in Iran between 1393 and 1398.   Findings: After evaluating these units, out of 15 companies evaluated, 6 companies had unit performance and were introduced as efficient companies. The average efficiency of insurance companies is 0.78 and the standard deviation is 0.2. The results show that the increase in the value of investments is due to the large reduction in costs and in terms of capital and net profit of companies is a large number that has a clear and strong potential for insurance companies.   Originality/Value: In this paper, investment modeling is performed to examine the performance of dynamic networks of insurance companies in Iran. ","comment":"Journal of Applied Research on Industrial Engineering, 2021","authors":"Rasoul Jamshidi, Mohammad Ebrahim Sadeghi","pdf":"http://arxiv.org/pdf/2206.11850v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.03874v1","published":"Wed, 08 Jun 2022 13:09:25 GMT","title":"Rapid X-ray Variability in Mkn 421 during a Multiwavelength Campaign","summary":"  The study of short-term variability properties in AGN jets has the potential to shed light on their particle acceleration and emission mechanisms. We report results from a four-day coordinated multi-wavelength campaign on the highly-peaked blazar (HBL) Mkn 421 in 2019 January. We obtained X-ray data from AstroSAT, BVRI photometry with the Whole Earth Blazar Telescope (WEBT), and TeV data from FACT to explore short-term multi-wavelength variability in this HBL. The X-ray continuum is rapidly variable on time-scales of tens of ks. Fractional variability amplitude increases with energy across the synchrotron hump, consistent with previous studies; we interpret this observation in the context of a model with multiple cells whose emission spectra contain cutoffs that follow a power-law distribution. We also performed time-averaged and time-resolved (time-scales of 6 ks) spectral fits; a broken power-law model fits all spectra well; time-resolved spectral fitting reveals the usual hardening when brightening behaviour. Intra-X-ray cross correlations yield evidence for the 0.6-0.8 keV band to likely lead the other bands by an average of 4.6 +- 2.6 ks, but only during the first half of the observation. The source displayed minimal night-to-night variability at all wavebands thus precluding significant interband correlations during our campaign. The broadband SED is modeled well with a standard one-zone leptonic model, yielding jet parameters consistent with those obtained from previous SEDs of this source. ","comment":"This article has been accepted for publication in The Monthly Notices   of the Royal Astronomical Society (2022), and is published in Volume 513,   Issue 2, pp.1662-1679. Published by Oxford University Press on behalf of the   Royal Astronomical Society. All rights reserved. 19 pages; 12 figures","authors":"Alex G. Markowitz, Krzysztof Nalewajko, Gopal Bhatta, Gulab C. Dewangan, Sunil Chandra, Daniela Dorner, Bernd Schleicher, Urszula Pajdosz-Smierciak, Lukasz Stawarz, Staszek Zola, Michal Ostrowski, Daniele Carosati, Saikruba Krishnan, Rumen Bachev, Erika Benitez, Kosmas Gazeas, David Hiriart, Shao-Ming Hu, Valeri Larionov, Alessandro Marchini, Katsura Matsumoto, A. A. Nikiforova, Tapio Pursimo, Claudia M. Raiteri, Daniel E. Reichart, Diego Rodriguez, Evgeni Semkov, Anton Strigachev, Yuki Sugiura, Massimo Villata, James R. Webb, Axel Arbet-Engels, Dominik Baack, Matteo Balbo, Adrian Biland, Thomas Bretz, Jens Buss, Laura Eisenberger, Dominik Elsaesser, Dorothee Hildebrand, Roman Iotov, Adelina Kalenski, Karl Mannheim, Alison Mitchell, Dominik Neise, Maximilian Noethe, Aleksander Paravac, Wolfgang Rhode, Vitalii Sliusar, Roland Walter","pdf":"http://arxiv.org/pdf/2206.03874v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.06010v2","published":"Mon, 13 Jun 2022 09:57:16 GMT","title":"Constant-Round Linear-Broadcast Secure Computation with Penalties","summary":"  It is known that Bitcoin enables achieving fairness in secure computation by imposing monetary penalties on adversarial parties. This functionality is called secure computation with penalties. Bentov and Kumaresan (Crypto 2014) introduced the claim-or-refund functionality that can be implemented via Bitcoin. They achieved secure computation with penalties with $O(n)$ rounds and $O(n)$ broadcasts for any function, where $n$ is the number of parties. After that, Kumaresan and Bentov (CCS 2014) showed a constant-round protocol. Unfortunately, this protocol requires $O(n^2)$ broadcasts. As far as we know, no protocol achieves $O(1)$ rounds and $O(n)$ broadcasts based on Bitcoin. This work accomplishes such efficiency in secure computation with penalties. We first show a protocol in a slightly relaxed setting called secure computation with non-equivalent penalties. This setting is the same as secure computation with penalties except that every honest party receives more than a predetermined amount of compensation, while the previous one requires that every honest party receives the same amount of compensation. Namely, our setting allows the compensations for honest parties to be non-equivalent. Moreover, we present a technique to remove the non-equivalence of our protocol without sacrificing efficiency. We then propose a new ideal functionality called claim-refund-or-give that can be implemented via Bitcoin. ","comment":"32 pages","authors":"Takeshi Nakai, Kazumasa Shinagawa","pdf":"http://arxiv.org/pdf/2206.06010v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.11973v1","published":"Thu, 23 Jun 2022 20:54:15 GMT","title":"Liquidity Risks in Lending Protocols (LPs): Evidence from Aave Protocol","summary":"  Decentralized Finance (DeFi) can replicate most traditional financial activities. Among various DeFi, Lending Protocols (LPs) resemble banks, allowing users to borrow and lend cryptocurrencies. By analysing stablecoin loans in Aave protocol, we find a small group of users with dual roles, i.e., borrowers and depositors, and these users account for significant loans and deposits. Therefore, potential liquidity risks can occur if these users collectively withdraw deposits and initiate loans, and potential liquidity risks can affect both loan-specific factors and status of Aave protocol. Surprisingly, liquidity risks in Aave are related to other LPs, implying illiquidity is infectious in DeFi. ","authors":"Xiaotong Sun","pdf":"http://arxiv.org/pdf/2206.11973v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12282v1","published":"Sat, 18 Jun 2022 11:33:55 GMT","title":"A comparative study of the MACD-base trading strategies: evidence from   the US stock market","summary":"  In recent years, more and more investors use technical analysis methods in their own trading. Evaluating the effectiveness of technical analysis has become more feasible due to increasing computing capability and blooming public data, which indie investors can perform stock analysis and backtest their own trading strategy conveniently. The Moving Average Convergence Divergence (MACD) indicator is one of the popular technical indicators that are widely used in different strategies. In order to verify the MACD effectiveness, in this thesis, I use the MACD indicator with traditional parameters (12, 26, 9) to build various trading strategies. Then, I apply these strategies to stocks listed on three indices in the US stock market (i.e., Dow-Jones, Nasdaq, and S&P 500) and evaluate its performance in terms of win rate, profitability, Sharpe ratio, number of trades and maximum drawdown. The backtesting is programmed using Python, covering the period between 01/01/2015 and 28-08-2021. The result shows that the win-rate of the strategy with only the MACD indicator is less than 50%. However, the win-rate is improved for the trading strategies that combine the MACD indicator with other momentum indicators like the Money Flow Index (MFI) and the Relative Strength Index (RSI). Based on this result, I redesign the MACD mathematical formula by taking the trading volume and daily price volatility into consideration to derive a new indicator called VPVMA. The results show that the win-rate and risk-adjust performance of this new trading strategy have been improved significantly. In general, the findings suggest that while all the MACD trading strategies mentioned above can generate positive returns, the performance is not good without using other momentum indicators. Hence, the VPVMA indicator performs better. ","authors":"Pat Tong Chio","pdf":"http://arxiv.org/pdf/2206.12282v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12262v1","published":"Fri, 10 Jun 2022 04:24:48 GMT","title":"Emoji-based Fine-grained Attention Network for Sentiment Analysis in the   Microblog Comments","summary":"  Microblogs have become a social platform for people to express their emotions in real-time, and it is a trend to analyze user emotional tendencies from the information on Microblogs. The dynamic features of emojis can affect the sentiment polarity of microblog texts. Since existing models seldom consider the diversity of emoji sentiment polarity,the paper propose a microblog sentiment classification model based on ALBERT-FAET. We obtain text embedding via ALBERT pretraining model and learn the inter-emoji embedding with an attention-based LSTM network. In addition, a fine-grained attention mechanism is proposed to capture the word-level interactions between plain text and emoji. Finally, we concatenate these features and feed them into a CNN classifier to predict the sentiment labels of the microblogs. To verify the effectiveness of the model and the fine-grained attention network, we conduct comparison experiments and ablation experiments. The comparison experiments show that the model outperforms previous methods in three evaluation indicators (accuracy, precision, and recall) and the model can significantly improve sentiment classification. The ablation experiments show that compared with ALBERT-AET, the proposed model ALBERT-FAET is better in the metrics, indicating that the fine-grained attention network can understand the diversified information of emoticons. ","authors":"Deng Yang, Liu Kejian, Yang Cheng, Feng Yuanyuan, Li Weihao","pdf":"http://arxiv.org/pdf/2206.12262v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.13489v1","published":"Mon, 27 Jun 2022 17:52:16 GMT","title":"Supply-Side Equilibria in Recommender Systems","summary":"  Digital recommender systems such as Spotify and Netflix affect not only consumer behavior but also producer incentives: producers seek to supply content that will be recommended by the system. But what content will be produced? In this paper, we investigate the supply-side equilibria in content recommender systems. We model users and content as $D$-dimensional vectors, and recommend the content that has the highest dot product with each user. The main features of our model are that the producer decision space is high-dimensional and the user base is heterogeneous. This gives rise to new qualitative phenomena at equilibrium: First, the formation of genres, where producers specialize to compete for subsets of users. Using a duality argument, we derive necessary and sufficient conditions for this specialization to occur. Second, we show that producers can achieve positive profit at equilibrium, which is typically impossible under perfect competition. We derive sufficient conditions for this to occur, and show it is closely connected to specialization of content. In both results, the interplay between the geometry of the users and the structure of producer costs influences the structure of the supply-side equilibria. At a conceptual level, our work serves as a starting point to investigate how recommender systems shape supply-side competition between producers. ","authors":"Meena Jagadeesan, Nikhil Garg, Jacob Steinhardt","pdf":"http://arxiv.org/pdf/2206.13489v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.13267v1","published":"Mon, 27 Jun 2022 12:57:42 GMT","title":"A Stochastic Target Problem for Branching Diffusions","summary":"  We consider an optimal stochastic target problem for branching diffusion processes. This problem consists in finding the minimal condition for which a control allows the underlying branching process to reach a target set at a finite terminal time for each of its branches. This problem is motivated by an example from fintech where we look for the super-replication price of options on blockchain based cryptocurrencies. We first state a dynamic programming principle for the value function of the stochastic target problem. We then show that the value function can be reduced to a new function with a finite dimensional argument by a so called branching property. Under wide conditions, this last function is shown to be the unique viscosity solution to an HJB variational inequality. ","authors":"Idris Kharroubi, LPSM, Antonio Ocello, LPSM","pdf":"http://arxiv.org/pdf/2206.13267v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.13104v1","published":"Mon, 27 Jun 2022 08:19:29 GMT","title":"Towards Secrecy-Aware Attacks Against Trust Prediction in Signed Graphs","summary":"  Signed graphs are widely used to model the trust relationships among users in security-sensitive systems such as cryptocurrency trading platforms, where trust prediction plays a critical role. In this paper, we investigate how attackers could mislead trust prediction via manipulating signed graphs while remaining secret. To this end, we first design effective poisoning attacks against representative trust prediction tools. The attacks are formulated as hard bi-level optimization problems, for which we propose several efficient approximation solutions. The resulting basic attacks would severely change the structural semantics (in particular, both local and global balance properties) of a signed graph, which makes the attacks prone to be detected by the powerful attack detectors we designed. To address this issue, we further refine the basic attacks by integrating some conflicting metrics as penalty terms into the objective function. The refined attacks become secrecy-aware: they can successfully evade attack detectors with high probability while sacrificing little attack performance. We conduct comprehensive experiments to demonstrate that the basic attacks can severely disrupt trust prediction, the basic attacks could be easily detected, and the refined attacks can preserve attack performance while evading detection. Overall, our results significantly advance the knowledge in designing more practical attacks, reflecting more realistic threats to current trust prediction systems. ","authors":"Yulin Zhu, Tomasz Michalak, Xiapu Luo, Kai Zhou","pdf":"http://arxiv.org/pdf/2206.13104v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12970v1","published":"Sun, 26 Jun 2022 20:49:33 GMT","title":"Cost-Asymmetric Memory Hard Password Hashing","summary":"  In the past decade, billions of user passwords have been exposed to the dangerous threat of offline password cracking attacks. An offline attacker who has stolen the cryptographic hash of a user's password can check as many password guesses as s/he likes limited only by the resources that s/he is willing to invest to crack the password. Pepper and key-stretching are two techniques that have been proposed to deter an offline attacker by increasing guessing costs. Pepper ensures that the cost of rejecting an incorrect password guess is higher than the (expected) cost of verifying a correct password guess. This is useful because most of the offline attacker's guesses will be incorrect. Unfortunately, as we observe the traditional peppering defense seems to be incompatible with modern memory hard key-stretching algorithms such as Argon2 or Scrypt. We introduce an alternative to pepper which we call Cost-Asymmetric Memory Hard Password Authentication which benefits from the same cost-asymmetry as the classical peppering defense i.e., the cost of rejecting an incorrect password guess is larger than the expected cost to authenticate a correct password guess. When configured properly we prove that our mechanism can only reduce the percentage of user passwords that are cracked by a rational offline attacker whose goal is to maximize (expected) profit i.e., the total value of cracked passwords minus the total guessing costs. We evaluate the effectiveness of our mechanism on empirical password datasets against a rational offline attacker. Our empirical analysis shows that our mechanism can reduce significantly the percentage of user passwords that are cracked by a rational attacker by up to 10%. ","authors":"Wenjie Bai, Jeremiah Blocki, Mohammad Hassan Ameri","pdf":"http://arxiv.org/pdf/2206.12970v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12922v1","published":"Sun, 26 Jun 2022 16:42:02 GMT","title":"Visualizing Non-Fungible Token Ethics: A Case Study On CryptoPunks","summary":"  As a blockchain-based application, Non-Fungible Token (NFT) has received worldwide attention over the past few years. Digital artwork is the main form of NFT that can be stored on different blockchains. Although the NFT market is rapidly developing, we observed potential ethical and racial fairness issues in the design of NFT artworks due to a lack of ethical guidelines or censorship. Therefore, we investigated CryptoPunks, the most famous collection in the NFT market, to explore and visualize its potential ethical issues. We explored the ethical issues from three aspects: design, trading transactions, and related topics on Twitter. We scraped data from Twitter and Dune Analytics using python libraries, Twitter crawler, and sentiment analysis tools. Our five visualizations implied that 1.6 times more male punks were created in the initial design process than the female ones. And the male ones have a higher average selling price than females; lighter-skinned punks tend to sell for higher prices. The results of our study and visualizations provide a preliminary exploration of CryptoPunks and further inspire future ethical-related investigation and research in the NFT domain. ","authors":"Yufan Zhang, Zichao Chen, Luyao Zhang, Xin Tong","pdf":"http://arxiv.org/pdf/2206.12922v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12852v1","published":"Sun, 26 Jun 2022 11:44:17 GMT","title":"Spectrum Sharing Among Multiple-Seller and Multiple-Buyer Operators of A   Mobile Network: A Stochastic Geometry Approach","summary":"  Sharing the spectrum among mobile network operators (MNOs) is a promising approach to improve the spectrum utilization and to increase the monetary income of MNOs. In this paper, we model a nonorthogonal spectrum sharing system for a large-scale cellular network where multiple seller MNOs lease their licensed sub-bands to several buyer MNOs. We first analyze the per-user expected rate and the per-MNO expected profit using stochastic geometry. Then, we formulate the joint problem of power control and licensed sub-band sharing to maximize the expected profit of all MNOs as a multiobjective optimization problem (MOOP) under the users' quality of service requirement and the nonnegative return on investment constraints. To transform the MOOP into a single objective form, we use a combination of the $\\\\epsilon$-constraint and weighted sum methods. However, the transformed problem is nonconvex because of the presence of binary variables and nonconvex rate functions in the objective function and constraints. We address this problem by using a penalty function and approximating the nonconvex rate functions by a constrained stochastic successive convex approximation method. Finally, the numerical results show the correctness and performance of the proposed algorithm under various conditions. ","comment":"17 pages, 11 figures","authors":"Elaheh Ataeebojd, Mehdi Rasti, Hossein Pedram, Pedro H. J. Nardelli","pdf":"http://arxiv.org/pdf/2206.12852v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12766v1","published":"Sun, 26 Jun 2022 02:20:38 GMT","title":"Towards Blockchain-Based Secure Data Management for Remote Patient   Monitoring","summary":"  Traditional data collection, storage and processing of Electronic Health Records (EHR) utilize centralized techniques that pose several risks of single point of failure and lean the systems to a number of internal and external data breaches that compromise their reliability and availability. Blockchain is an emerging distributed technology that can solve these issues due to its immutability and architectural nature that prevent records manipulation or alterations. In this paper, we discuss the progress and opportunities of remote patient monitoring using futuristic blockchain technologies and its two primary frameworks: Ethereum and Hyperledger Fabric. We also discuss the possible blockchain use cases in software engineering for systematic, disciplined, and quantifiable application development. The study extends by introducing a system architecture for EHR data management using Ethereum as a model. We discuss the challenges and limitations along with the initial evaluation results of the proposed system and draw future research directions in this promising area. ","authors":"Md Jobair Hossain Faruk, Hossain Shahriar, Maria Valero, Sweta Sneha, Sheikh I. Ahamed Mohammad Rahman","pdf":"http://arxiv.org/pdf/2206.12766v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12714v1","published":"Sat, 25 Jun 2022 18:57:02 GMT","title":"Defending Multimodal Fusion Models against Single-Source Adversaries","summary":"  Beyond achieving high performance across many vision tasks, multimodal models are expected to be robust to single-source faults due to the availability of redundant information between modalities. In this paper, we investigate the robustness of multimodal neural networks against worst-case (i.e., adversarial) perturbations on a single modality. We first show that standard multimodal fusion models are vulnerable to single-source adversaries: an attack on any single modality can overcome the correct information from multiple unperturbed modalities and cause the model to fail. This surprising vulnerability holds across diverse multimodal tasks and necessitates a solution. Motivated by this finding, we propose an adversarially robust fusion strategy that trains the model to compare information coming from all the input sources, detect inconsistencies in the perturbed modality compared to the other modalities, and only allow information from the unperturbed modalities to pass through. Our approach significantly improves on state-of-the-art methods in single-source robustness, achieving gains of 7.8-25.2% on action recognition, 19.7-48.2% on object detection, and 1.6-6.7% on sentiment analysis, without degrading performance on unperturbed (i.e., clean) data. ","comment":"CVPR 2021","authors":"Karren Yang, Wan-Yi Lin, Manash Barman, Filipe Condessa, Zico Kolter","pdf":"http://arxiv.org/pdf/2206.12714v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12649v1","published":"Sat, 25 Jun 2022 13:25:39 GMT","title":"Sentiment Analysis with R: Natural Language Processing for   Semi-Automated Assessments of Qualitative Data","summary":"  Sentiment analysis is a sub-discipline in the field of natural language processing and computational linguistics and can be used for automated or semi-automated analyses of text documents. One of the aims of these analyses is to recognize an expressed attitude as positive or negative as it can be contained in comments on social media platforms or political documents and speeches as well as fictional and nonfictional texts. Regarding analyses of comments on social media platforms, this is an extension of the previous tutorial on semi-automated screenings of social media network data. A longitudinal perspective regarding social media comments as well as cross-sectional perspectives regarding fictional and nonfictional texts, e.g. entire books and libraries, can lead to extensive text documents. Their analyses can be simplified and accelerated by using sentiment analysis with acceptable inter-rater reliability. Therefore, this tutorial introduces the basic functions for performing a sentiment analysis with R and explains how text documents can be analysed step by step - regardless of their underlying formatting. All prerequisites and steps are described in detail and associated codes are available on GitHub. A comparison of two political speeches illustrates a possible use case. ","comment":"14 pages, 6 figures","authors":"Dennis Klinkhammer","pdf":"http://arxiv.org/pdf/2206.12649v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.12408v1","published":"Wed, 22 Jun 2022 17:19:59 GMT","title":"Convexity and Duality in Optimum Real-time Bidding and Related Problems","summary":"  We study problems arising in real-time auction markets, common in e-commerce and computational advertising, where bidders face the problem of calculating optimal bids. We focus upon a contract management problem where a demand aggregator is subject to multiple contractual obligations requiring them to acquire items of heterogeneous types at a specified rate, which they will seek to fulfill at minimum cost. Our main results show that, through a transformation of variables, this problem can be formulated as a convex optimization problem, for both first and second price auctions. Convexity results in efficient algorithms for solving instances of this problem, and the resulting duality theory admits rich structure and interpretations. Additionally, we show that the transformation of variables used to formulate this problem as a convex program can also be used to guarantee the convexity of optimal bidding problems studied by other authors (who did not leverage convexity). Finally, we show how the expected cost of bidding in second price auctions is formally identical to certain transaction costs when submitting market orders in limit order book markets. This fact is used to analyze a Markowitz portfolio problem which accounts for these transaction costs, establishing an interesting connection between finance and optimal bidding. ","authors":"Ryan J. Kinnear, Ravi R. Mazumdar, Peter Marbach","pdf":"http://arxiv.org/pdf/2206.12408v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.14168v1","published":"Tue, 28 Jun 2022 17:32:18 GMT","title":"Comparison of metadata with relevance for bibliometrics between   Microsoft Academic Graph and OpenAlex until 2020","summary":"  Microsoft Academic Graph (MAG) has been studied a lot concerning its suitability for bibliometric evaluations. In May 2021, it was announced that it would retire on December 31, 2021. Soon after that, the non-profit organization OurResearch, aiming at providing 'a fully open catalog of the global research system', announced they would preserve and incorporate the last full MAG corpus, only excluding patent data, and to continue and hopefully improve it. After the launch of OpenAlex in January 2022, it is of interest to know if the usefulness of the MAG data is preserved or even improved in OpenAlex. To this end, we compared metadata that are relevant for bibliometric analyses (in particular field and time normalization of citations) of MAG and OpenAlex: - the coverage of documents over the years, - the agreement of bibliographic data, - the numbers of references of each document, - the kind and distribution of document types, - the distribution and relation of subject classifications. ","comment":"11 pages, 3 figures, 6 tables; submitted to the 26th International   Conference on Science, Technology and Innovation Indicators (STI 2022)","authors":"Thomas Scheidsteger, Robin Haunschild","pdf":"http://arxiv.org/pdf/2206.14168v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.14107v1","published":"Tue, 28 Jun 2022 16:07:32 GMT","title":"Special subsets of addresses for blockchains using the secp256k1 curve","summary":"  In 2020 Sala, Sogiorno and Taufer have been able to find the private keys of some Bitcoin addresses, thus being able to spend the cryptocurrency linked to them. This result was unexpected, since the recovery of non-trivial private keys for blockchain addresses is deemed to be an infeasible problem. In this paper we widen this analysis by mounting a similar attack to other small subsets of the set of private keys. We then apply it to other blockchains as well, examining Ethereum, Dogecoin, Litecoin, Dash, Zcash and Bitcoin Cash. In addition to the results, we also explain the techniques we have used to perform this exhaustive search for all the addresses that have ever appeared in these blockchains. ","comment":"13 pages","authors":"Antonio J. Di Scala, Andrea Gangemi, Giuliano Romeo, Gabriele Vernetti","pdf":"http://arxiv.org/pdf/2206.14107v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.13969v1","published":"Tue, 28 Jun 2022 12:49:16 GMT","title":"MACSA: A Multimodal Aspect-Category Sentiment Analysis Dataset with   Multimodal Fine-grained Aligned Annotations","summary":"  Multimodal fine-grained sentiment analysis has recently attracted increasing attention due to its broad applications. However, the existing multimodal fine-grained sentiment datasets most focus on annotating the fine-grained elements in text but ignore those in images, which leads to the fine-grained elements in visual content not receiving the full attention they deserve. In this paper, we propose a new dataset, the Multimodal Aspect-Category Sentiment Analysis (MACSA) dataset, which contains more than 21K text-image pairs. The dataset provides fine-grained annotations for both textual and visual content and firstly uses the aspect category as the pivot to align the fine-grained elements between the two modalities. Based on our dataset, we propose the Multimodal ACSA task and a multimodal graph-based aligned model (MGAM), which adopts a fine-grained cross-modal fusion method. Experimental results show that our method can facilitate the baseline comparison for future research on this corpus. We will make the dataset and code publicly available. ","authors":"Hao Yang, Yanyan Zhao, Jianwei Liu, Yang Wu, Bing Qin","pdf":"http://arxiv.org/pdf/2206.13969v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.13895v1","published":"Tue, 28 Jun 2022 11:24:02 GMT","title":"Increasing countries financial resilience through global catastrophe   risk pooling","summary":"  Extreme weather events can have severe impacts on national economies, leading the recovery of low- to middle-income countries to become reliant on foreign financial aid. Foreign aid, however, is slow and uncertain. Therefore, the Sendai Framework and the Paris Agreement advocate for more resilient financial instruments like sovereign catastrophe risk pools. Existing pools, however, might not fully exploit financial resilience potentials because they were not designed with the goal of maximizing risk diversification and they pool risk only regionally. To address this, we introduce a method that forms pools maximizing risk diversification and which selects countries with low bilateral correlations or low shares in the pool risk. We apply the method to explore the benefits of global pooling with respect to regional pooling. We find that global pooling increases risk diversification, it lowers countries shares in the pool risk and it increases the number of countries profiting from risk pooling. ","authors":"Alessio Ciullo, Eric Strobl, Simona Meiler, Olivia Martius, David N. Bresch","pdf":"http://arxiv.org/pdf/2206.13895v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.13939v1","published":"Sat, 25 Jun 2022 06:12:17 GMT","title":"Functional Optimization Reinforcement Learning for Real-Time Bidding","summary":"  Real-time bidding is the new paradigm of programmatic advertising. An advertiser wants to make the intelligent choice of utilizing a \\\\textbf{Demand-Side Platform} to improve the performance of their ad campaigns. Existing approaches are struggling to provide a satisfactory solution for bidding optimization due to stochastic bidding behavior. In this paper, we proposed a multi-agent reinforcement learning architecture for RTB with functional optimization. We designed four agents bidding environment: three Lagrange-multiplier based functional optimization agents and one baseline agent (without any attribute of functional optimization) First, numerous attributes have been assigned to each agent, including biased or unbiased win probability, Lagrange multiplier, and click-through rate. In order to evaluate the proposed RTB strategy's performance, we demonstrate the results on ten sequential simulated auction campaigns. The results show that agents with functional actions and rewards had the most significant average winning rate and winning surplus, given biased and unbiased winning information respectively. The experimental evaluations show that our approach significantly improve the campaign's efficacy and profitability. ","authors":"Yining Lu, Changjie Lu, Naina Bandyopadhyay, Manoj Kumar, Gaurav Gupta","pdf":"http://arxiv.org/pdf/2206.13939v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.13980v1","published":"Tue, 14 Jun 2022 02:37:44 GMT","title":"Label-enhanced Prototypical Network with Contrastive Learning for   Multi-label Few-shot Aspect Category Detection","summary":"  Multi-label aspect category detection allows a given review sentence to contain multiple aspect categories, which is shown to be more practical in sentiment analysis and attracting increasing attention. As annotating large amounts of data is time-consuming and labor-intensive, data scarcity occurs frequently in real-world scenarios, which motivates multi-label few-shot aspect category detection. However, research on this problem is still in infancy and few methods are available. In this paper, we propose a novel label-enhanced prototypical network (LPN) for multi-label few-shot aspect category detection. The highlights of LPN can be summarized as follows. First, it leverages label description as auxiliary knowledge to learn more discriminative prototypes, which can retain aspect-relevant information while eliminating the harmful effect caused by irrelevant aspects. Second, it integrates with contrastive learning, which encourages that the sentences with the same aspect label are pulled together in embedding space while simultaneously pushing apart the sentences with different aspect labels. In addition, it introduces an adaptive multi-label inference module to predict the aspect count in the sentence, which is simple yet effective. Extensive experimental results on three datasets demonstrate that our proposed model LPN can consistently achieve state-of-the-art performance. ","comment":"Accepted to KDD 2022","authors":"Han Liu, Feng Zhang, Xiaotong Zhang, Siyang Zhao, Junjie Sun, Hong Yu, Xianchao Zhang","pdf":"http://arxiv.org/pdf/2206.13980v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.14782v1","published":"Wed, 29 Jun 2022 17:29:48 GMT","title":"Implementation of Ethereum Accounts and Transactions on Embedded IoT   Devices","summary":"  The growing interest in Internet of Things (IoT) and Industrial IoT (IIoT) poses the challenge of finding robust solutions for the certification and notarization of data produced and collected by embedded devices. The blockchain and distributed ledger technologies represent a promising solution to address these issues, but rise other questions, for example regarding their practical feasibility. In fact, IoT devices have limited resources and, consequently, may not be able to easily perform all the operations required to participate in a blockchain. In this paper we propose a minimal architecture to allow IoT devices performing data certification and notarization on the Ethereum blockchain. We develop a hardware-software platform through which a lightweight device (e.g., an IoT sensor), holding a secret key and the associated public address, produces signed transactions, which are then submitted to the blockchain network. This guarantees data integrity and authenticity and, on the other hand, minimizes the computational burden on the lightweight device. To show the practicality of the proposed approach, we report and discuss the results of benchmarks performed on ARM Cortex-M4 hardware architectures, sending transactions over the Ropsten testnet. Our results show that all the necessary operations can be performed with small latency, thus proving that an IoT device can directly interact with the blockchain, without apparent bottlenecks. ","authors":"Giulia Rafaiani, Paolo Santini, Marco Baldi, Franco Chiaraluce","pdf":"http://arxiv.org/pdf/2206.14782v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.14774v1","published":"Wed, 29 Jun 2022 17:16:58 GMT","title":"TweetNLP: Cutting-Edge Natural Language Processing for Social Media","summary":"  In this paper we present TweetNLP, an integrated platform for Natural Language Processing (NLP) in social media. TweetNLP supports a diverse set of NLP tasks, including generic focus areas such as sentiment analysis and named entity recognition, as well as social media-specific tasks such as emoji prediction and offensive language identification. Task-specific systems are powered by reasonably-sized Transformer-based language models specialized on social media text (in particular, Twitter) which can be run without the need for dedicated hardware or cloud services. The main contributions of TweetNLP are: (1) an integrated Python library for a modern toolkit supporting social media analysis using our various task-specific models adapted to the social domain; (2) an interactive online demo for codeless experimentation using our models; and (3) a tutorial covering a wide variety of typical social media applications. ","comment":"Demo paper. TweetNLP: https://tweetnlp.org/","authors":"Jose Camacho-Collados, Kiamehr Rezaee, Talayeh Riahi, Asahi Ushio, Daniel Loureiro, Dimosthenis Antypas, Joanne Boisson, Luis Espinosa-Anke, Fangyu Liu, Eugenio Martínez-Cámara, Gonzalo Medina, Thomas Buhrmann, Leonardo Neves, Francesco Barbieri","pdf":"http://arxiv.org/pdf/2206.14774v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.14760v1","published":"Wed, 29 Jun 2022 16:45:37 GMT","title":"A hybrid level-based learning swarm algorithm with mutation operator for   solving large-scale cardinality-constrained portfolio optimization problems","summary":"  In this work, we propose a hybrid variant of the level-based learning swarm optimizer (LLSO) for solving large-scale portfolio optimization problems. Our goal is to maximize a modified formulation of the Sharpe ratio subject to cardinality, box and budget constraints. The algorithm involves a projection operator to deal with these three constraints simultaneously and we implicitly control transaction costs thanks to a rebalancing constraint. We also introduce a suitable exact penalty function to manage the turnover constraint. In addition, we develop an ad hoc mutation operator to modify candidate exemplars in the highest level of the swarm. The experimental results, using three large-scale data sets, show that the inclusion of this procedure improves the accuracy of the solutions. Then, a comparison with other variants of the LLSO algorithm and two state-of-the-art swarm optimizers points out the outstanding performance of the proposed solver in terms of exploration capabilities and solution quality. Finally, we assess the profitability of the portfolio allocation strategy in the last five years using an investible pool of 1119 constituents from the MSCI World Index. ","comment":"Submitted","authors":"Massimiliano Kaucic, Filippo Piccotto, Gabriele Sbaiz, Giorgio Valentinuz","pdf":"http://arxiv.org/pdf/2206.14760v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.14643v1","published":"Wed, 29 Jun 2022 13:37:03 GMT","title":"Simple and Effective Multi-sentence TTS with Expressive and Coherent   Prosody","summary":"  Generating expressive and contextually appropriate prosody remains a challenge for modern text-to-speech (TTS) systems. This is particularly evident for long, multi-sentence inputs. In this paper, we examine simple extensions to a Transformer-based FastSpeech-like system, with the goal of improving prosody for multi-sentence TTS. We find that long context, powerful text features, and training on multi-speaker data all improve prosody. More interestingly, they result in synergies. Long context disambiguates prosody, improves coherence, and plays to the strengths of Transformers. Fine-tuning word-level features from a powerful language model, such as BERT, appears to profit from more training data, readily available in a multi-speaker setting. We look into objective metrics on pausing and pacing and perform thorough subjective evaluations for speech naturalness. Our main system, which incorporates all the extensions, achieves consistently strong results, including statistically significant improvements in speech naturalness over all its competitors. ","comment":"Accepted to be published in the Proceedings of InterSpeech 2022","authors":"Peter Makarov, Ammar Abbas, Mateusz Łajszczak, Arnaud Joly, Sri Karlapati, Alexis Moinet, Thomas Drugman, Penny Karanasou","pdf":"http://arxiv.org/pdf/2206.14643v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.14607v1","published":"Tue, 28 Jun 2022 03:22:55 GMT","title":"NERDA-Con: Extending NER models for Continual Learning -- Integrating   Distinct Tasks and Updating Distribution Shifts","summary":"  With increasing applications in areas such as biomedical information extraction pipelines and social media analytics, Named Entity Recognition (NER) has become an indispensable tool for knowledge extraction. However, with the gradual shift in language structure and vocabulary, NERs are plagued with distribution shifts, making them redundant or not as profitable without re-training. Re-training NERs based on Large Language Models (LLMs) from scratch over newly acquired data poses economic disadvantages. In contrast, re-training only with newly acquired data will result in Catastrophic Forgetting of previously acquired knowledge. Therefore, we propose NERDA-Con, a pipeline for training NERs with LLM bases by incorporating the concept of Elastic Weight Consolidation (EWC) into the NER fine-tuning NERDA pipeline. As we believe our work has implications to be utilized in the pipeline of continual learning and NER, we open-source our code as well as provide the fine-tuning library of the same name NERDA-Con at https://github.com/SupritiVijay/NERDA-Con and https://pypi.org/project/NERDA-Con/. ","comment":"6 pages, 4 figures, Accepted at Workshop on Updatable Machine   Learning(UpML), International Conference on Machine Learning (ICML'22)","authors":"Supriti Vijay, Aman Priyanshu","pdf":"http://arxiv.org/pdf/2206.14607v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.15228v1","published":"Thu, 30 Jun 2022 12:19:41 GMT","title":"Signed ego network model and its application to Twitter","summary":"  The Ego Network Model (ENM) describes how individuals organise their social relations in concentric circles (typically five) of decreasing intimacy, and it has been found almost ubiquitously in social networks, both offline and online. The ENM gauges the tie strength between peers in terms of interaction frequency, which is easy to measure and provides a good proxy for the time spent nurturing the relationship. However, advances in signed network analysis have shown that positive and negative relations play very different roles in network dynamics. For this reason, this work sets out to investigate the ENM when including signed relations. The main contributions of this paper are twofold: firstly, a novel method of signing relationships between individuals using sentiment analysis and, secondly, an investigation of the properties of Signed Ego Networks (Ego Networks with signed connections). Signed Ego Networks are then extracted for the users of eight different Twitter datasets composed of both specialised users (e.g. journalists) and generic users. We find that negative links are over-represented in the active part of the Ego Networks of all types of users, suggesting that Twitter users tend to engage regularly with negative connections. Further, we observe that negative relationships are overwhelmingly predominant in the Ego Network circles of specialised users, hinting at very polarised online interactions for this category of users. In addition, negative relationships are found disproportionately more at the more intimate levels of the ENM for journalists, while their percentages are stable across the circles of the other Twitter users ","authors":"Jack Tacchi, Chiara Boldrini, Andrea Passarella, Marco Conti","pdf":"http://arxiv.org/pdf/2206.15228v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.15139v1","published":"Thu, 30 Jun 2022 09:14:24 GMT","title":"Pump Up Password Security! Evaluating and Enhancing Risk-Based   Authentication on a Real-World Large-Scale Online Service","summary":"  Risk-based authentication (RBA) aims to protect users against attacks involving stolen passwords. RBA monitors features during login, and requests re-authentication when feature values widely differ from previously observed ones. It is recommended by various national security organizations, and users perceive it more usable and equally secure than equivalent two-factor authentication. Despite that, RBA is still only used by very few online services. Reasons for this include a lack of validated open resources on RBA properties, implementation, and configuration. This effectively hinders the RBA research, development, and adoption progress.   To close this gap, we provide the first long-term RBA analysis on a real-world large-scale online service. We collected feature data of 3.3 million users and 31.3 million login attempts over more than one year. Based on the data, we provide (i) studies on RBA's real-world characteristics, and its configurations and enhancements to balance usability, security, and privacy, (ii) a machine learning based RBA parameter optimization method to support administrators finding an optimal configuration for their own use case scenario, (iii) an evaluation of the round-trip time feature's potential to replace the IP address for enhanced user privacy, and (iv) a synthesized RBA data set to reproduce this research and to foster future RBA research. Our results provide insights on selecting an optimized RBA configuration so that users profit from RBA after just a few logins. The open data set enables researchers to study, test, and improve RBA for widespread deployment in the wild. ","comment":"35 pages, 18 figures, 7 tables","authors":"Stephan Wiefling, Paul René Jørgensen, Sigurd Thunem, Luigi Lo Iacono","pdf":"http://arxiv.org/pdf/2206.15139v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.14932v1","published":"Wed, 29 Jun 2022 22:24:49 GMT","title":"A Data Science Pipeline for Algorithmic Trading: A Comparative Study of   Applications for Finance and Cryptoeconomics","summary":"  Recent advances in Artificial Intelligence (AI) have made algorithmic trading play a central role in finance. However, current research and applications are disconnected information islands. We propose a generally applicable pipeline for designing, programming, and evaluating the algorithmic trading of stock and crypto assets. Moreover, we demonstrate how our data science pipeline works with respect to four conventional algorithms: the moving average crossover, volume-weighted average price, sentiment analysis, and statistical arbitrage algorithms. Our study offers a systematic way to program, evaluate, and compare different trading strategies. Furthermore, we implement our algorithms through object-oriented programming in Python3, which serves as open-source software for future academic research and applications. ","comment":"Accepted at: The First International Symposium on Recent Advances of   Blockchain Evolution: Architecture, Intelligence, Incentive, and Applications","authors":"Luyao Zhang, Tianyu Wu, Saad Lahrichi, Carlos-Gustavo Salas-Flores, Jiayi Li","pdf":"http://arxiv.org/pdf/2206.14932v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00290v1","published":"Fri, 01 Jul 2022 09:35:47 GMT","title":"Competitive DER Aggregation for Participation in Wholesale Markets","summary":"  The problem of the large-scale aggregation of the behind-the-meter demand and generation resources by a distributed-energy-resource aggregator (DERA) is considered. As a profit-seeking wholesale market participant, a DERA maximizes its profit while providing competitive services to its customers with higher consumer/prosumer surpluses than those offered by the distribution utilities or community choice aggregators. A constrained profit maximization program for aggregating behind-the-meter generation and consumption resources is formulated, from which payment functions for the behind-the-meter consumptions and generations are derived. Also obtained are DERA's bid and offer curves for its participation in the wholesale energy market and the optimal schedule of behind-the-meter resources. It is shown that the proposed DERA's aggregation model can achieve market efficiency equivalent to that when its customers participate individually directly in the wholesale market. ","comment":"9 pages, 3 figures","authors":"Cong Chen, Ahmed S. Alahmed, Timothy D. Mount, Lang Tong","pdf":"http://arxiv.org/pdf/2207.00290v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00190v1","published":"Fri, 01 Jul 2022 03:39:24 GMT","title":"Range of Motion Sensors for Monitoring Recovery of Total Knee   Arthroplasty","summary":"  A low-cost, accurate device to measure and record knee range of motion (ROM) is of the essential need to improve confidence in at-home rehabilitation. It is to reduce hospital stay duration and overall medical cost after Total Knee Arthroplasty (TKA) procedures. The shift in Medicare funding from pay-as-you-go to the Bundled Payments for Care Improvement (BPCI) has created a push towards at-home care over extended hospital stays. It has heavily affected TKA patients, who typically undergo physical therapy at the clinic after the procedure to ensure full recovery of ROM. In this paper, we use accelerometers to create a ROM sensor that can be integrated into the post-operative surgical dressing, so that the cost of the sensors can be included in the bundled payments. In this paper, we demonstrate the efficacy of our method in comparison to the baseline computer vision method. Our results suggest that calculating angular displacement from accelerometer sensors demonstrates accurate ROM recordings under both stationary and walking conditions. The device would keep track of angle measurements and alert the patient when certain angle thresholds have been crossed, allowing patients to recover safely at home instead of going to multiple physical therapy sessions. The affordability of our sensor makes it more accessible to patients in need. ","comment":"8 pages, 16 figures, 1 table, submitted to BSN conference 2022","authors":"Minh Cao, Brett Bailey, Wenhao Zhang, Solana Fernandez, Aaron Han, Smiti Narayanan, Shrineel Patel, Steven Saletta, Alexandra Stavrakis, Stephen Speicher, Stephanie Seidlits, Arash Naeim, Ramin Ramezani","pdf":"http://arxiv.org/pdf/2207.00190v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00117v1","published":"Thu, 30 Jun 2022 22:22:24 GMT","title":"WAKU-RLN-RELAY: Privacy-Preserving Peer-to-Peer Economic Spam Protection","summary":"  In this paper, we propose WAKU-RLN-RELAY as a spam-protected gossip-based routing protocol that can run in heterogeneous networks. It features a privacy-preserving peer-to-peer (p2p) economic spam protection mechanism. WAKU-RLN-RELAY addresses the performance and privacy issues of the state-of-the-art p2p spam prevention techniques including peer scoring utilized by libp2p, and proof-of-work used by e.g., Whisper, the p2p messaging layer of Ethereum. In WAKU-RLN-RELAY, spam protection works by limiting the messaging rate of each network participant. Rate violation is disincentivized since it results in financial punishment where the punishment is cryptographically guaranteed. Peers who identify spammers are also rewarded. To enforce the rate limit, we adopt the suggested framework of Semaphore and its extended version, however, we modify that framework to properly address the unique requirements of a network of p2p resource-restricted users. The current work dives into the end-to-end integration of Semaphore into WAKU-RLN-RELAY, the modifications required to make it suitable for resource-limited users, and the open problems and future research directions. We also provide a proof-of-concept open-source implementation of WAKU-RLN-RELAY, and its specifications together with a rough performance evaluation. ","comment":"IEEE ICDCSW 2022","authors":"Sanaz Taheri-Boshrooyeh, Oskar Thorén, Barry Whitehat, Wei Jie Koh, Onur Kilic, Kobi Gurkan","pdf":"http://arxiv.org/pdf/2207.00117v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00111v1","published":"Thu, 30 Jun 2022 21:51:58 GMT","title":"Deradicalizing YouTube: Characterization, Detection, and Personalization   of Religiously Intolerant Arabic Videos","summary":"  Growing evidence suggests that YouTube's recommendation algorithm plays a role in online radicalization via surfacing extreme content. Radical Islamist groups, in particular, have been profiting from the global appeal of YouTube to disseminate hate and jihadist propaganda. In this quantitative, data-driven study, we investigate the prevalence of religiously intolerant Arabic YouTube videos, the tendency of the platform to recommend such videos, and how these recommendations are affected by demographics and watch history. Based on our deep learning classifier developed to detect hateful videos and a large-scale dataset of over 350K videos, we find that Arabic videos targeting religious minorities are particularly prevalent in search results (30%) and first-level recommendations (21%), and that 15% of overall captured recommendations point to hateful videos. Our personalized audit experiments suggest that gender and religious identity can substantially affect the extent of exposure to hateful content. Our results contribute vital insights into the phenomenon of online radicalization and facilitate curbing online harmful content. ","comment":"To appear in the Proceedings of the ACM on Human Computer Interaction   (CSCW 2022)","authors":"Nuha Albadi, Maram Kurdi, Shivakant Mishra","pdf":"http://arxiv.org/pdf/2207.00111v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00413v1","published":"Mon, 20 Jun 2022 19:46:49 GMT","title":"Metaverse for Wireless Systems: Vision, Enablers, Architecture, and   Future Directions","summary":"  Recently, significant research efforts have been initiated to enable the next-generation, namely, the sixth-generation (6G) wireless systems. In this article, we present a vision of metaverse towards effectively enabling the development of 6G wireless systems. A metaverse will use virtual representation (e.g., digital twin), digital avatars, and interactive experience technologies (e.g., extended reality) to assist analyses, optimizations, and operations of various wireless applications. Specifically, the metaverse can offer virtual wireless system operations through the digital twin that allows network designers, mobile developers, and telecommunications engineers to monitor, observe, analyze, and simulations their solutions collaboratively and virtually. We first introduce a general architecture for metaverse-based wireless systems. We discuss key driving applications, design trends, and key enablers of metaverse-based wireless systems. Finally, we present several open challenges and their potential solutions. ","authors":"Latif U. Khan, Zhu Han, Dusit Niyato, Ekram Hossain, Choong Seon Hong","pdf":"http://arxiv.org/pdf/2207.00413v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2206.13939v2","published":"Sat, 25 Jun 2022 06:12:17 GMT","title":"Functional Optimization Reinforcement Learning for Real-Time Bidding","summary":"  Real-time bidding is the new paradigm of programmatic advertising. An advertiser wants to make the intelligent choice of utilizing a \\\\textbf{Demand-Side Platform} to improve the performance of their ad campaigns. Existing approaches are struggling to provide a satisfactory solution for bidding optimization due to stochastic bidding behavior. In this paper, we proposed a multi-agent reinforcement learning architecture for RTB with functional optimization. We designed four agents bidding environment: three Lagrange-multiplier based functional optimization agents and one baseline agent (without any attribute of functional optimization) First, numerous attributes have been assigned to each agent, including biased or unbiased win probability, Lagrange multiplier, and click-through rate. In order to evaluate the proposed RTB strategy's performance, we demonstrate the results on ten sequential simulated auction campaigns. The results show that agents with functional actions and rewards had the most significant average winning rate and winning surplus, given biased and unbiased winning information respectively. The experimental evaluations show that our approach significantly improve the campaign's efficacy and profitability. ","authors":"Changjie Lu, Yining Lu, Naina Bandyopadhyay, Manoj Kumar, Gaurav Gupta","pdf":"http://arxiv.org/pdf/2206.13939v2","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.01340v1","published":"Mon, 04 Jul 2022 11:51:34 GMT","title":"How centralized is decentralized? Comparison of wealth distribution in   coins and tokens","summary":"  Rapidly growing distributed ledger technologies (DLTs) have recently received attention among researchers in both industry and academia. While a lot of existing analysis (mainly) of the Bitcoin and Ethereum networks is available, the lack of measurements for other crypto projects is observed. This article addresses questions about tokenomics and wealth distributions in cryptocurrencies. We analyze the time-dependent statistical properties of top cryptocurrency holders for 14 different distributed ledger projects. The provided metrics include approximated Zipf coefficient, Shannon entropy, Gini coefficient, and Nakamoto coefficient. We show that there are quantitative differences between the coins (cryptocurrencies operating on their own independent network) and tokens (which operate on top of a smart contract platform). Presented results show that coins and tokens have different values of approximated Zipf coefficient and centralization levels. This work is relevant for DLTs as it might be useful in modeling and improving the committee selection process, especially in decentralized autonomous organizations (DAOs) and delegated proof of stake (DPoS) blockchains. ","comment":"5 figures","authors":"Bartosz Kuśmierz, Roman Overko","pdf":"http://arxiv.org/pdf/2207.01340v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.01137v1","published":"Sun, 03 Jul 2022 22:38:01 GMT","title":"Promotheus: An End-to-End Machine Learning Framework for Optimizing   Markdown in Online Fashion E-commerce","summary":"  Managing discount promotional events (\\markdown\\) is a significant part of running an e-commerce business, and inefficiencies here can significantly hamper a retailer's profitability. Traditional approaches for tackling this problem rely heavily on price elasticity modelling. However, the partial information nature of price elasticity modelling, together with the non-negotiable responsibility for protecting profitability, mean that machine learning practitioners must often go through great lengths to define strategies for measuring offline model quality. In the face of this, many retailers fall back on rule-based methods, thus forgoing significant gains in profitability that can be captured by machine learning. In this paper, we introduce two novel end-to-end markdown management systems for optimising markdown at different stages of a retailer's journey. The first system, \\Ithax\\, enacts a rational supply-side pricing strategy without demand estimation, and can be usefully deployed as a \\cold start\\ solution to collect markdown data while maintaining revenue control. The second system, \\Promotheus\\, presents a full framework for markdown optimization with price elasticity. We describe in detail the specific modelling and validation procedures that, within our experience, have been crucial to building a system that performs robustly in the real world. Both markdown systems achieve superior profitability compared to decisions made by our experienced operations teams in a controlled online test, with improvements of 86% (Promotheus) and 79% (Ithax) relative to manual strategies. These systems have been deployed to manage markdown at ASOS.com, and both systems can be fruitfully deployed for price optimization across a wide variety of retail e-commerce settings. ","comment":"11 pages; Accepted at KDD 2022","authors":"Eleanor Loh, Jalaj Khandelwal, Brian Regan, Duncan A. Little","pdf":"http://arxiv.org/pdf/2207.01137v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00907v1","published":"Sat, 02 Jul 2022 20:26:55 GMT","title":"Emotion Analysis using Multi-Layered Networks for Graphical   Representation of Tweets","summary":"  Anticipating audience reaction towards a certain piece of text is integral to several facets of society ranging from politics, research, and commercial industries. Sentiment analysis (SA) is a useful natural language processing (NLP) technique that utilizes both lexical/statistical and deep learning methods to determine whether different sized texts exhibit a positive, negative, or neutral emotion. However, there is currently a lack of tools that can be used to analyse groups of independent texts and extract the primary emotion from the whole set. Therefore, the current paper proposes a novel algorithm referred to as the Multi-Layered Tweet Analyzer (MLTA) that graphically models social media text using multi-layered networks (MLNs) in order to better encode relationships across independent sets of tweets. Graph structures are capable of capturing meaningful relationships in complex ecosystems compared to other representation methods. State of the art Graph Neural Networks (GNNs) are used to extract information from the Tweet-MLN and make predictions based on the extracted graph features. Results show that not only does the MLTA predict from a larger set of possible emotions, delivering a more accurate sentiment compared to the standard positive, negative or neutral, it also allows for accurate group-level predictions of Twitter data. ","authors":"Anna Nguyen, Antonio Longa, Massimiliano Luca, Joe Kaul, Gabriel Lopez","pdf":"http://arxiv.org/pdf/2207.00907v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00747v1","published":"Sat, 02 Jul 2022 06:20:57 GMT","title":"Rationale-Augmented Ensembles in Language Models","summary":"  Recent research has shown that rationales, or step-by-step chains of thought, can be used to improve performance in multi-step reasoning tasks. We reconsider rationale-augmented prompting for few-shot in-context learning, where (input -> output) prompts are expanded to (input, rationale -> output) prompts. For rationale-augmented prompting we demonstrate how existing approaches, which rely on manual prompt engineering, are subject to sub-optimal rationales that may harm performance. To mitigate this brittleness, we propose a unified framework of rationale-augmented ensembles, where we identify rationale sampling in the output space as the key component to robustly improve performance. This framework is general and can easily be extended to common natural language processing tasks, even those that do not traditionally leverage intermediate steps, such as question answering, word sense disambiguation, and sentiment analysis. We demonstrate that rationale-augmented ensembles achieve more accurate and interpretable results than existing prompting approaches--including standard prompting without rationales and rationale-based chain-of-thought prompting--while simultaneously improving interpretability of model predictions through the associated rationales. ","authors":"Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Denny Zhou","pdf":"http://arxiv.org/pdf/2207.00747v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00722v1","published":"Sat, 02 Jul 2022 03:01:30 GMT","title":"A Study on the Impact of Human Resource Accounting on Firms Value with   Respect to Companies Listed in National Stock Exchange","summary":"  The study focuses on the Impact of Employment Benefit Cots on the Profitability of Companies listed in the National Stock Exchange. The study has considered the Amount spent on Employment Benefit Cots as an Independent variable and Profit after tax, Total Assets, Return on Equity, and Return on Asset and Debt equity Ration as the Dependent variable. The present study is to analyses the relationship between Employment Benefit Cots and Profit after tax, Total Assets, Return on Equity, Return on Asset, and Debt equity Ration. The data is collected from 20 companies listed on the National Stock Exchange for 10 years from the Annual reports of companies. The data collected were analyzed using Panel data Regression in E-Views. Results revealed that there is a significant Relationship between Employment Benefit Cots and Profit after tax, Total Assets, Return on Equity, Return on Asset, and Debt equity Ration. The study shows that Employment Benefit Cots impact positively on Firms profitability. ","authors":"Anil S, Sudharani R, Suresh N","pdf":"http://arxiv.org/pdf/2207.00722v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00720v1","published":"Sat, 02 Jul 2022 02:50:42 GMT","title":"A Study on Impact of Capital Structure on Profitability of Companies   Listed in Indian Stock Exchange with respect to Automobile Industry","summary":"  Current research helps in understanding both positive and negative impacts of capital structure on profits of Indian automobile companies by using variables like Return on Capital Employed, Return on Long Term Funds, Return on Net Worth, Gross Profit Margin, and Operating Profit, and Return on Asset. The study hypothesized that RoCE, RoLT, and RoNW have a positive effect and GP, OP and ROA have a negative impact on debt-equity and interest coverage ratios i.e capital structure of the companies. Also, the study proves that the relationship between profitability and capital structure variables is strongly significant. The hypothesis was tested by using fixed effect and random effect models by considering 10 years of data (from 2010-2019) from 17 automobile companies. The result of the study recommends that the firms can improve their performance by using an optimal capital structure. Also, a fair mix of debt and equity should be established to ensure that the firm maintains capital adequacy. Firms can thus be able to meet their financial compulsions and investments that can promise attractive returns. ","authors":"P. Aishwarya, Sudharani R, Suresh N","pdf":"http://arxiv.org/pdf/2207.00720v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00716v1","published":"Sat, 02 Jul 2022 02:38:43 GMT","title":"A Study on Impact of Environmental Accounting on Profitability of   Companies listed in Bombay Stock Exchange","summary":"  The study focuses on the Impact of Environmental Accounting on the Profitability of Companies listed on the Bombay Stock Exchange. The study has considered the Amount spent on Environmental protection as an Independent variable and Return on Capital Employed, Return on Assets, Return on Net worth/equity, Net Profit Margin, and Dividend per Share as the Dependent variable. The present study is to analyses the relationship between Amounts spent on Environmental protection costs and Return on Capital Employed, Return on Assets, Return on Net worth/equity, Net Profit Margin, and Dividend per Share. The data is collected from 18 companies listed on the Bombay Stock Exchange for 10 years from the Annual reports of companies. The data collected were analysed using Panel data Regression in E-Views. Results revealed that there is a significant Relationship between Environmental protection Cost and Return on Capital Employed, Return on Assets, Return on Net worth/equity, Net Profit Margin, and Dividend per Share. The study shows that Environmental accounting impact positively on Firms profitability. ","authors":"Nandini E. S, Sudharani R, Suresh N","pdf":"http://arxiv.org/pdf/2207.00716v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00715v1","published":"Sat, 02 Jul 2022 02:26:13 GMT","title":"A study on Determinants of Dividend Policy and its Impact on Financial   Performances: A Panel Data Analysis for Indian Listed Firms","summary":"  Determination of the correct mix of dividend and retained earnings and its effect on profitability has been a subject of controversy in financial management literature. This paper seeks to contribute to the ongoing debate by examining the relationship between dividend payout policy and the financial performance of 60 firms listed on the National Stock Exchange between 2009-2018. The Return on Assets (ROA) served as a surrogate for the dependent variable, profitability, while the Dividend Pay-out ratio proxied for dividend policy and was the only explanatory variable. Control variables include firm size, asset tangibility, and leverage. Regression result reveals a positive and significant relationship between dividend payout policy (DPO) and firm performance (ROA). It is recommended that companies should endeavor to put in place a robust dividend payout policy that would encourage investment in projects that give positive Net Present Value. ","authors":"Suresh N, Pooja M","pdf":"http://arxiv.org/pdf/2207.00715v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.00816v1","published":"Thu, 30 Jun 2022 17:11:04 GMT","title":"Mining Tourism Experience on Twitter: A case study","summary":"  With the increase of digital data and social network platforms the impact of social media science in driving company decision related to product/service features and customer care operations is becoming more crucial. In particular, platform such as Twitter where people can share experience about almost everything can drastically impact the reputation and offering of a company as well as of a place or tourism site. Text mining tools are researched and proposed in literature in order to gain value and perform trend topics and sentiment analysis on Twitter. As data are the fuels for these models, the \\right\\ ones, i.e the domain-related ones makes a difference on their accuracy. In this paper, we describe a pipeline of \\\\textit{DataOps / MLOps} operations performed over a tourism related Twitter dataset in order to comprehend tourism motivation and interest. The gained knowledge can be exploit, by the travel/hospitality industry in order to develop data-driven strategic service, and by travelers which can consume relevant information about tourist destination. ","authors":"Davide Stirparo, Beatrice Penna, Mohammad Kazemi, Ariona Shashaj","pdf":"http://arxiv.org/pdf/2207.00816v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.01512v1","published":"Mon, 27 Jun 2022 11:03:56 GMT","title":"Advancing Education Through Extended Reality and Internet of Everything   Enabled Metaverses: Applications, Challenges, and Open Issues","summary":"  Metaverse has evolved as one of the popular research agendas that let the users learn, socialize, and collaborate in a networked 3D immersive virtual world. Due to the rich multimedia streaming capability and immersive user experience with high-speed communication, the metaverse is an ideal model for education, training, and skill development tasks. To facilitate research in this area, we provide a comprehensive review of the various educational use cases and explore how enabling technologies such as Extended reality (XR) and Internet of Everything (IoE) will play a major role in educational services in future metaverses. Secondly, we provide an overview of metaverse-based educational applications focusing on education, training, and skill development and analyze the technologies they are built upon. We identify common research problems and future research directions in the domain. The paper also identifies core ethical considerations of metaverse for education and potential pitfalls. We believe this survey can fully demonstrate the versatility of metaverse-driven education, which could serve as a potential guideline for the researchers. ","comment":"22 pages","authors":"Senthil Kumar Jagatheesaperumal, Kashif Ahmad, Ala Al-Fuqaha, Junaid Qadir","pdf":"http://arxiv.org/pdf/2207.01512v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.01488v1","published":"Tue, 14 Jun 2022 14:05:39 GMT","title":"Award rate inequities in biomedical research","summary":"  The analysis of existing institutional research proposal databases can provide novel insights into science funding parity. The purpose of this study was to analyze the relationship between race/ethnicity and extramural research proposal and award rates across a medical school faculty and to determine whether there was evidence that researchers changed their submission strategies because of differential inequities across submission categories. The authors performed an analysis of 14,263 biomedical research proposals with proposed start dates between 2010-2022 from the University of Michigan Medical School, measuring the proposal submission and award rates for each racial/ethnic group across 4 possible submission categories (R01 & Equivalent programs, other federal, industry, and non-profit). Biomedical researchers from different racial/ethnic groups follow markedly different proposal submission strategies within the University of Michigan Medical School. There is also a clear relationship between race/ethnicity and rates of proposal award. Black/African American and Asian researchers appear disadvantaged across all submission categories relative to White researchers. This study can be easily replicated by other academic research institutions, revealing opportunities for positive intervention. ","authors":"Alessandra Zimmermann, Richard Klavans, Heather Offhaus, Teri A. Grieb, Caleb Smith","pdf":"http://arxiv.org/pdf/2207.01488v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.02197v1","published":"Tue, 05 Jul 2022 17:57:31 GMT","title":"Uncertainty relations from graph theory","summary":"  Quantum measurements are inherently probabilistic. Further defying our classical intuition, quantum theory often forbids us to precisely determine the outcomes of simultaneous measurements. This phenomenon is captured and quantified through uncertainty relations. Although studied since the inception of quantum theory, this problem of determining the possible expectation values of a collection of quantum measurements remains, in general, unsolved. By constructing a close connection between observables and graph theory, we derive uncertainty relations valid for any set of dichotomic observables. These relations are, in many cases, tight, and related to the size of the maximum clique of the associated graph. As applications, they can be straightforwardly used to build entropic uncertainty relations, separability criteria and entanglement witnesses. ","comment":"Comments are welcome","authors":"Carlos de Gois, Kiara Hansenne, Otfried Gühne","pdf":"http://arxiv.org/pdf/2207.02197v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.02160v1","published":"Tue, 05 Jul 2022 16:28:47 GMT","title":"A Comprehensive Review of Visual-Textual Sentiment Analysis from Social   Media Networks","summary":"  Social media networks have become a significant aspect of people's lives, serving as a platform for their ideas, opinions and emotions. Consequently, automated sentiment analysis (SA) is critical for recognising people's feelings in ways that other information sources cannot. The analysis of these feelings revealed various applications, including brand evaluations, YouTube film reviews and healthcare applications. As social media continues to develop, people post a massive amount of information in different forms, including text, photos, audio and video. Thus, traditional SA algorithms have become limited, as they do not consider the expressiveness of other modalities. By including such characteristics from various material sources, these multimodal data streams provide new opportunities for optimising the expected results beyond text-based SA. Our study focuses on the forefront field of multimodal SA, which examines visual and textual data posted on social media networks. Many people are more likely to utilise this information to express themselves on these platforms. To serve as a resource for academics in this rapidly growing field, we introduce a comprehensive overview of textual and visual SA, including data pre-processing, feature extraction techniques, sentiment benchmark datasets, and the efficacy of multiple classification methodologies suited to each field. We also provide a brief introduction of the most frequently utilised data fusion strategies and a summary of existing research on visual-textual SA. Finally, we highlight the most significant challenges and investigate several important sentiment applications. ","authors":"Israa Khalaf Salman Al-Tameemi, Mohammad-Reza Feizi-Derakhshi, Saeed Pashazadeh, Mohammad Asadpour","pdf":"http://arxiv.org/pdf/2207.02160v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.02093v1","published":"Tue, 05 Jul 2022 14:55:16 GMT","title":"Predicting Out-of-Domain Generalization with Local Manifold Smoothness","summary":"  Understanding how machine learning models generalize to new environments is a critical part of their safe deployment. Recent work has proposed a variety of complexity measures that directly predict or theoretically bound the generalization capacity of a model. However, these methods rely on a strong set of assumptions that in practice are not always satisfied. Motivated by the limited settings in which existing measures can be applied, we propose a novel complexity measure based on the local manifold smoothness of a classifier. We define local manifold smoothness as a classifier's output sensitivity to perturbations in the manifold neighborhood around a given test point. Intuitively, a classifier that is less sensitive to these perturbations should generalize better. To estimate smoothness we sample points using data augmentation and measure the fraction of these points classified into the majority class. Our method only requires selecting a data augmentation method and makes no other assumptions about the model or data distributions, meaning it can be applied even in out-of-domain (OOD) settings where existing methods cannot. In experiments on robustness benchmarks in image classification, sentiment analysis, and natural language inference, we demonstrate a strong and robust correlation between our manifold smoothness measure and actual OOD generalization on over 3,000 models evaluated on over 100 train/test domain pairs. ","comment":"18 pages, 3 figures","authors":"Nathan Ng, Kyunghyun Cho, Neha Hulkund, Marzyeh Ghassemi","pdf":"http://arxiv.org/pdf/2207.02093v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"},{"id":"http://arxiv.org/abs/2207.01790v1","published":"Tue, 05 Jul 2022 03:27:50 GMT","title":"Penny Wise and Pound Foolish: Quantifying the Risk of Unlimited Approval   of ERC20 Tokens on Ethereum","summary":"  The prosperity of decentralized finance motivates many investors to profit via trading their crypto assets on decentralized applications (DApps for short) of the Ethereum ecosystem. Apart from Ether (the native cryptocurrency of Ethereum), many ERC20 (a widely used token standard on Ethereum) tokens obtain vast market value in the ecosystem. Specifically, the approval mechanism is used to delegate the privilege of spending users' tokens to DApps. By doing so, the DApps can transfer these tokens to arbitrary receivers on behalf of the users. To increase the usability, unlimited approval is commonly adopted by DApps to reduce the required interaction between them and their users. However, as shown in existing security incidents, this mechanism can be abused to steal users' tokens.   In this paper, we present the first systematic study to quantify the risk of unlimited approval of ERC20 tokens on Ethereum. Specifically, by evaluating existing transactions up to 31st July 2021, we find that unlimited approval is prevalent (60%, 15.2M/25.4M) in the ecosystem, and 22% of users have a high risk of their approved tokens for stealing. After that, we investigate the security issues that are involved in interacting with the UIs of 22 representative DApps and 9 famous wallets to prepare the approval transactions. The result reveals the worrisome fact that all DApps request unlimited approval from the front-end users and only 10% (3/31) of UIs provide explanatory information for the approval mechanism. Meanwhile, only 16% (5/31) of UIs allow users to modify their approval amounts. Finally, we take a further step to characterize the user behavior into five modes and formalize the good practice, i.e., on-demand approval and timely spending, towards securely spending approved tokens. However, the evaluation result suggests that only 0.2% of users follow the good practice to mitigate the risk. ","comment":"16 pages 12 figures Conferences: The 25th International Symposium on   Research in Attacks, Intrusions and Defenses (RAID 2022), October 26--28,   2022, Limassol, Cyprus","authors":"Dabao Wang, Hang Feng, Siwei Wu, Yajin Zhou, Lei Wu, Xingliang Yuan","pdf":"http://arxiv.org/pdf/2207.01790v1","imageURL":"https://avatars.githubusercontent.com/u/45442578?s=280&v=4"}]